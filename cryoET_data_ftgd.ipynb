{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEnsjrTVCQkE"
      },
      "outputs": [],
      "source": [
        "# pip install torch torchvision\n",
        "# pip install -U openmim\n",
        "# pip install mmengine\n",
        "# pip install mmcv\n",
        "# mim install mmdet\n",
        "# git clone https://github.com/open-mmlab/mmdetection.git\n",
        "# cd mmdetection\n",
        "# pip install -v -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o0UZaoQqO5U",
        "outputId": "82efcb0a-8669-4f65-fa98-28c63b867fa6",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mrcfile\n",
            "  Downloading mrcfile-1.5.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from mrcfile) (1.26.4)\n",
            "Downloading mrcfile-1.5.3-py2.py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mrcfile\n",
            "Successfully installed mrcfile-1.5.3\n",
            "Collecting cryoet-data-portal\n",
            "  Downloading cryoet_data_portal-4.2.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from cryoet-data-portal) (2.28.2)\n",
            "Collecting boto3 (from cryoet-data-portal)\n",
            "  Downloading boto3-1.35.79-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting deepmerge (from cryoet-data-portal)\n",
            "  Downloading deepmerge-2.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting gql[requests] (from cryoet-data-portal)\n",
            "  Downloading gql-3.5.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cryoet-data-portal) (4.65.2)\n",
            "Collecting strcase (from cryoet-data-portal)\n",
            "  Downloading strcase-1.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.79 (from boto3->cryoet-data-portal)\n",
            "  Downloading botocore-1.35.79-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->cryoet-data-portal) (0.10.0)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->cryoet-data-portal)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting graphql-core<3.3,>=3.2 (from gql[requests]->cryoet-data-portal)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->cryoet-data-portal) (1.18.3)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->cryoet-data-portal)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->cryoet-data-portal) (3.7.1)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->cryoet-data-portal) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->cryoet-data-portal) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->cryoet-data-portal) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->cryoet-data-portal) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->cryoet-data-portal) (2024.8.30)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql[requests]->cryoet-data-portal) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql[requests]->cryoet-data-portal) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.79->boto3->cryoet-data-portal) (2.8.2)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests]->cryoet-data-portal) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests]->cryoet-data-portal) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict>=4.0->yarl<2.0,>=1.6->gql[requests]->cryoet-data-portal) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.79->boto3->cryoet-data-portal) (1.16.0)\n",
            "Downloading cryoet_data_portal-4.2.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.79-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepmerge-2.0-py3-none-any.whl (13 kB)\n",
            "Downloading strcase-1.0.0-py3-none-any.whl (3.2 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading botocore-1.35.79-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: strcase, graphql-core, deepmerge, backoff, botocore, s3transfer, gql, boto3, cryoet-data-portal\n",
            "Successfully installed backoff-2.2.1 boto3-1.35.79 botocore-1.35.79 cryoet-data-portal-4.2.1 deepmerge-2.0 gql-3.5.0 graphql-core-3.2.5 s3transfer-0.10.4 strcase-1.0.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting groundingdino-py\n",
            "  Downloading groundingdino-py-0.4.0.tar.gz (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (0.15.2+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (4.46.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (0.43.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (1.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (4.10.0.84)\n",
            "Collecting supervision==0.6.0 (from groundingdino-py)\n",
            "  Downloading supervision-0.6.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from groundingdino-py) (2.0.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from supervision==0.6.0->groundingdino-py) (3.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm->groundingdino-py) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->groundingdino-py) (0.26.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->groundingdino-py) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->groundingdino-py) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->groundingdino-py) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->groundingdino-py) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->groundingdino-py) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->groundingdino-py) (3.1.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->groundingdino-py) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->groundingdino-py) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->groundingdino-py) (15.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->groundingdino-py) (2.28.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->groundingdino-py) (11.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->groundingdino-py) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->groundingdino-py) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->groundingdino-py) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->groundingdino-py) (4.65.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->groundingdino-py) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->groundingdino-py) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->groundingdino-py) (2024.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->groundingdino-py) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->groundingdino-py) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->groundingdino-py) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->groundingdino-py) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->groundingdino-py) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->groundingdino-py) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->groundingdino-py) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->groundingdino-py) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->groundingdino-py) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->groundingdino-py) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->groundingdino-py) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->groundingdino-py) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->supervision==0.6.0->groundingdino-py) (1.16.0)\n",
            "Downloading supervision-0.6.0-py3-none-any.whl (31 kB)\n",
            "Building wheels for collected packages: groundingdino-py\n",
            "  Building wheel for groundingdino-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for groundingdino-py: filename=groundingdino_py-0.4.0-py2.py3-none-any.whl size=88749 sha256=2888057a591257d479be8eab32c8f7463ddf4969c210ff6f7a9a367179e93170\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/25/30/97b491abad279d329c62bef1e91bc56bf2fd40b22281068e1d\n",
            "Successfully built groundingdino-py\n",
            "Installing collected packages: supervision, groundingdino-py\n",
            "Successfully installed groundingdino-py-0.4.0 supervision-0.6.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.36.20-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: botocore==1.35.79 in /usr/local/lib/python3.10/dist-packages (from awscli) (1.35.79)\n",
            "Collecting docutils<0.17,>=0.10 (from awscli)\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.10.4)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (6.0.2)\n",
            "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.4.6)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.35.79->awscli) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.35.79->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.35.79->awscli) (1.26.20)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.35.79->awscli) (1.16.0)\n",
            "Downloading awscli-1.36.20-py3-none-any.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: rsa, docutils, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\n",
            "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\n",
            "sphinx 8.1.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed awscli-1.36.20 docutils-0.16 rsa-4.7.2\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (1.26.20)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.20\n",
            "    Uninstalling urllib3-1.26.20:\n",
            "      Successfully uninstalled urllib3-1.26.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.28.2 requires urllib3<1.27,>=1.21.1, but you have urllib3 2.2.3 which is incompatible.\n",
            "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\n",
            "sphinx 8.1.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.50 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed urllib3-2.2.3\n"
          ]
        }
      ],
      "source": [
        "! pip install mrcfile\n",
        "! pip install -U cryoet-data-portal\n",
        "! pip install matplotlib\n",
        "! pip install groundingdino-py\n",
        "! pip install scikit-learn\n",
        "! pip install awscli\n",
        "! pip install --upgrade urllib3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gmQIX2EzqDkg",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Third party imports\n",
        "import cryoet_data_portal as portal\n",
        "import matplotlib.pyplot as plt\n",
        "import mrcfile\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image, ImageDraw\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Instantiate a client, using the data portal GraphQL API by default\n",
        "client = portal.Client()\n",
        "\n",
        "# runs also have s3_prefix where the run data is stored, might be helpful later\n",
        "\n",
        "def find_dataset_by_id(dataset_id):\n",
        "    datasets = portal.Dataset.find(client, [portal.Dataset.id == dataset_id])\n",
        "    return datasets[0] # seems like this is always 1 for the most part\n",
        "\n",
        "\n",
        "def get_dataset_to_runs_for_dataset_id(dataset_id):\n",
        "    dataset = find_dataset_by_id(dataset_id)\n",
        "    return {dataset.id :[run.name for run in dataset.runs]}\n",
        "\n",
        "\n",
        "def get_run_to_tomograms_for_dataset_id(dataset_id):\n",
        "    dataset = find_dataset_by_id(dataset_id)\n",
        "    runs = dataset.runs\n",
        "    run_to_tomograms = {}\n",
        "    for run in runs:\n",
        "        run_to_tomograms[run.name] = run.tomograms\n",
        "    return run_to_tomograms\n",
        "\n",
        "\n",
        "def get_annotations_for_tomogram(tomogram):\n",
        "    annotations = portal.Annotation.find(client, [portal.Tomogram.id == tomogram.id])\n",
        "    return annotations\n",
        "\n",
        "\n",
        "def download_mrc_for_tomogram(dataset_id, tomogram):\n",
        "    \"\"\"Download the MRC file for a given tomogram\"\"\"\n",
        "    # TODO: download to the run name folder generated from the aws sync commands\n",
        "    # new filename should be {tomogram.id}.mrc\n",
        "    url = tomogram.https_mrc_file\n",
        "    dir_name = f\"{dataset_id}_{tomogram.run.name}_{tomogram.id}\"\n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "    local_file = f\"{dir_name}/{tomogram.voxel_spacing}_downloaded.mrc\"\n",
        "    response = requests.get(url)\n",
        "    with open(local_file, 'wb') as f:\n",
        "       f.write(response.content)\n",
        "\n",
        "\n",
        "def get_tomogram_to_annotation_for_run_id(tomograms: list[portal.Tomogram]):\n",
        "    return {\n",
        "        tomogram.id: get_annotations_for_tomogram(tomogram)\n",
        "        for tomogram in tomograms\n",
        "    }\n",
        "\n",
        "\n",
        "def visualize_slice_and_save(mrc_path, z_slice: int, tomogram_id):\n",
        "    with mrcfile.open(mrc_path) as mrc:\n",
        "       slice = mrc.data[z_slice, :, :]\n",
        "       plt.figure(figsize=(10,10))\n",
        "       plt.imshow(slice, cmap='gray')\n",
        "       plt.colorbar()\n",
        "       plt.title(f'Tomogram Slice')\n",
        "       plt.show()\n",
        "       slice_norm = (slice - np.min(slice)) / (np.max(slice) - np.min(slice))\n",
        "       plt.imsave(f'{tomogram_id}_{z_slice}_slice.png', slice_norm, cmap='gray', vmin=0, vmax=1)\n",
        "\n",
        "\n",
        "def save_mrc_slice(mrc_path: str, z_slice: int, tomogram_id: str,\n",
        "                  voxel_spacing: float = None) -> None:\n",
        "    \"\"\"Save a normalized slice from an MRC file\"\"\"\n",
        "    with mrcfile.open(mrc_path) as mrc:\n",
        "        slice = mrc.data[z_slice, :, :]\n",
        "        slice_norm = (slice - np.min(slice)) / (np.max(slice) - np.min(slice))\n",
        "        if voxel_spacing:\n",
        "            plt.figure(figsize=(10, 10), dpi=300)\n",
        "            # By multiplying the pixel dimensions (slice.shape) by voxel_spacing,\n",
        "            # we convert from pixel coordinates to physical units (e.g., nanometers),\n",
        "            # making the scale bars and measurements scientifically meaningful.\n",
        "            plt.imshow(slice_norm, cmap='gray', extent=[0, slice.shape[1]*voxel_spacing,\n",
        "                      slice_norm.shape[0]*voxel_spacing, 0])\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 10), dpi=300)\n",
        "            plt.imshow(slice_norm, cmap='gray')\n",
        "\n",
        "        plt.savefig(f'{tomogram_id}_{z_slice}_slice.png', bbox_inches='tight', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "def process_and_save_all_mrc_layers(mrc_path: str):\n",
        "    # Get directory containing the MRC file\n",
        "    mrc_dir = os.path.dirname(mrc_path)\n",
        "    if not mrc_dir:  # If empty string (current directory)\n",
        "        mrc_dir = '.'\n",
        "    voxel_spacing = os.path.basename(mrc_path).replace('_downloaded.mrc', '')\n",
        "    with mrcfile.open(mrc_path) as mrc:\n",
        "        num_layers = mrc.data.shape[0]\n",
        "        for z in range(num_layers):\n",
        "            slice = mrc.data[z, :, :]\n",
        "            slice_norm = (slice - np.min(slice)) / (np.max(slice) - np.min(slice))\n",
        "            # Convert to 8-bit (0-255) for PNG\n",
        "            slice_norm = (slice_norm * 255).astype(np.uint8)\n",
        "            img = Image.fromarray(slice_norm)\n",
        "            img.save(f'{mrc_dir}/{voxel_spacing}_{z}_slice.png')\n",
        "            print(f\"Processed layer {z}/{num_layers-1}\")\n",
        "\n",
        "def sync_annotations_cmds_for_datasets(dataset_to_runs: dict[str, list[str]], run_to_tomograms: dict[str, list[portal.Tomogram]]):\n",
        "    commands = set()\n",
        "    for dataset_id, run_names in dataset_to_runs.items():\n",
        "        for run_name in run_names:\n",
        "            # The * wildcard will work with aws s3 sync command\n",
        "            # It will match any VoxelSpacing directory like VoxelSpacing10.012, VoxelSpacing14.848 etc.\n",
        "            tomograms = run_to_tomograms[run_name]\n",
        "            for tomogram in tomograms:\n",
        "                cmd = f\"aws s3 --no-sign-request sync s3://cryoet-data-portal-public/{dataset_id}/{run_name}/Reconstructions/VoxelSpacing{tomogram.voxel_spacing}/Annotations {run_name}/Annotations\"\n",
        "                commands.add(cmd)\n",
        "    return commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvU2gJ8Os-Rd",
        "outputId": "3a67166d-a60a-4765-9a9b-44feb81160da",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'TS_5_4': [<cryoet_data_portal._models.Tomogram at 0x7efd7fd115a0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd7fd11960>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd7fd11b10>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd7fef5a20>],\n",
              " 'TS_69_2': [<cryoet_data_portal._models.Tomogram at 0x7efd7fd36a40>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd7fd37fd0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd7fd37880>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd7fd358a0>],\n",
              " 'TS_6_4': [<cryoet_data_portal._models.Tomogram at 0x7efd4e05e590>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e05e620>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e05e440>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e05e230>],\n",
              " 'TS_6_6': [<cryoet_data_portal._models.Tomogram at 0x7efd4e100910>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e1009a0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e1007c0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e1007f0>],\n",
              " 'TS_73_6': [<cryoet_data_portal._models.Tomogram at 0x7efd4e102bf0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e102c80>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e102aa0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4e1028f0>],\n",
              " 'TS_86_3': [<cryoet_data_portal._models.Tomogram at 0x7efd4df38e20>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4df38e50>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4df38bb0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4df38af0>],\n",
              " 'TS_99_9': [<cryoet_data_portal._models.Tomogram at 0x7efd4df3b2e0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4df3b3a0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4df3b1c0>,\n",
              "  <cryoet_data_portal._models.Tomogram at 0x7efd4df3b100>]}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "project_id = 10440\n",
        "tomograms_for_10440 = get_run_to_tomograms_for_dataset_id(project_id)\n",
        "tomograms_for_10440"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYf2TKo6CQkG"
      },
      "outputs": [],
      "source": [
        "dataset_to_runs_10440 = get_dataset_to_runs_for_dataset_id(project_id)\n",
        "sync_cmds = sync_annotations_cmds_for_datasets(dataset_to_runs_10440, tomograms_for_10440)\n",
        "\n",
        "for cmd in sync_cmds:\n",
        "    subprocess.run(cmd.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOtpQ2VvCQkH",
        "outputId": "c4127dbc-e675-44aa-ed96-23a9f5795274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'aws s3 --no-sign-request sync s3://cryoet-data-portal-public/10440/TS_5_4/Reconstructions/VoxelSpacing10.012/Annotations TS_5_4/Annotations',\n",
              " 'aws s3 --no-sign-request sync s3://cryoet-data-portal-public/10440/TS_69_2/Reconstructions/VoxelSpacing10.012/Annotations TS_69_2/Annotations',\n",
              " 'aws s3 --no-sign-request sync s3://cryoet-data-portal-public/10440/TS_6_4/Reconstructions/VoxelSpacing10.012/Annotations TS_6_4/Annotations',\n",
              " 'aws s3 --no-sign-request sync s3://cryoet-data-portal-public/10440/TS_6_6/Reconstructions/VoxelSpacing10.012/Annotations TS_6_6/Annotations',\n",
              " 'aws s3 --no-sign-request sync s3://cryoet-data-portal-public/10440/TS_73_6/Reconstructions/VoxelSpacing10.012/Annotations TS_73_6/Annotations',\n",
              " 'aws s3 --no-sign-request sync s3://cryoet-data-portal-public/10440/TS_86_3/Reconstructions/VoxelSpacing10.012/Annotations TS_86_3/Annotations',\n",
              " 'aws s3 --no-sign-request sync s3://cryoet-data-portal-public/10440/TS_99_9/Reconstructions/VoxelSpacing10.012/Annotations TS_99_9/Annotations'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sync_cmds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVxlolZHCQkH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for run_name, tomograms in tomograms_for_10440.items():\n",
        "    for tomogram in tomograms:\n",
        "        download_mrc_for_tomogram(project_id, tomogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDGo0nVJCQkH",
        "outputId": "b61050a6-f72e-4dc5-d6c7-87aea4a4c25f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed layer 0/183\n",
            "Processed layer 1/183\n",
            "Processed layer 2/183\n",
            "Processed layer 3/183\n",
            "Processed layer 4/183\n",
            "Processed layer 5/183\n",
            "Processed layer 6/183\n",
            "Processed layer 7/183\n",
            "Processed layer 8/183\n",
            "Processed layer 9/183\n",
            "Processed layer 10/183\n",
            "Processed layer 11/183\n",
            "Processed layer 12/183\n",
            "Processed layer 13/183\n",
            "Processed layer 14/183\n",
            "Processed layer 15/183\n",
            "Processed layer 16/183\n",
            "Processed layer 17/183\n",
            "Processed layer 18/183\n",
            "Processed layer 19/183\n",
            "Processed layer 20/183\n",
            "Processed layer 21/183\n",
            "Processed layer 22/183\n",
            "Processed layer 23/183\n",
            "Processed layer 24/183\n",
            "Processed layer 25/183\n",
            "Processed layer 26/183\n",
            "Processed layer 27/183\n",
            "Processed layer 28/183\n",
            "Processed layer 29/183\n",
            "Processed layer 30/183\n",
            "Processed layer 31/183\n",
            "Processed layer 32/183\n",
            "Processed layer 33/183\n",
            "Processed layer 34/183\n",
            "Processed layer 35/183\n",
            "Processed layer 36/183\n",
            "Processed layer 37/183\n",
            "Processed layer 38/183\n",
            "Processed layer 39/183\n",
            "Processed layer 40/183\n",
            "Processed layer 41/183\n",
            "Processed layer 42/183\n",
            "Processed layer 43/183\n",
            "Processed layer 44/183\n",
            "Processed layer 45/183\n",
            "Processed layer 46/183\n",
            "Processed layer 47/183\n",
            "Processed layer 48/183\n",
            "Processed layer 49/183\n",
            "Processed layer 50/183\n",
            "Processed layer 51/183\n",
            "Processed layer 52/183\n",
            "Processed layer 53/183\n",
            "Processed layer 54/183\n",
            "Processed layer 55/183\n",
            "Processed layer 56/183\n",
            "Processed layer 57/183\n",
            "Processed layer 58/183\n",
            "Processed layer 59/183\n",
            "Processed layer 60/183\n",
            "Processed layer 61/183\n",
            "Processed layer 62/183\n",
            "Processed layer 63/183\n",
            "Processed layer 64/183\n",
            "Processed layer 65/183\n",
            "Processed layer 66/183\n",
            "Processed layer 67/183\n",
            "Processed layer 68/183\n",
            "Processed layer 69/183\n",
            "Processed layer 70/183\n",
            "Processed layer 71/183\n",
            "Processed layer 72/183\n",
            "Processed layer 73/183\n",
            "Processed layer 74/183\n",
            "Processed layer 75/183\n",
            "Processed layer 76/183\n",
            "Processed layer 77/183\n",
            "Processed layer 78/183\n",
            "Processed layer 79/183\n",
            "Processed layer 80/183\n",
            "Processed layer 81/183\n",
            "Processed layer 82/183\n",
            "Processed layer 83/183\n",
            "Processed layer 84/183\n",
            "Processed layer 85/183\n",
            "Processed layer 86/183\n",
            "Processed layer 87/183\n",
            "Processed layer 88/183\n",
            "Processed layer 89/183\n",
            "Processed layer 90/183\n",
            "Processed layer 91/183\n",
            "Processed layer 92/183\n",
            "Processed layer 93/183\n",
            "Processed layer 94/183\n",
            "Processed layer 95/183\n",
            "Processed layer 96/183\n",
            "Processed layer 97/183\n",
            "Processed layer 98/183\n",
            "Processed layer 99/183\n",
            "Processed layer 100/183\n",
            "Processed layer 101/183\n",
            "Processed layer 102/183\n",
            "Processed layer 103/183\n",
            "Processed layer 104/183\n",
            "Processed layer 105/183\n",
            "Processed layer 106/183\n",
            "Processed layer 107/183\n",
            "Processed layer 108/183\n",
            "Processed layer 109/183\n",
            "Processed layer 110/183\n",
            "Processed layer 111/183\n",
            "Processed layer 112/183\n",
            "Processed layer 113/183\n",
            "Processed layer 114/183\n",
            "Processed layer 115/183\n",
            "Processed layer 116/183\n",
            "Processed layer 117/183\n",
            "Processed layer 118/183\n",
            "Processed layer 119/183\n",
            "Processed layer 120/183\n",
            "Processed layer 121/183\n",
            "Processed layer 122/183\n",
            "Processed layer 123/183\n",
            "Processed layer 124/183\n",
            "Processed layer 125/183\n",
            "Processed layer 126/183\n",
            "Processed layer 127/183\n",
            "Processed layer 128/183\n",
            "Processed layer 129/183\n",
            "Processed layer 130/183\n",
            "Processed layer 131/183\n",
            "Processed layer 132/183\n",
            "Processed layer 133/183\n",
            "Processed layer 134/183\n",
            "Processed layer 135/183\n",
            "Processed layer 136/183\n",
            "Processed layer 137/183\n",
            "Processed layer 138/183\n",
            "Processed layer 139/183\n",
            "Processed layer 140/183\n",
            "Processed layer 141/183\n",
            "Processed layer 142/183\n",
            "Processed layer 143/183\n",
            "Processed layer 144/183\n",
            "Processed layer 145/183\n",
            "Processed layer 146/183\n",
            "Processed layer 147/183\n",
            "Processed layer 148/183\n",
            "Processed layer 149/183\n",
            "Processed layer 150/183\n",
            "Processed layer 151/183\n",
            "Processed layer 152/183\n",
            "Processed layer 153/183\n",
            "Processed layer 154/183\n",
            "Processed layer 155/183\n",
            "Processed layer 156/183\n",
            "Processed layer 157/183\n",
            "Processed layer 158/183\n",
            "Processed layer 159/183\n",
            "Processed layer 160/183\n",
            "Processed layer 161/183\n",
            "Processed layer 162/183\n",
            "Processed layer 163/183\n",
            "Processed layer 164/183\n",
            "Processed layer 165/183\n",
            "Processed layer 166/183\n",
            "Processed layer 167/183\n",
            "Processed layer 168/183\n",
            "Processed layer 169/183\n",
            "Processed layer 170/183\n",
            "Processed layer 171/183\n",
            "Processed layer 172/183\n",
            "Processed layer 173/183\n",
            "Processed layer 174/183\n",
            "Processed layer 175/183\n",
            "Processed layer 176/183\n",
            "Processed layer 177/183\n",
            "Processed layer 178/183\n",
            "Processed layer 179/183\n",
            "Processed layer 180/183\n",
            "Processed layer 181/183\n",
            "Processed layer 182/183\n",
            "Processed layer 183/183\n"
          ]
        }
      ],
      "source": [
        "process_and_save_all_mrc_layers(\"10440_TS_99_9_17042/10.012_downloaded.mrc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "OnaTgVI1CQkH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from PIL import ImageDraw\n",
        "import json\n",
        "from PIL import Image\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def read_points_file(file_path: str) -> list:\n",
        "    with open(file_path, 'r') as f:\n",
        "        return [json.loads(line) for line in f]\n",
        "\n",
        "def annotate_slice_with_points(slice_path: str, points: list, z_index: int, color: str, box_size: int = 30):\n",
        "    if os.path.exists(slice_path.replace('_slice.png', '_slice_annotated.png')):\n",
        "        img = Image.open(slice_path.replace('_slice.png', '_slice_annotated.png')).convert('RGB')\n",
        "    else:\n",
        "        img = Image.open(slice_path).convert('RGB')\n",
        "\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    for point in points:\n",
        "        loc = point['location']\n",
        "        if abs(loc['z'] - z_index) <= 0.5:\n",
        "            x, y = int(loc['x']), int(loc['y'])\n",
        "            half_size = box_size // 2\n",
        "            draw.rectangle([x-half_size, y-half_size, x+half_size, y+half_size],\n",
        "                         outline=color, width=2)\n",
        "    return img\n",
        "\n",
        "\n",
        "# def annotate_slice_with_points(slice_path: str, points: list, z_index: int, radius: int = 5):\n",
        "#     \"\"\"Draw points on a slice image if they're within ±0.5 of the z_index\"\"\"\n",
        "#     img = Image.open(slice_path)\n",
        "#     draw = ImageDraw.Draw(img)\n",
        "\n",
        "#     for point in points:\n",
        "#         loc = point['location']\n",
        "#         if abs(loc['z'] - z_index) <= 0.5:  # Point is on this slice\n",
        "#             x, y = int(loc['x']), int(loc['y'])\n",
        "#             draw.ellipse([x-radius, y-radius, x+radius, y+radius],\n",
        "#                         fill='red', outline='white')\n",
        "\n",
        "#     return img\n",
        "\n",
        "\n",
        "def process_all_slices(points_file: str, base_dir: str, color: str):\n",
        "    points = read_points_file(points_file)\n",
        "    pattern = os.path.join(base_dir, '*_slice.png')\n",
        "    slice_files = glob.glob(pattern)\n",
        "\n",
        "    for slice_file in slice_files:\n",
        "        if any(x in slice_file for x in [\"39\", \"40\", \"35\", \"31\", \"32\"]):\n",
        "            z = int(slice_file.split('_')[-2])\n",
        "            annotated = annotate_slice_with_points(slice_file, points, z, color)\n",
        "            annotated.save(slice_file.replace('_slice.png', '_slice_annotated.png'))\n",
        "\n",
        "# Usage\n",
        "process_all_slices(\"TS_99_9/Annotations/100/ferritin_complex-1.0_point.ndjson\", \"10440_TS_99_9_17042\", \"red\")\n",
        "process_all_slices(\"TS_99_9/Annotations/101/beta_amylase-1.0_point.ndjson\", \"10440_TS_99_9_17042\", \"blue\")\n",
        "process_all_slices(\"TS_99_9/Annotations/102/beta_galactosidase-1.0_point.ndjson\", \"10440_TS_99_9_17042\", \"green\")\n",
        "process_all_slices(\"TS_99_9/Annotations/103/cytosolic_ribosome-1.0_point.ndjson\", \"10440_TS_99_9_17042\", \"yellow\")\n",
        "process_all_slices(\"TS_99_9/Annotations/104/thyroglobulin-1.0_point.ndjson\", \"10440_TS_99_9_17042\", \"orange\")\n",
        "process_all_slices(\"TS_99_9/Annotations/105/pp7_vlp-1.0_point.ndjson\", \"10440_TS_99_9_17042\", \"purple\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMMY9n9KNwxk"
      },
      "outputs": [],
      "source": [
        "# ! rm 10440_TS_99_9_17042/*_annotated.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TCcrsEGKCQkH"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "\n",
        "def create_coco_dataset(image_dir: str, annotation_files: dict):\n",
        "    \"\"\"\n",
        "    Convert tomogram annotations to COCO format\n",
        "\n",
        "    Args:\n",
        "        image_dir: Directory containing annotated slice images\n",
        "        annotation_files: Dict mapping category names to annotation file paths\n",
        "    \"\"\"\n",
        "    coco_format = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": []\n",
        "    }\n",
        "\n",
        "    # Create categories\n",
        "    for cat_id, category in enumerate(annotation_files.keys(), 1):\n",
        "        coco_format[\"categories\"].append({\n",
        "            \"id\": cat_id,\n",
        "            \"name\": category\n",
        "        })\n",
        "\n",
        "    # Map category names to IDs\n",
        "    category_map = {cat[\"name\"]: cat[\"id\"] for cat in coco_format[\"categories\"]}\n",
        "\n",
        "    # Process images\n",
        "    image_id = 0\n",
        "    annotation_id = 0\n",
        "\n",
        "    for img_path in Path(image_dir).glob(\"*_slice.png\"):\n",
        "        # Get image dimensions\n",
        "        img = Image.open(img_path)\n",
        "        width, height = img.size\n",
        "\n",
        "        # Add image info\n",
        "        coco_format[\"images\"].append({\n",
        "            \"id\": image_id,\n",
        "            \"file_name\": img_path.name,\n",
        "            \"width\": width,\n",
        "            \"height\": height\n",
        "        })\n",
        "\n",
        "        # Get slice number\n",
        "        z_index = int(img_path.stem.split('_')[-2])\n",
        "\n",
        "        # Process each category's annotations\n",
        "        for category, anno_file in annotation_files.items():\n",
        "            with open(anno_file) as f:\n",
        "                points = [json.loads(line) for line in f]\n",
        "\n",
        "            # Add annotations for points on this slice\n",
        "            for point in points:\n",
        "                loc = point['location']\n",
        "                if abs(loc['z'] - z_index) <= 0.5:\n",
        "                    # Convert center point to bbox [x,y,width,height]\n",
        "                    box_size = 30  # Same as used in annotation\n",
        "                    half_size = box_size // 2\n",
        "                    bbox = [\n",
        "                        int(loc['x']) - half_size,\n",
        "                        int(loc['y']) - half_size,\n",
        "                        box_size,\n",
        "                        box_size\n",
        "                    ]\n",
        "\n",
        "                    coco_format[\"annotations\"].append({\n",
        "                        \"id\": annotation_id,\n",
        "                        \"image_id\": image_id,\n",
        "                        \"category_id\": category_map[category],\n",
        "                        \"bbox\": bbox,\n",
        "                        \"area\": box_size * box_size,\n",
        "                        \"iscrowd\": 0\n",
        "                    })\n",
        "                    annotation_id += 1\n",
        "\n",
        "        image_id += 1\n",
        "\n",
        "    return coco_format\n",
        "\n",
        "# Usage\n",
        "annotation_files = {\n",
        "    \"ferritin_complex\": \"/content/drive/MyDrive/TS_99_9/Annotations/100/ferritin_complex-1.0_point.ndjson\",\n",
        "    \"beta_amylase\": \"/content/drive/MyDrive/TS_99_9/Annotations/101/beta_amylase-1.0_point.ndjson\",\n",
        "    \"beta_galactosidase\": \"/content/drive/MyDrive/TS_99_9/Annotations/102/beta_galactosidase-1.0_point.ndjson\",\n",
        "    \"cytosolic_ribosome\": \"/content/drive/MyDrive/TS_99_9/Annotations/103/cytosolic_ribosome-1.0_point.ndjson\",\n",
        "    \"thyroglobulin\": \"/content/drive/MyDrive/TS_99_9/Annotations/104/thyroglobulin-1.0_point.ndjson\",\n",
        "    \"virus\": \"/content/drive/MyDrive/TS_99_9/Annotations/105/pp7_vlp-1.0_point.ndjson\"\n",
        "}\n",
        "\n",
        "coco_annotations = create_coco_dataset(\"/content/drive/MyDrive/10440_TS_99_9_17042\", annotation_files)\n",
        "\n",
        "# Save COCO format annotations\n",
        "with open('annotations_coco.json', 'w') as f:\n",
        "    json.dump(coco_annotations, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vt_cRB5ICQkI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "with open('annotations_coco.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "train_imgs, val_imgs = train_test_split(data['images'], test_size=0.2)\n",
        "\n",
        "# Create train and val annotation files\n",
        "train_data = data.copy()\n",
        "train_data['images'] = train_imgs\n",
        "with open('train_coco.json', 'w') as f:\n",
        "    json.dump(train_data, f)\n",
        "\n",
        "val_data = data.copy()\n",
        "val_data['images'] = val_imgs\n",
        "with open('val_coco.json', 'w') as f:\n",
        "    json.dump(val_data, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPezryiOFY4a"
      },
      "source": [
        "# start finetuning groundingdyno with mmdetection using annotation point coco datasets\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JF_vCo0bFhNu",
        "outputId": "67078168-952d-402e-81db-b858c35639f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m520.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.1.4)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (11.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89991 sha256=00ecdc3b8271bab9dac1734ab65ea4071cb8c697583372d9eef4e03a5f722066\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/2c/b6/3ed2983b1b44fe0dea1bb35234b09f2c22fb8ebb308679c922\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n",
            "torch version: 2.0.1+cu118 cuda: True\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (2.2.2)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.7)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.66.6)\n",
            "Collecting openxlab (from opendatalab->openmim)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.17.0)\n",
            "Collecting filelock~=3.14.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging~=24.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (24.2)\n",
            "Collecting pytz>=2020.1 (from pandas->openmim)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting requests (from openmim)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting rich (from openmim)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\n",
            "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading openxlab-0.1.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112372 sha256=a9f6f890915d0e4dfab570692c4ff027f848af0e5794bef39d81e6705b6fc42d\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535316 sha256=77dbc165ab1f7301f3a6480e6a95b4ade8a865e3368eff0cc3e708afa2bd6fe5\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/11/5e/08e7cb4e03a3e83b4862edd12d1143c8d3936a3dd57a3ee46d\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=ab9443987806f2b52c25768af64c85d4c60846e909f51ee3807d9f7c9b53c6eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: pytz, crcmod, urllib3, tqdm, setuptools, pycryptodome, ordered-set, jmespath, filelock, colorama, rich, requests, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.2\n",
            "    Uninstalling pytz-2024.2:\n",
            "      Successfully uninstalled pytz-2024.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.6\n",
            "    Uninstalling tqdm-4.66.6:\n",
            "      Successfully uninstalled tqdm-4.66.6\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\n",
            "pymc 5.18.2 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\n",
            "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\n",
            "sphinx 8.1.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.50 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 colorama-0.4.6 crcmod-1.7 filelock-3.14.0 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.2 ordered-set-4.1.0 oss2-2.17.0 pycryptodome-3.21.0 pytz-2023.4 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2 urllib3-1.26.20\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7cf555feaa36413b9ec27d2cb9099925",
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pytz",
                  "requests",
                  "setuptools",
                  "tqdm",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmengine>=0.7.0\n",
            "  Downloading mmengine-0.10.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting addict (from mmengine>=0.7.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (6.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (2.5.0)\n",
            "Collecting yapf (from mmengine>=0.7.0)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.7.0) (2.18.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (2.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.7.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.7.0) (1.17.0)\n",
            "Downloading mmengine-0.10.5-py3-none-any.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.3/452.3 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, yapf, mmengine\n",
            "Successfully installed addict-2.4.0 mmengine-0.10.5 yapf-0.43.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmcv<2.1.0,>=2.0.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (74.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (0.10.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (6.0.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (3.8.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (2.5.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0) (2.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0) (1.17.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.1\n",
            "mmcv: 2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "import torch, torchvision\n",
        "print(\"torch version:\",torch.__version__, \"cuda:\",torch.cuda.is_available())\n",
        "!pip install -U openmim\n",
        "!mim install \"mmengine>=0.7.0\"\n",
        "!mim install \"mmcv>=2.0.0,<2.1.0\"\n",
        "#mmcv>=2.0.0rc4,<2.2.0\n",
        "# Check mmcv installation\n",
        "import mmcv\n",
        "print(\"mmcv:\",mmcv.__version__)\n",
        "#This method has worked for me on google colab.\n",
        "\n",
        "# Run the training script\n",
        "# ! python tools/train.py path/to/finetune_config.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoFRhzl9jqPm",
        "outputId": "0f4e3d6e-7757-4ae3-a8dd-d0af3db1765d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using pip 24.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content/drive/MyDrive/mmdetection\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-ohhmtp4_/mmdet.egg-info\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-ohhmtp4_/mmdet.egg-info/SOURCES.txt'\n",
            "  warning: no files found matching 'mmdet/VERSION'\n",
            "  warning: no files found matching 'mmdet/.mim/demo/*/*'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-ohhmtp4_/mmdet.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.26.4)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (2.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.13.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.17.0)\n",
            "Collecting terminaltables (from mmdet==3.3.0)\n",
            "  Obtaining dependency information for terminaltables from https://files.pythonhosted.org/packages/c4/fb/ea621e0a19733e01fe4005d46087d383693c0f4a8f824b47d8d4122c87e0/terminaltables-3.1.10-py2.py3-none-any.whl.metadata\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (4.65.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (2.8.2)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    running egg_info\n",
            "    warning: no files found matching 'mmdet/VERSION'\n",
            "    warning: no files found matching 'mmdet/.mim/demo/*/*'\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    running build_ext\n",
            "Successfully installed mmdet-3.3.0 terminaltables-3.1.10\n"
          ]
        }
      ],
      "source": [
        "# ! git clone https://github.com/open-mmlab/mmdetection.git\n",
        "! pip install -v -e /content/drive/MyDrive/mmdetection\n",
        "# also add CustomCocoDataset to mmdet/datasets and add to __init__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RLBnRBRk-F6",
        "outputId": "6ad4a995-e175-494b-a3aa-e57fb2b5d4da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing rtmdet_tiny_8xb32-300e_coco...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 MiB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth to /content\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mim\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mim/commands/download.py\", line 70, in cli\n",
            "    download(package, configs, dest_root, check_certificate, dataset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mim/commands/download.py\", line 107, in download\n",
            "    return _download_configs(package, configs, dest_root,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mim/commands/download.py\", line 180, in _download_configs\n",
            "    config_obj = Config.fromfile(config_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 461, in fromfile\n",
            "    cfg_dict, cfg_text, env_variables = Config._file2dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 947, in _file2dict\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 889, in _file2dict\n",
            "    _cfg_dict, _cfg_text, _env_variables = Config._file2dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 947, in _file2dict\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 889, in _file2dict\n",
            "    _cfg_dict, _cfg_text, _env_variables = Config._file2dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 947, in _file2dict\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 889, in _file2dict\n",
            "    _cfg_dict, _cfg_text, _env_variables = Config._file2dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 845, in _file2dict\n",
            "    if lazy_import is None and Config._is_lazy_import(filename):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\", line 1661, in _is_lazy_import\n",
            "    with open(filename, encoding='utf-8') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/mmdetection/mmdet/.mim/configs/rtmdet/../_base_/schedules/schedule_1x.py'\n"
          ]
        }
      ],
      "source": [
        "! mim download mmdet --config rtmdet_tiny_8xb32-300e_coco --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "JNzv669DlDMW",
        "outputId": "5c7aa737-2ab3-4d40-ed37-c7260ba85ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.18.2 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\n",
            "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "yfinance 0.2.50 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "590b98ae316c4452ab7d74e8ddb2de56",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-12-10 20:52:46.257823: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-10 20:52:46.381786: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-10 20:52:46.398457: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-10 20:52:46.472363: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-10 20:52:50.369309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "Loads checkpoint by local backend from path: ../rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
            "\n",
            "12/10 20:52:55 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n",
            "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
            "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n",
            "\u001b[2K/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an \n",
            "upcoming release, it will be required to pass the indexing argument. (Triggered internally at \n",
            "../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[2KInference \u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m  \u001b[36m \u001b[0m\n",
            "\u001b[?25hresults have been saved at outputs\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy==1.23.5\n",
        "\n",
        "! cd mmdetection && python demo/image_demo.py demo/demo.jpg ../rtmdet_tiny_8xb32-300e_coco.py --weights ../rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth --device cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541,
          "referenced_widgets": [
            "bcb77c13076141e180baae89b36f91d2",
            "73292c29eea747b6b87cc202bf63cf39",
            "d324155e057c45a085dcd5aa411a40df",
            "899879659aca4677bbc85ce6dd3d3026",
            "c5823cedb1f74011b70fee06c37d084a",
            "b09f7109168f4294a80aefaa5c49432b",
            "058373ce91c9405492df3e7381d9e750",
            "32ba22c0d97f42ac83da374d98eaa519",
            "aabcf19f14f547bf9dc90c21f0228266",
            "7ad47d08b4bf49aa811e36aa6d18d327",
            "848029d5ac424538ae9efbcde8c042ea",
            "64a2ac7439164acd8c68bae0664e989c",
            "2e7171ac41d14fa4a07d3524f5c08501",
            "ab30b91b7552489996e323be81d40ebf",
            "564fd734b1ba44adb381cf286baeb993",
            "10b528bd4b0f4d8a86e57f9caa9acdb1",
            "a5cc0e51d3ef417b844d85558cce6267",
            "e7384a69f73b4e68a1955f83fcb81873",
            "9b625fbfedec40ff8f1722c6d106d212",
            "5cd90df8b53749ecbfcd33e9956ea5d0",
            "cce8427ef2354ab7a494870d4ff8a601",
            "f753631e9e0f4771a77e9005f8304b1e",
            "4e3207c1d9514299b56c8ffd0afe3691",
            "f3f171b8646e4e969a6055c05a3b6370",
            "78c5532280bf42f6b6da9c202a41d496",
            "30505c7b565445cc9f70a961da2e2e69",
            "070f2d176e404d0fba57ca0c00cff31b",
            "bc8834a66e1c4f60b48fdde46e6bba46",
            "d948c3b3b3f04929a11aa9e925f85bf7",
            "17fb60778927455bb0c0e222b5479554",
            "9df1bc8c8d194cefbbac40371393faf6",
            "3223638c2d2a4a77baf8dfcc6e8fb944",
            "114d5244775645b488c536af762ea71d",
            "668d751e06d542a8b9fc4d4f3bf17fdb",
            "a3f4094fc2d94cd18a912f75393008a7",
            "5b4278cf6ccb40c89005c2f2c84ff5a3",
            "d3d8508668d6471592667a8b19227eec",
            "854ae1afb85b4255b57927e3aa0afaa8",
            "b45643cd6c2148a98a2e560704ebc4f3",
            "0002d229d22f4562951c1332ab9aea32",
            "6b08d1e009384d77873c447e6184f7de",
            "782bbd88682b40348759f06969b3a5ea",
            "20d8c1ec8fca42fbb72d6c292a37a5d0",
            "42b69f457d324012a112737bfed4ebf0",
            "0c9a5518c2894dbcad7d9a0ca7b6b466",
            "de1b0cffcb014954895bd097930f2012",
            "c9e2d5c317ae4af79ee167b789087f8d",
            "f6e1e14592de4309a26a1603f445f78a",
            "795ff19d7cda498d9f3648077776d762",
            "71b0a36e17c64e49a9c0f96a94f3747e",
            "a14a10039fb5407fb72b70ba4525cfd5",
            "c67ee0314410458984acb5ccae11fbc8",
            "0d76974e9d304a29be21ffa5ad25cd14",
            "a9876268ab49422dbb5560df47e8c646",
            "a787c1fc926b45a286b2f64bdf8e4506"
          ]
        },
        "id": "eULj4KQnH6Lm",
        "outputId": "c568da70-548d-4e31-de3f-edbd6a4a49bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcb77c13076141e180baae89b36f91d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64a2ac7439164acd8c68bae0664e989c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e3207c1d9514299b56c8ffd0afe3691",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "668d751e06d542a8b9fc4d4f3bf17fdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c9a5518c2894dbcad7d9a0ca7b6b466",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('bert-base-uncased/tokenizer_config.json',\n",
              " 'bert-base-uncased/special_tokens_map.json',\n",
              " 'bert-base-uncased/vocab.txt',\n",
              " 'bert-base-uncased/added_tokens.json',\n",
              " 'bert-base-uncased/tokenizer.json')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\", add_pooling_layer=False, config=config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "config.save_pretrained(\"bert-base-uncased\")\n",
        "model.save_pretrained(\"bert-base-uncased\")\n",
        "tokenizer.save_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUVghzccpH1k",
        "outputId": "4ffc19e8-f970-4b79-be13-1dc84f0e4967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images: 147\n",
            "Annotations: 202\n",
            "Categories: 6\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open('train_coco.json') as f:\n",
        "    data = json.load(f)\n",
        "print(f\"Images: {len(data['images'])}\")\n",
        "print(f\"Annotations: {len(data['annotations'])}\")\n",
        "print(f\"Categories: {len(data['categories'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZeugCNBqP8d",
        "outputId": "6da651a2-bd33-435b-84cd-ecdcb3099fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First image path: 10.012_92_slice.png\n",
            "Exists?: False\n"
          ]
        }
      ],
      "source": [
        "# Check first few image paths exist\n",
        "import os\n",
        "print(f\"First image path: {data['images'][0]['file_name']}\")\n",
        "print(f\"Exists?: {os.path.exists(os.path.join('10440_TS_99_9_17042', data['images'][0]['file_name']))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0vRSR7oK4s6",
        "outputId": "d9c95ef9-e297-43ab-828a-db5b2e786437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample annotation:\n",
            "{\n",
            "  \"id\": 0,\n",
            "  \"image_id\": 2,\n",
            "  \"category_id\": 5,\n",
            "  \"bbox\": [\n",
            "    52,\n",
            "    68,\n",
            "    30,\n",
            "    30\n",
            "  ],\n",
            "  \"area\": 900,\n",
            "  \"iscrowd\": 0\n",
            "}\n",
            "\n",
            "Categories:\n",
            "1: ferritin_complex\n",
            "2: beta_amylase\n",
            "3: beta_galactosidase\n",
            "4: cytosolic_ribosome\n",
            "5: thyroglobulin\n",
            "6: virus\n"
          ]
        }
      ],
      "source": [
        "print(\"Sample annotation:\")\n",
        "print(json.dumps(data['annotations'][0], indent=2))\n",
        "\n",
        "print(\"\\nCategories:\")\n",
        "for cat in data['categories']:\n",
        "    print(f\"{cat['id']}: {cat['name']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rz_b7VhLBM8",
        "outputId": "dcc04f07-0741-4a13-a15f-cd008c389287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing image IDs: {6, 8, 144, 25, 27, 46, 48, 49, 53, 58, 64, 70, 78, 80, 87, 90, 97, 110, 111, 115, 125, 126}\n"
          ]
        }
      ],
      "source": [
        "image_ids = set(img['id'] for img in data['images'])\n",
        "anno_image_ids = set(anno['image_id'] for anno in data['annotations'])\n",
        "print(f\"Missing image IDs: {anno_image_ids - image_ids}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Blm1b7rHF8",
        "outputId": "2b0068f4-c304-4a09-f263-9fe669ae2572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annotations after cleanup: 159\n"
          ]
        }
      ],
      "source": [
        "# Remove annotations without matching images\n",
        "valid_annotations = [anno for anno in data['annotations'] if anno['image_id'] in image_ids]\n",
        "data['annotations'] = valid_annotations\n",
        "\n",
        "# Save fixed data\n",
        "with open('train_coco.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "print(f\"Annotations after cleanup: {len(valid_annotations)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2TK912arQ7G",
        "outputId": "158a326c-1f6a-4a4d-9a0a-f6bcf78b4196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val annotations after cleanup: 34\n"
          ]
        }
      ],
      "source": [
        "# Load and fix val data\n",
        "with open('val_coco.json') as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "val_image_ids = set(img['id'] for img in val_data['images'])\n",
        "val_valid_annotations = [anno for anno in val_data['annotations'] if anno['image_id'] in val_image_ids]\n",
        "val_data['annotations'] = val_valid_annotations\n",
        "\n",
        "with open('val_coco.json', 'w') as f:\n",
        "    json.dump(val_data, f)\n",
        "\n",
        "print(f\"Val annotations after cleanup: {len(val_valid_annotations)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zo0HgwCczKuS"
      },
      "outputs": [],
      "source": [
        "# Add text fields to each annotation\n",
        "for anno in data['annotations']:\n",
        "    category_name = next(cat['name'] for cat in data['categories'] if cat['id'] == anno['category_id'])\n",
        "    anno['text'] = category_name\n",
        "\n",
        "# Save updated data\n",
        "with open('train_coco.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "# Do same for validation\n",
        "with open('val_coco.json') as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "for anno in val_data['annotations']:\n",
        "    category_name = next(cat['name'] for cat in val_data['categories'] if cat['id'] == anno['category_id'])\n",
        "    anno['text'] = category_name\n",
        "\n",
        "with open('val_coco.json', 'w') as f:\n",
        "    json.dump(val_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma39BsL833aZ",
        "outputId": "3114aa24-db4a-4fa3-953f-d2940236dc6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": 0,\n",
            "  \"image_id\": 2,\n",
            "  \"category_id\": 5,\n",
            "  \"bbox\": [\n",
            "    52,\n",
            "    68,\n",
            "    30,\n",
            "    30\n",
            "  ],\n",
            "  \"area\": 900,\n",
            "  \"iscrowd\": 0,\n",
            "  \"text\": \"thyroglobulin\"\n",
            "}\n",
            "Annotations missing required fields: []\n"
          ]
        }
      ],
      "source": [
        "with open('train_coco.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Check first annotation structure\n",
        "print(json.dumps(data['annotations'][0], indent=2))\n",
        "\n",
        "# Verify each annotation has required fields\n",
        "required_fields = ['bbox', 'image_id', 'category_id']\n",
        "missing = [i for i, anno in enumerate(data['annotations'])\n",
        "          if not all(field in anno for field in required_fields)]\n",
        "print(f\"Annotations missing required fields: {missing}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wqIKJwmd5k-_"
      },
      "outputs": [],
      "source": [
        "# Update train data\n",
        "with open('train_coco.json') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "# Remove text from images if it exists\n",
        "for img in train_data['images']:\n",
        "    if 'text' in img:\n",
        "        del img['text']\n",
        "\n",
        "# Add text to each annotation\n",
        "for ann in train_data['annotations']:\n",
        "    ann['text'] = \"Find ferritin complex, beta amylase, beta galactosidase, cytosolic ribosome, thyroglobulin, and virus\"\n",
        "\n",
        "with open('train_coco.json', 'w') as f:\n",
        "    json.dump(train_data, f)\n",
        "\n",
        "# Update validation data\n",
        "with open('val_coco.json') as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "# Remove text from images if it exists\n",
        "for img in val_data['images']:\n",
        "    if 'text' in img:\n",
        "        del img['text']\n",
        "\n",
        "# Add text to each annotation\n",
        "for ann in val_data['annotations']:\n",
        "    ann['text'] = \"Find ferritin complex, beta amylase, beta galactosidase, cytosolic ribosome, thyroglobulin, and virus\"\n",
        "\n",
        "with open('val_coco.json', 'w') as f:\n",
        "    json.dump(val_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jytf8OgZ4UtM",
        "outputId": "6350c8ee-148f-461a-ee37-f407c2e8e525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample image path: 10440_TS_99_9_17042/10.012_5_slice.png\n",
            "Images exist: True\n"
          ]
        }
      ],
      "source": [
        "# Check first image path and existence\n",
        "print(\"Sample image path:\", os.path.join('10440_TS_99_9_17042', data['images'][0]['file_name']))\n",
        "print(\"Images exist:\", all(os.path.exists(os.path.join('10440_TS_99_9_17042', img['file_name']))\n",
        "                          for img in data['images']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgHrkH2V4zdm",
        "outputId": "a0f1a676-9a18-4af6-e20c-283aa29258fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Image 50:\n",
            "Path: 10.012_101_slice.png\n",
            "Number of annotations: 1\n",
            "Category: 4, BBox: [316, 531, 30, 30]\n",
            "\n",
            "Image 51:\n",
            "Path: 10.012_76_slice.png\n",
            "Number of annotations: 4\n",
            "Category: 1, BBox: [30, 181, 30, 30]\n",
            "Category: 5, BBox: [535, 447, 30, 30]\n",
            "Category: 6, BBox: [293, 33, 30, 30]\n",
            "Category: 6, BBox: [13, 395, 30, 30]\n",
            "\n",
            "Image 52:\n",
            "Path: 10.012_16_slice.png\n",
            "Number of annotations: 0\n",
            "\n",
            "Image 53:\n",
            "Path: 10.012_169_slice.png\n",
            "Number of annotations: 0\n",
            "\n",
            "Image 54:\n",
            "Path: 10.012_114_slice.png\n",
            "Number of annotations: 5\n",
            "Category: 2, BBox: [265, 561, 30, 30]\n",
            "Category: 4, BBox: [477, 543, 30, 30]\n",
            "Category: 4, BBox: [273, 276, 30, 30]\n",
            "Category: 5, BBox: [107, 186, 30, 30]\n",
            "Category: 5, BBox: [201, 17, 30, 30]\n"
          ]
        }
      ],
      "source": [
        "# Print first few images and annotations that would be loaded\n",
        "for i in range(50,55):\n",
        "    print(f\"\\nImage {i}:\")\n",
        "    print(f\"Path: {data['images'][i]['file_name']}\")\n",
        "    annos = [a for a in data['annotations'] if a['image_id'] == data['images'][i]['id']]\n",
        "    print(f\"Number of annotations: {len(annos)}\")\n",
        "    for a in annos:\n",
        "        print(f\"Category: {a['category_id']}, BBox: {a['bbox']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WMCdQp65KGW",
        "outputId": "991eb71b-d496-4f00-b0bd-b21204a471a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Required GroundingDINO fields:\n",
            "\n",
            "Image format:\n",
            "{\n",
            "  \"id\": 29,\n",
            "  \"file_name\": \"10.012_5_slice.png\",\n",
            "  \"width\": 630,\n",
            "  \"height\": 630\n",
            "}\n",
            "\n",
            "Annotation format:\n",
            "{\n",
            "  \"id\": 1,\n",
            "  \"image_id\": 2,\n",
            "  \"category_id\": 2,\n",
            "  \"bbox\": [\n",
            "    173,\n",
            "    8,\n",
            "    30,\n",
            "    30\n",
            "  ],\n",
            "  \"area\": 900,\n",
            "  \"iscrowd\": 0\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(\"Required GroundingDINO fields:\")\n",
        "print(\"\\nImage format:\")\n",
        "print(json.dumps(data['images'][0], indent=2))\n",
        "print(\"\\nAnnotation format:\")\n",
        "print(json.dumps(data['annotations'][0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOV_sNoZ5NWx",
        "outputId": "0d135f6b-a39c-4ddb-eab4-03489e1daac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset saved to train_coco_cleaned.json\n"
          ]
        }
      ],
      "source": [
        "# import json\n",
        "\n",
        "# # Paths\n",
        "# input_file = \"train_coco.json\"\n",
        "# output_file = \"train_coco_cleaned.json\"\n",
        "\n",
        "# # Load dataset\n",
        "# with open(input_file, 'r') as f:\n",
        "#     coco_data = json.load(f)\n",
        "\n",
        "# # Remove \"text\" key from images\n",
        "# for image in coco_data[\"images\"]:\n",
        "#     image.pop(\"text\", None)\n",
        "\n",
        "# # Remove \"text\" key from annotations\n",
        "# for annotation in coco_data[\"annotations\"]:\n",
        "#     annotation.pop(\"text\", None)\n",
        "\n",
        "# # Save cleaned dataset\n",
        "# with open(output_file, 'w') as f:\n",
        "#     json.dump(coco_data, f, indent=4)\n",
        "\n",
        "# print(f\"Cleaned dataset saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfpxSPvp7dUo",
        "outputId": "5986cbf6-1538-444c-c465-9f1479e6be28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results:\n",
            "- All annotations have valid 'image_id' references.\n",
            "- All image files are present.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "# data_root = \"10440_TS_99_9_17042\"  # Directory containing images\n",
        "data_root = \"/content/drive/MyDrive/10440_TS_99_9_17042\"\n",
        "annotation_file = \"train_coco.json\"  # Updated dataset file\n",
        "\n",
        "# Load dataset\n",
        "with open(annotation_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Check if critical fields are empty\n",
        "print(\"Validation Results:\")\n",
        "if not data[\"images\"]:\n",
        "    print(\"- 'images' array is empty.\")\n",
        "if not data[\"annotations\"]:\n",
        "    print(\"- 'annotations' array is empty.\")\n",
        "if not data[\"categories\"]:\n",
        "    print(\"- 'categories' array is empty.\")\n",
        "\n",
        "# Check orphaned annotations\n",
        "image_ids = {img[\"id\"] for img in data[\"images\"]}\n",
        "orphan_annotations = [\n",
        "    ann for ann in data[\"annotations\"] if ann[\"image_id\"] not in image_ids\n",
        "]\n",
        "if orphan_annotations:\n",
        "    print(f\"- Orphan annotations found: {len(orphan_annotations)}\")\n",
        "else:\n",
        "    print(\"- All annotations have valid 'image_id' references.\")\n",
        "\n",
        "# Check missing images\n",
        "missing_images = [\n",
        "    img[\"file_name\"] for img in data[\"images\"]\n",
        "    if not os.path.exists(os.path.join(data_root, img[\"file_name\"]))\n",
        "]\n",
        "if missing_images:\n",
        "    print(f\"- Missing image files: {len(missing_images)}\")\n",
        "else:\n",
        "    print(\"- All image files are present.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6xJc6wSuU3w",
        "outputId": "1d95a8a0-6ac9-4274-e3bd-19b4a1b79552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-13 17:31:37--  https://download.openmmlab.com/mmdetection/v3.0/grounding_dino/groundingdino_swint_ogc_mmdet-822d7e9d.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 163.181.82.164, 163.181.82.148, 163.181.82.166, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|163.181.82.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 691901857 (660M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/groundingdino_swint_ogc_mmdet-822d7e9d.pth’\n",
            "\n",
            "groundingdino_swint 100%[===================>] 659.85M  24.2MB/s    in 27s     \n",
            "\n",
            "2024-12-13 17:32:04 (24.7 MB/s) - ‘checkpoints/groundingdino_swint_ogc_mmdet-822d7e9d.pth’ saved [691901857/691901857]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ! wget https://download.openmmlab.com/mmdetection/v3.0/grounding_dino/groundingdino_swint_ogc_mmdet-822d7e9d.pth -P checkpoints/\n",
        "# ! wget https://download.openmmlab.com/mmdetection/v3.0/grounding_dino/grounding_dino_swin-t_finetune_16xb2_1x_coco/grounding_dino_swin-t_finetune_16xb2_1x_coco_20230921_152544-5f234b20.pth -P checkpoints/\n",
        "! wget https://download.openmmlab.com/mmdetection/v3.0/grounding_dino/groundingdino_swint_ogc_mmdet-822d7e9d.pth -P checkpoints/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55Lsoy8-nulL",
        "outputId": "c34a1385-8c2d-4e75-a078-3c8523e950e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 147\n",
            "Images with annotations: 80\n",
            "Images without annotations: 67\n",
            "Min annotations per image: 1\n",
            "Max annotations per image: 5\n",
            "Total annotations: 159\n",
            "Warning: Negative bbox coordinates in annotation 4\n",
            "Warning: Negative bbox coordinates in annotation 5\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load and analyze the annotation file\n",
        "def analyze_coco_annotations(json_file):\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Count annotations per image\n",
        "    image_to_anns = defaultdict(int)\n",
        "    for ann in data['annotations']:\n",
        "        image_to_anns[ann['image_id']] += 1\n",
        "\n",
        "    # Basic stats\n",
        "    total_images = len(data['images'])\n",
        "    images_with_anns = len(image_to_anns)\n",
        "    empty_images = total_images - images_with_anns\n",
        "\n",
        "    print(f\"Total images: {total_images}\")\n",
        "    print(f\"Images with annotations: {images_with_anns}\")\n",
        "    print(f\"Images without annotations: {empty_images}\")\n",
        "\n",
        "    # Distribution of annotations per image\n",
        "    ann_counts = list(image_to_anns.values())\n",
        "    if ann_counts:\n",
        "        print(f\"Min annotations per image: {min(ann_counts)}\")\n",
        "        print(f\"Max annotations per image: {max(ann_counts)}\")\n",
        "        print(f\"Total annotations: {sum(ann_counts)}\")\n",
        "\n",
        "    # Check for potential issues\n",
        "    for ann in data['annotations']:\n",
        "        bbox = ann['bbox']\n",
        "        if any(x < 0 for x in bbox):\n",
        "            print(f\"Warning: Negative bbox coordinates in annotation {ann['id']}\")\n",
        "        if bbox[2] == 0 or bbox[3] == 0:\n",
        "            print(f\"Warning: Zero width/height in annotation {ann['id']}\")\n",
        "\n",
        "# Run analysis\n",
        "analyze_coco_annotations('/content/train_coco.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtqB-uUKn7cB",
        "outputId": "63319278-bc54-407f-d8ec-a535c7cc41db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original images: 147\n",
            "Clean images: 78\n",
            "Original annotations: 202\n",
            "Clean annotations: 200\n",
            "Original images: 37\n",
            "Clean images: 22\n",
            "Original annotations: 202\n",
            "Clean annotations: 200\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def clean_coco_annotations(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Get images that have annotations\n",
        "    images_with_anns = set()\n",
        "    valid_annotations = []\n",
        "\n",
        "    for ann in data['annotations']:\n",
        "        # Check for valid bbox coordinates\n",
        "        bbox = ann['bbox']\n",
        "        if all(x >= 0 for x in bbox) and bbox[2] > 0 and bbox[3] > 0:\n",
        "            valid_annotations.append(ann)\n",
        "            images_with_anns.add(ann['image_id'])\n",
        "\n",
        "    # Keep only images that have valid annotations\n",
        "    valid_images = [img for img in data['images'] if img['id'] in images_with_anns]\n",
        "\n",
        "    # Create clean dataset\n",
        "    clean_data = {\n",
        "        'images': valid_images,\n",
        "        'annotations': valid_annotations,\n",
        "        'categories': data['categories']\n",
        "    }\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(clean_data, f)\n",
        "\n",
        "    print(f\"Original images: {len(data['images'])}\")\n",
        "    print(f\"Clean images: {len(valid_images)}\")\n",
        "    print(f\"Original annotations: {len(data['annotations'])}\")\n",
        "    print(f\"Clean annotations: {len(valid_annotations)}\")\n",
        "\n",
        "# Clean both train and val sets\n",
        "clean_coco_annotations('/content/train_coco.json', '/content/train_coco_clean.json')\n",
        "clean_coco_annotations('/content/val_coco.json', '/content/val_coco_clean.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA98Ga7qz7dH",
        "outputId": "4747584c-ffa7-4eb3-dbb7-ae68ebed0708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categories:\n",
            "ID: 1, Name: ferritin_complex\n",
            "ID: 2, Name: beta_amylase\n",
            "ID: 3, Name: beta_galactosidase\n",
            "ID: 4, Name: cytosolic_ribosome\n",
            "ID: 5, Name: thyroglobulin\n",
            "ID: 6, Name: virus\n",
            "\n",
            "Category IDs used in annotations: [1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def check_categories_and_annotations(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(\"Categories:\")\n",
        "    for cat in data['categories']:\n",
        "        print(f\"ID: {cat['id']}, Name: {cat['name']}\")\n",
        "\n",
        "    # Check what category IDs are actually used in annotations\n",
        "    used_cats = set()\n",
        "    for ann in data['annotations']:\n",
        "        used_cats.add(ann['category_id'])\n",
        "\n",
        "    print(\"\\nCategory IDs used in annotations:\", sorted(list(used_cats)))\n",
        "\n",
        "check_categories_and_annotations('/content/train_coco_clean.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnqS3w6q0Vib",
        "outputId": "0b457821-e4de-4c62-9625-a458d166de37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original category IDs: [1, 2, 3, 4, 5, 6]\n",
            "New category IDs: [0, 1, 2, 3, 4, 5]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def remap_categories(input_train_file, input_val_file, output_train_file, output_val_file):\n",
        "    # Read both files\n",
        "    with open(input_train_file, 'r') as f:\n",
        "        train_data = json.load(f)\n",
        "    with open(input_val_file, 'r') as f:\n",
        "        val_data = json.load(f)\n",
        "\n",
        "    # Create mapping from old to new category IDs\n",
        "    cat_map = {cat['id']: idx for idx, cat in enumerate(train_data['categories'])}\n",
        "\n",
        "    # Update training data\n",
        "    for cat in train_data['categories']:\n",
        "        cat['id'] = cat_map[cat['id']]\n",
        "    for ann in train_data['annotations']:\n",
        "        ann['category_id'] = cat_map[ann['category_id']]\n",
        "\n",
        "    # Update validation data\n",
        "    for cat in val_data['categories']:\n",
        "        cat['id'] = cat_map[cat['id']]\n",
        "    for ann in val_data['annotations']:\n",
        "        ann['category_id'] = cat_map[ann['category_id']]\n",
        "\n",
        "    # Save remapped data\n",
        "    with open(output_train_file, 'w') as f:\n",
        "        json.dump(train_data, f, indent=2)\n",
        "    with open(output_val_file, 'w') as f:\n",
        "        json.dump(val_data, f, indent=2)\n",
        "\n",
        "    print(\"Original category IDs:\", sorted(list(cat_map.keys())))\n",
        "    print(\"New category IDs:\", sorted(list(cat_map.values())))\n",
        "\n",
        "# Run the remapping\n",
        "remap_categories(\n",
        "    '/content/train_coco_clean.json',\n",
        "    '/content/val_coco.json',\n",
        "    '/content/train_coco_remapped.json',\n",
        "    '/content/val_coco_remapped.json'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSZpxc5Y6ngM",
        "outputId": "18b2f981-73f7-4043-e781-ed5b238b2e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-12-13 17:33:52.680366: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-13 17:33:52.701453: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-13 17:33:52.707945: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-13 17:33:53.994762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
            "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                  ] 51/78, 3.6 task/s, elapsed: 14s, ETA:     8s/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:760: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:831: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\n",
            "  warnings.warn(\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 78/78, 3.8 task/s, elapsed: 21s, ETA:     0s"
          ]
        }
      ],
      "source": [
        "! python /content/drive/MyDrive/mmdetection/tools/analysis_tools/browse_dataset.py /content/drive/MyDrive/finetune_config.py --output-dir inspect_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgEgolsdrwYt",
        "outputId": "6f57a638-4894-460b-d04e-fd5dacb2e4dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            ") at 0x7f37611e3a90>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8728],\n",
            "        [ 4.2051],\n",
            "        [-1.8567],\n",
            "        [-1.9099],\n",
            "        [ 2.7178]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[102.7913,  97.4329, 141.8173, 135.6463],\n",
            "        [216.0483,   9.0733, 255.8695,  46.8063],\n",
            "        [102.5259,  97.8431, 141.3778, 135.9814],\n",
            "        [104.6924,  98.0456, 142.9929, 135.8190],\n",
            "        [124.7729,   1.5498, 163.1868,  39.8681]], device='cuda:0')\n",
            "GT bboxes: tensor([[104.1270,  97.7778, 142.2222, 135.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2958,  7.0578],\n",
            "        [ 7.2556,  9.8273],\n",
            "        [ 7.2552,  9.8572],\n",
            "        [14.6040, -1.7145],\n",
            "        [ 4.3345, 11.8388]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[221.7305, 451.7704, 260.6806, 491.0824],\n",
            "        [248.0509, 638.3814, 287.2872, 676.9169],\n",
            "        [249.6232, 639.4101, 288.2826, 677.7946],\n",
            "        [185.7576,  68.0479, 224.2194, 105.0836],\n",
            "        [429.9515, 613.4310, 468.5914, 650.8251]], device='cuda:0')\n",
            "GT bboxes: tensor([[656.5079, 609.5238, 694.6032, 647.6191],\n",
            "        [184.1270,  68.5714, 222.2222, 106.6667]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8787],\n",
            "        [ 4.1935],\n",
            "        [-1.8495],\n",
            "        [-1.9687],\n",
            "        [ 2.7065]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[102.7787,  97.3440, 141.7602, 135.9779],\n",
            "        [216.0627,   9.7041, 255.9728,  46.7671],\n",
            "        [102.5795,  97.4993, 141.4774, 136.1797],\n",
            "        [104.1953,  97.6068, 142.5436, 136.0530],\n",
            "        [124.7358,   1.8433, 162.8903,  39.8816]], device='cuda:0')\n",
            "GT bboxes: tensor([[104.1270,  97.7778, 142.2222, 135.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2924,  7.0577],\n",
            "        [ 7.2484,  9.8248],\n",
            "        [ 7.2487,  9.8456],\n",
            "        [14.6097, -1.7471],\n",
            "        [ 4.3320, 11.8326]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[221.3681, 451.7761, 260.8422, 491.5902],\n",
            "        [248.0473, 638.4094, 287.6193, 677.0942],\n",
            "        [249.2003, 638.9894, 288.2052, 677.6116],\n",
            "        [185.3919,  67.9816, 224.0736, 105.3164],\n",
            "        [429.7644, 613.5497, 468.5533, 650.9354]], device='cuda:0')\n",
            "GT bboxes: tensor([[656.5079, 609.5238, 694.6032, 647.6191],\n",
            "        [184.1270,  68.5714, 222.2222, 106.6667]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8895],\n",
            "        [ 4.2006],\n",
            "        [-1.8668],\n",
            "        [-1.9781],\n",
            "        [ 2.7164]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[102.9573,  97.7879, 141.5334, 135.6176],\n",
            "        [216.1208,   9.7541, 256.0077,  46.5638],\n",
            "        [102.7604,  97.9059, 141.2586, 135.7842],\n",
            "        [104.2277,  97.9824, 142.1587, 135.6901],\n",
            "        [124.8053,   2.0722, 162.6072,  39.3496]], device='cuda:0')\n",
            "GT bboxes: tensor([[104.1270,  97.7778, 142.2222, 135.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2938,  7.0594],\n",
            "        [ 7.2449,  9.8199],\n",
            "        [ 7.2450,  9.8381],\n",
            "        [14.6115, -1.7602],\n",
            "        [ 4.3289, 11.8256]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[221.6343, 451.8704, 260.7423, 491.2354],\n",
            "        [248.2392, 638.5170, 287.3814, 677.1217],\n",
            "        [249.1645, 638.9832, 287.9649, 677.5076],\n",
            "        [185.3273,  68.2570, 223.7800, 104.9466],\n",
            "        [429.8892, 613.6684, 468.3195, 650.8647]], device='cuda:0')\n",
            "GT bboxes: tensor([[656.5079, 609.5238, 694.6032, 647.6191],\n",
            "        [184.1270,  68.5714, 222.2222, 106.6667]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8894],\n",
            "        [ 4.1992],\n",
            "        [-1.8658],\n",
            "        [-1.9581],\n",
            "        [ 2.7118]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[103.1628,  97.7571, 141.4343, 135.4481],\n",
            "        [216.3786,   9.8151, 255.9093,  46.4080],\n",
            "        [102.9742,  97.8502, 141.1619, 135.5258],\n",
            "        [104.3415,  97.9153, 142.0469, 135.4348],\n",
            "        [124.8715,   2.3388, 162.5819,  39.2300]], device='cuda:0')\n",
            "GT bboxes: tensor([[104.1270,  97.7778, 142.2222, 135.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2994,  7.0641],\n",
            "        [ 7.2485,  9.8249],\n",
            "        [ 7.2466,  9.8395],\n",
            "        [14.6194, -1.7542],\n",
            "        [ 4.3313, 11.8302]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[221.6068, 451.8950, 260.8638, 491.1153],\n",
            "        [248.3061, 638.5192, 287.4301, 677.0475],\n",
            "        [249.0506, 638.8724, 288.0257, 677.4277],\n",
            "        [185.4907,  68.3694, 223.6550, 104.9039],\n",
            "        [430.0336, 613.7873, 468.3635, 650.7031]], device='cuda:0')\n",
            "GT bboxes: tensor([[656.5079, 609.5238, 694.6032, 647.6191],\n",
            "        [184.1270,  68.5714, 222.2222, 106.6667]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8832],\n",
            "        [ 4.1983],\n",
            "        [-1.8580],\n",
            "        [-1.9491],\n",
            "        [ 2.7098]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[103.1969,  97.9005, 141.4602, 135.3146],\n",
            "        [216.2950,   9.8143, 256.0099,  46.4007],\n",
            "        [102.9497,  98.0170, 141.2468, 135.4167],\n",
            "        [104.2435,  98.0716, 141.9620, 135.3521],\n",
            "        [124.8781,   2.3874, 162.6050,  39.2099]], device='cuda:0')\n",
            "GT bboxes: tensor([[104.1270,  97.7778, 142.2222, 135.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2908,  7.0556],\n",
            "        [ 7.2423,  9.8208],\n",
            "        [ 7.2402,  9.8357],\n",
            "        [14.6178, -1.7650],\n",
            "        [ 4.3289, 11.8288]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[221.7193, 451.8315, 260.7796, 491.1160],\n",
            "        [248.2233, 638.5507, 287.6410, 677.0611],\n",
            "        [249.0820, 638.9332, 288.1783, 677.3644],\n",
            "        [185.3491,  68.2616, 223.4884, 104.8313],\n",
            "        [430.0713, 613.8152, 468.4055, 650.6885]], device='cuda:0')\n",
            "GT bboxes: tensor([[656.5079, 609.5238, 694.6032, 647.6191],\n",
            "        [184.1270,  68.5714, 222.2222, 106.6667]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8737],\n",
            "        [ 4.2028],\n",
            "        [-1.8485],\n",
            "        [-1.9355],\n",
            "        [ 2.7169]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[103.2168,  97.8960, 141.4448, 135.2514],\n",
            "        [216.3784,   9.8430, 255.9681,  46.3617],\n",
            "        [103.0259,  97.9911, 141.1679, 135.3438],\n",
            "        [104.2739,  98.0477, 141.9094, 135.2861],\n",
            "        [124.9061,   2.3831, 162.5951,  39.1952]], device='cuda:0')\n",
            "GT bboxes: tensor([[104.1270,  97.7778, 142.2222, 135.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2992,  7.0635],\n",
            "        [ 7.2495,  9.8273],\n",
            "        [ 7.2462,  9.8423],\n",
            "        [14.6230, -1.7446],\n",
            "        [ 4.3343, 11.8340]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[221.7404, 451.8812, 260.7696, 491.0456],\n",
            "        [248.2636, 638.5977, 287.5754, 677.0425],\n",
            "        [249.1923, 638.9735, 288.1393, 677.3229],\n",
            "        [185.3855,  68.1964, 223.4979, 104.6317],\n",
            "        [430.0928, 613.8510, 468.3927, 650.6720]], device='cuda:0')\n",
            "GT bboxes: tensor([[656.5079, 609.5238, 694.6032, 647.6191],\n",
            "        [184.1270,  68.5714, 222.2222, 106.6667]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8921],\n",
            "        [ 4.2028],\n",
            "        [-1.8048],\n",
            "        [-1.7837],\n",
            "        [ 2.7258]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[103.1743,  97.5166, 141.7491, 135.5635],\n",
            "        [216.0902,   8.7824, 255.2437,  46.4072],\n",
            "        [102.5233,  98.4179, 141.2238, 136.2563],\n",
            "        [105.6685,  98.5766, 143.6821, 136.0498],\n",
            "        [124.8937,   0.9578, 163.5752,  39.7114]], device='cuda:0')\n",
            "GT bboxes: tensor([[104.1270,  97.7778, 142.2222, 135.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2902,  7.0662],\n",
            "        [ 7.2593,  9.8200],\n",
            "        [ 7.2627,  9.8757],\n",
            "        [14.6004, -1.6914],\n",
            "        [ 4.3397, 11.8340]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[221.7522, 452.4514, 260.5693, 491.5640],\n",
            "        [247.9088, 638.5042, 286.6851, 677.1978],\n",
            "        [250.4579, 640.1340, 288.5196, 678.7793],\n",
            "        [186.2909,  68.0262, 224.6480, 105.7174],\n",
            "        [429.7245, 613.7435, 468.2766, 650.8333]], device='cuda:0')\n",
            "GT bboxes: tensor([[656.5079, 609.5238, 694.6032, 647.6191],\n",
            "        [184.1270,  68.5714, 222.2222, 106.6667]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 70\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_53_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f376400a470>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[720.0000, 261.5873, 758.0952, 299.6826]], device='cuda:0')\n",
            "            labels: tensor([2], device='cuda:0')\n",
            "        ) at 0x7f3761b9fdc0>\n",
            ") at 0x7f37611e3a90>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 106\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_116_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9d3f0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[304.7619, 640.0000, 342.8571, 678.0953]], device='cuda:0')\n",
            "            labels: tensor([3], device='cuda:0')\n",
            "        ) at 0x7f3761b9dde0>\n",
            ") at 0x7f376400a3e0>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7180],\n",
            "        [-1.7511],\n",
            "        [ 8.7399],\n",
            "        [11.3082],\n",
            "        [ 8.7143]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[430.1257,   3.7813, 468.2837,  42.4333],\n",
            "        [720.9854, 261.8514, 759.0146, 297.0912],\n",
            "        [430.1394,   2.5439, 467.7526,  40.7349],\n",
            "        [ 17.3035, 212.3190,  54.0151, 248.4005],\n",
            "        [429.8894,   4.4012, 468.0191,  43.6115]], device='cuda:0')\n",
            "GT bboxes: tensor([[720.0000, 261.5873, 758.0952, 299.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7691],\n",
            "        [ 3.4903],\n",
            "        [-1.7548],\n",
            "        [-1.8268],\n",
            "        [ 4.0258]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[304.4470, 638.2876, 342.5740, 676.1920],\n",
            "        [157.0351, 622.9083, 195.7697, 660.2209],\n",
            "        [305.9896, 638.1472, 343.3347, 677.1355],\n",
            "        [304.1761, 638.4113, 342.3102, 677.6104],\n",
            "        [426.8894, 709.7159, 464.7391, 745.4167]], device='cuda:0')\n",
            "GT bboxes: tensor([[304.7619, 640.0000, 342.8571, 678.0953]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7432],\n",
            "        [-1.8020],\n",
            "        [ 8.7521],\n",
            "        [11.3082],\n",
            "        [ 8.7410]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[430.2153,   4.3464, 468.3034,  42.2641],\n",
            "        [720.7873, 261.6477, 759.2996, 297.8277],\n",
            "        [430.5584,   3.5231, 467.8376,  41.0714],\n",
            "        [ 17.3318, 212.4009,  53.9811, 248.7319],\n",
            "        [429.9457,   4.6186, 467.9743,  43.1987]], device='cuda:0')\n",
            "GT bboxes: tensor([[720.0000, 261.5873, 758.0952, 299.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8063],\n",
            "        [ 3.4787],\n",
            "        [-1.7940],\n",
            "        [-1.8667],\n",
            "        [ 4.0184]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[304.8513, 638.2954, 342.5747, 676.5386],\n",
            "        [156.8475, 622.9651, 195.7634, 660.5557],\n",
            "        [305.9565, 638.3504, 343.0707, 677.2979],\n",
            "        [304.7397, 638.4022, 342.4223, 677.6171],\n",
            "        [426.8412, 709.5776, 464.6623, 745.9753]], device='cuda:0')\n",
            "GT bboxes: tensor([[304.7619, 640.0000, 342.8571, 678.0953]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7313],\n",
            "        [-1.7927],\n",
            "        [ 8.7389],\n",
            "        [11.3061],\n",
            "        [ 8.7265]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[430.2118,   4.3898, 468.2406,  42.3476],\n",
            "        [720.9274, 261.4485, 759.2524, 297.8795],\n",
            "        [430.6159,   3.8181, 467.6031,  41.4795],\n",
            "        [ 17.4025, 212.2233,  53.8834, 248.7657],\n",
            "        [430.0485,   4.6582, 468.0140,  43.0600]], device='cuda:0')\n",
            "GT bboxes: tensor([[720.0000, 261.5873, 758.0952, 299.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7910],\n",
            "        [ 3.4748],\n",
            "        [-1.8064],\n",
            "        [-1.8478],\n",
            "        [ 4.0206]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[305.0203, 638.3967, 342.3132, 676.5557],\n",
            "        [157.0032, 623.1835, 195.5125, 660.5848],\n",
            "        [305.9400, 638.5639, 342.9434, 677.1400],\n",
            "        [304.9092, 638.5994, 342.2051, 677.3690],\n",
            "        [426.9608, 709.8010, 464.7829, 745.8696]], device='cuda:0')\n",
            "GT bboxes: tensor([[304.7619, 640.0000, 342.8571, 678.0953]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7344],\n",
            "        [-1.7934],\n",
            "        [ 8.7357],\n",
            "        [11.2968],\n",
            "        [ 8.7299]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[430.4118,   4.4015, 468.2265,  42.3571],\n",
            "        [720.8691, 261.6145, 759.3203, 297.7048],\n",
            "        [430.5984,   3.8661, 467.7854,  41.5251],\n",
            "        [ 17.5414, 212.2866,  53.7759, 248.6371],\n",
            "        [430.2280,   4.6570, 467.9696,  43.0351]], device='cuda:0')\n",
            "GT bboxes: tensor([[720.0000, 261.5873, 758.0952, 299.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7979],\n",
            "        [ 3.4795],\n",
            "        [-1.8086],\n",
            "        [-1.8465],\n",
            "        [ 4.0171]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[305.0840, 638.4846, 342.3688, 676.6158],\n",
            "        [157.0998, 623.0820, 195.5577, 660.4700],\n",
            "        [305.9400, 638.6866, 342.9279, 677.0572],\n",
            "        [304.9901, 638.7393, 342.2448, 677.2765],\n",
            "        [427.0939, 709.8220, 464.7685, 745.8347]], device='cuda:0')\n",
            "GT bboxes: tensor([[304.7619, 640.0000, 342.8571, 678.0953]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7229],\n",
            "        [-1.7832],\n",
            "        [ 8.7298],\n",
            "        [11.3055],\n",
            "        [ 8.7184]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[430.4272,   4.4253, 468.2888,  42.3483],\n",
            "        [721.0338, 261.6379, 759.1829, 297.5935],\n",
            "        [430.5859,   3.9005, 467.9523,  41.5314],\n",
            "        [ 17.6885, 212.4258,  53.5955, 248.5212],\n",
            "        [430.2790,   4.6846, 468.1415,  42.9985]], device='cuda:0')\n",
            "GT bboxes: tensor([[720.0000, 261.5873, 758.0952, 299.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8037],\n",
            "        [ 3.4746],\n",
            "        [-1.8132],\n",
            "        [-1.8554],\n",
            "        [ 4.0227]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[305.1407, 638.5894, 342.3947, 676.6180],\n",
            "        [157.1073, 623.1771, 195.6023, 660.4133],\n",
            "        [305.9987, 638.7729, 342.9115, 677.0628],\n",
            "        [305.0311, 638.8237, 342.3203, 677.2869],\n",
            "        [427.1561, 709.8359, 464.7967, 745.8599]], device='cuda:0')\n",
            "GT bboxes: tensor([[304.7619, 640.0000, 342.8571, 678.0953]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7307],\n",
            "        [-1.7792],\n",
            "        [ 8.7390],\n",
            "        [11.3093],\n",
            "        [ 8.7261]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[430.4660,   4.4515, 468.2764,  42.3281],\n",
            "        [721.0292, 261.6606, 759.1837, 297.6386],\n",
            "        [430.6114,   3.9366, 467.9383,  41.5075],\n",
            "        [ 17.6837, 212.4632,  53.6174, 248.5259],\n",
            "        [430.3115,   4.7153, 468.1167,  42.9744]], device='cuda:0')\n",
            "GT bboxes: tensor([[720.0000, 261.5873, 758.0952, 299.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7984],\n",
            "        [ 3.4818],\n",
            "        [-1.8042],\n",
            "        [-1.8453],\n",
            "        [ 4.0288]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[305.1606, 638.6031, 342.3809, 676.6295],\n",
            "        [157.1521, 623.1526, 195.5678, 660.3619],\n",
            "        [306.0687, 638.7985, 342.9352, 677.0581],\n",
            "        [305.0629, 638.8324, 342.2547, 677.2809],\n",
            "        [427.1729, 709.8895, 464.7825, 745.8178]], device='cuda:0')\n",
            "GT bboxes: tensor([[304.7619, 640.0000, 342.8571, 678.0953]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7249],\n",
            "        [-1.8407],\n",
            "        [ 8.7766],\n",
            "        [11.2927],\n",
            "        [ 8.7217]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[4.3034e+02, 3.5390e+00, 4.6829e+02, 4.2366e+01],\n",
            "        [7.2062e+02, 2.6167e+02, 7.5902e+02, 2.9803e+02],\n",
            "        [4.2955e+02, 6.0882e-01, 4.6725e+02, 3.9108e+01],\n",
            "        [1.6210e+01, 2.1178e+02, 5.4642e+01, 2.5004e+02],\n",
            "        [4.2942e+02, 5.1517e+00, 4.6765e+02, 4.4643e+01]], device='cuda:0')\n",
            "GT bboxes: tensor([[720.0000, 261.5873, 758.0952, 299.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7062],\n",
            "        [ 3.4809],\n",
            "        [-1.7418],\n",
            "        [-1.7635],\n",
            "        [ 4.0094]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[303.9861, 638.2202, 342.1538, 675.9333],\n",
            "        [157.3726, 623.2310, 195.8423, 660.4748],\n",
            "        [306.2666, 638.1736, 343.5497, 677.3513],\n",
            "        [303.4971, 638.7039, 341.7999, 678.9225],\n",
            "        [426.3419, 708.8136, 464.6834, 745.8912]], device='cuda:0')\n",
            "GT bboxes: tensor([[304.7619, 640.0000, 342.8571, 678.0953]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 76\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_79_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9c5e0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[599.3651, 107.9365, 637.4603, 146.0318],\n",
            "                        [520.6349, 478.7302, 558.7302, 516.8254],\n",
            "                        [492.6984, 408.8889, 530.7936, 446.9841],\n",
            "                        [427.9365, 481.2699, 466.0317, 519.3651],\n",
            "                        [582.8571, 577.7778, 620.9524, 615.8730]], device='cuda:0')\n",
            "            labels: tensor([1, 2, 4, 4, 5], device='cuda:0')\n",
            "        ) at 0x7f3761b9dbd0>\n",
            ") at 0x7f376400baf0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 67\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_68_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9d4e0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[722.5397, 623.4921, 760.6349, 661.5873],\n",
            "                        [ 52.0635, 690.7937,  90.1587, 728.8889],\n",
            "                        [218.4127, 429.2064, 256.5079, 467.3016]], device='cuda:0')\n",
            "            labels: tensor([0, 0, 3], device='cuda:0')\n",
            "        ) at 0x7f3761b9ddb0>\n",
            ") at 0x7f376400a470>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.5059,  2.2438,  2.7403,  2.9470,  2.3563],\n",
            "        [ 6.9317,  2.4251, -1.7745,  3.2217,  5.0397],\n",
            "        [ 8.5231,  2.2787,  2.7447,  2.9633,  2.3645],\n",
            "        [ 6.9404,  2.4332, -1.7812,  3.2105,  5.0438],\n",
            "        [ 8.5340,  2.2949,  2.7837,  2.9948,  2.3620]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[493.1527, 564.7333, 532.4957, 603.2861],\n",
            "        [492.9586, 406.7167, 530.8485, 445.0901],\n",
            "        [492.7383, 564.9686, 531.5965, 603.5724],\n",
            "        [492.4048, 407.0891, 530.4739, 445.1567],\n",
            "        [493.3455, 565.5004, 531.7072, 603.1541]], device='cuda:0')\n",
            "GT bboxes: tensor([[599.3651, 107.9365, 637.4603, 146.0318],\n",
            "        [520.6349, 478.7302, 558.7302, 516.8254],\n",
            "        [492.6984, 408.8889, 530.7936, 446.9841],\n",
            "        [427.9365, 481.2699, 466.0317, 519.3651],\n",
            "        [582.8571, 577.7778, 620.9524, 615.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[11.1297, -1.7411,  6.8053],\n",
            "        [11.1385, -1.9068,  6.8329],\n",
            "        [11.1370, -1.8291,  6.8676],\n",
            "        [11.1167, -1.8086,  6.8679],\n",
            "        [-1.8439, 11.1284, 10.2246]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 53.8685, 692.2335,  90.5871, 727.8990],\n",
            "        [ 52.0678, 691.1898,  89.7142, 728.0175],\n",
            "        [ 52.6644, 691.9590,  89.8681, 727.8438],\n",
            "        [ 53.6245, 691.0294,  91.0454, 728.0413],\n",
            "        [721.6587, 623.5467, 759.3579, 660.9443]], device='cuda:0')\n",
            "GT bboxes: tensor([[722.5397, 623.4921, 760.6349, 661.5873],\n",
            "        [ 52.0635, 690.7937,  90.1587, 728.8889],\n",
            "        [218.4127, 429.2064, 256.5079, 467.3016]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.5391,  2.2631,  2.7459,  2.9588,  2.3570],\n",
            "        [ 6.9361,  2.4205, -1.8166,  3.2132,  5.0396],\n",
            "        [ 8.5584,  2.2991,  2.7534,  2.9703,  2.3702],\n",
            "        [ 6.9417,  2.4321, -1.7831,  3.2118,  5.0448],\n",
            "        [ 8.5572,  2.3047,  2.7696,  2.9861,  2.3746]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[492.8542, 564.9482, 532.1086, 603.6797],\n",
            "        [492.7501, 406.8715, 530.7803, 445.4597],\n",
            "        [492.5848, 565.1755, 531.4012, 603.5616],\n",
            "        [492.4326, 406.9480, 530.5031, 445.3015],\n",
            "        [493.1968, 565.4686, 531.3079, 603.1931]], device='cuda:0')\n",
            "GT bboxes: tensor([[599.3651, 107.9365, 637.4603, 146.0318],\n",
            "        [520.6349, 478.7302, 558.7302, 516.8254],\n",
            "        [492.6984, 408.8889, 530.7936, 446.9841],\n",
            "        [427.9365, 481.2699, 466.0317, 519.3651],\n",
            "        [582.8571, 577.7778, 620.9524, 615.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[11.1368, -1.7870,  6.8246],\n",
            "        [11.1439, -1.8813,  6.8449],\n",
            "        [11.1453, -1.8056,  6.8521],\n",
            "        [11.1313, -1.8058,  6.8439],\n",
            "        [-1.8496, 11.1265, 10.2757]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 53.6727, 692.1767,  90.3799, 728.3154],\n",
            "        [ 52.3968, 691.5199,  89.6795, 728.3123],\n",
            "        [ 52.9424, 692.1414,  89.6211, 728.2073],\n",
            "        [ 53.6662, 691.5982,  90.5919, 728.2750],\n",
            "        [721.2401, 623.4833, 759.5865, 661.1949]], device='cuda:0')\n",
            "GT bboxes: tensor([[722.5397, 623.4921, 760.6349, 661.5873],\n",
            "        [ 52.0635, 690.7937,  90.1587, 728.8889],\n",
            "        [218.4127, 429.2064, 256.5079, 467.3016]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.5456,  2.2816,  2.7649,  2.9789,  2.3649],\n",
            "        [ 6.9329,  2.4305, -1.7566,  3.2204,  5.0458],\n",
            "        [ 8.5462,  2.2934,  2.7572,  2.9727,  2.3746],\n",
            "        [ 6.9349,  2.4362, -1.7554,  3.2187,  5.0489],\n",
            "        [ 8.5466,  2.2996,  2.7677,  2.9862,  2.3778]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[492.6264, 564.8534, 531.9034, 603.6334],\n",
            "        [493.0270, 406.8161, 530.4630, 444.9870],\n",
            "        [492.5209, 565.1210, 531.3595, 603.4809],\n",
            "        [492.8224, 406.8352, 530.3264, 444.8871],\n",
            "        [493.0432, 565.3895, 531.2263, 603.2228]], device='cuda:0')\n",
            "GT bboxes: tensor([[599.3651, 107.9365, 637.4603, 146.0318],\n",
            "        [520.6349, 478.7302, 558.7302, 516.8254],\n",
            "        [492.6984, 408.8889, 530.7936, 446.9841],\n",
            "        [427.9365, 481.2699, 466.0317, 519.3651],\n",
            "        [582.8571, 577.7778, 620.9524, 615.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[11.1368, -1.7986,  6.8457],\n",
            "        [11.1462, -1.8739,  6.8348],\n",
            "        [11.1463, -1.8018,  6.8311],\n",
            "        [11.1346, -1.8278,  6.8320],\n",
            "        [-1.8553, 11.1262, 10.2564]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 53.5643, 692.1302,  90.3125, 728.2914],\n",
            "        [ 52.3538, 691.7233,  89.6548, 728.3708],\n",
            "        [ 52.9578, 692.1900,  89.5815, 728.2468],\n",
            "        [ 53.4855, 691.7043,  90.5067, 728.5035],\n",
            "        [721.3065, 623.3788, 759.4753, 661.4702]], device='cuda:0')\n",
            "GT bboxes: tensor([[722.5397, 623.4921, 760.6349, 661.5873],\n",
            "        [ 52.0635, 690.7937,  90.1587, 728.8889],\n",
            "        [218.4127, 429.2064, 256.5079, 467.3016]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.5498,  2.2917,  2.7711,  2.9881,  2.3706],\n",
            "        [ 6.9291,  2.4301, -1.7521,  3.2222,  5.0466],\n",
            "        [ 8.5586,  2.3086,  2.7712,  2.9912,  2.3788],\n",
            "        [ 6.9316,  2.4356, -1.7519,  3.2203,  5.0494],\n",
            "        [ 8.5555,  2.3105,  2.7802,  2.9986,  2.3814]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[492.7701, 564.8741, 531.7212, 603.4644],\n",
            "        [492.9882, 406.6286, 530.6186, 444.8784],\n",
            "        [492.6678, 565.1717, 531.2425, 603.2924],\n",
            "        [492.7962, 406.6697, 530.4686, 444.8046],\n",
            "        [493.1505, 565.5035, 531.0988, 603.0301]], device='cuda:0')\n",
            "GT bboxes: tensor([[599.3651, 107.9365, 637.4603, 146.0318],\n",
            "        [520.6349, 478.7302, 558.7302, 516.8254],\n",
            "        [492.6984, 408.8889, 530.7936, 446.9841],\n",
            "        [427.9365, 481.2699, 466.0317, 519.3651],\n",
            "        [582.8571, 577.7778, 620.9524, 615.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[11.1381, -1.7790,  6.8369],\n",
            "        [11.1464, -1.8384,  6.8517],\n",
            "        [11.1467, -1.7679,  6.8466],\n",
            "        [11.1366, -1.8252,  6.8490],\n",
            "        [-1.8599, 11.1273, 10.2713]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 53.8274, 692.1359,  90.0595, 728.1886],\n",
            "        [ 52.6609, 691.8109,  89.5082, 728.2975],\n",
            "        [ 53.2346, 692.2431,  89.3801, 728.1802],\n",
            "        [ 53.5021, 691.8127,  90.3321, 728.4209],\n",
            "        [721.4302, 623.4494, 759.4553, 661.3886]], device='cuda:0')\n",
            "GT bboxes: tensor([[722.5397, 623.4921, 760.6349, 661.5873],\n",
            "        [ 52.0635, 690.7937,  90.1587, 728.8889],\n",
            "        [218.4127, 429.2064, 256.5079, 467.3016]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.5608,  2.3020,  2.7723,  2.9891,  2.3705],\n",
            "        [ 6.9251,  2.4273, -1.7441,  3.2203,  5.0465],\n",
            "        [ 8.5679,  2.3170,  2.7710,  2.9916,  2.3786],\n",
            "        [ 6.9277,  2.4331, -1.7411,  3.2184,  5.0495],\n",
            "        [ 8.5686,  2.3228,  2.7831,  3.0015,  2.3812]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[492.8138, 564.8546, 531.7202, 603.4266],\n",
            "        [493.1052, 406.6032, 530.5886, 444.8250],\n",
            "        [492.7509, 565.1527, 531.2460, 603.2618],\n",
            "        [492.9494, 406.6850, 530.3956, 444.7334],\n",
            "        [493.1896, 565.5126, 531.0679, 603.0112]], device='cuda:0')\n",
            "GT bboxes: tensor([[599.3651, 107.9365, 637.4603, 146.0318],\n",
            "        [520.6349, 478.7302, 558.7302, 516.8254],\n",
            "        [492.6984, 408.8889, 530.7936, 446.9841],\n",
            "        [427.9365, 481.2699, 466.0317, 519.3651],\n",
            "        [582.8571, 577.7778, 620.9524, 615.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[11.1382, -1.7782,  6.8437],\n",
            "        [11.1470, -1.8204,  6.8614],\n",
            "        [11.1472, -1.7575,  6.8603],\n",
            "        [11.1374, -1.8284,  6.8579],\n",
            "        [-1.8537, 11.1274, 10.2648]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 53.8122, 692.0900,  89.9973, 728.1745],\n",
            "        [ 52.7944, 691.8554,  89.3924, 728.2773],\n",
            "        [ 53.2942, 692.2656,  89.2883, 728.1685],\n",
            "        [ 53.5615, 691.8314,  90.1957, 728.4247],\n",
            "        [721.3790, 623.4922, 759.3954, 661.3588]], device='cuda:0')\n",
            "GT bboxes: tensor([[722.5397, 623.4921, 760.6349, 661.5873],\n",
            "        [ 52.0635, 690.7937,  90.1587, 728.8889],\n",
            "        [218.4127, 429.2064, 256.5079, 467.3016]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.5442,  2.2891,  2.7661,  2.9828,  2.3618],\n",
            "        [ 6.9324,  2.4357, -1.7341,  3.2287,  5.0444],\n",
            "        [ 8.5521,  2.3050,  2.7645,  2.9853,  2.3706],\n",
            "        [ 6.9347,  2.4410, -1.7334,  3.2265,  5.0472],\n",
            "        [ 8.5533,  2.3106,  2.7787,  2.9964,  2.3726]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[492.8573, 564.8645, 531.7266, 603.4691],\n",
            "        [493.1152, 406.6477, 530.5682, 444.7748],\n",
            "        [492.7715, 565.1693, 531.2314, 603.2952],\n",
            "        [492.9431, 406.7242, 530.4019, 444.6862],\n",
            "        [493.2355, 565.5496, 531.1018, 603.0229]], device='cuda:0')\n",
            "GT bboxes: tensor([[599.3651, 107.9365, 637.4603, 146.0318],\n",
            "        [520.6349, 478.7302, 558.7302, 516.8254],\n",
            "        [492.6984, 408.8889, 530.7936, 446.9841],\n",
            "        [427.9365, 481.2699, 466.0317, 519.3651],\n",
            "        [582.8571, 577.7778, 620.9524, 615.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[11.1341, -1.7786,  6.8280],\n",
            "        [11.1431, -1.8229,  6.8446],\n",
            "        [11.1432, -1.7591,  6.8446],\n",
            "        [11.1335, -1.8290,  6.8394],\n",
            "        [-1.8574, 11.1227, 10.2685]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 53.8244, 692.0903,  89.9924, 728.1322],\n",
            "        [ 52.7880, 691.8683,  89.3922, 728.2609],\n",
            "        [ 53.3108, 692.2910,  89.3161, 728.1447],\n",
            "        [ 53.5760, 691.8448,  90.2061, 728.4065],\n",
            "        [721.4090, 623.5139, 759.3893, 661.3370]], device='cuda:0')\n",
            "GT bboxes: tensor([[722.5397, 623.4921, 760.6349, 661.5873],\n",
            "        [ 52.0635, 690.7937,  90.1587, 728.8889],\n",
            "        [218.4127, 429.2064, 256.5079, 467.3016]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.5601,  2.2987,  2.8212,  3.0255,  2.3368],\n",
            "        [ 6.9392,  2.4101, -1.8236,  3.2158,  5.0284],\n",
            "        [ 8.5833,  2.3409,  2.8002,  3.0198,  2.3492],\n",
            "        [ 6.9518,  2.4323, -1.8079,  3.1985,  5.0401],\n",
            "        [ 8.5925,  2.3429,  2.8284,  3.0382,  2.3444]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[493.6878, 564.8714, 532.7065, 603.9378],\n",
            "        [493.0500, 407.3640, 531.0814, 445.7368],\n",
            "        [492.5805, 565.4664, 531.3223, 604.3507],\n",
            "        [491.9746, 407.8707, 530.3492, 445.4596],\n",
            "        [493.6290, 566.2698, 531.6429, 603.7352]], device='cuda:0')\n",
            "GT bboxes: tensor([[599.3651, 107.9365, 637.4603, 146.0318],\n",
            "        [520.6349, 478.7302, 558.7302, 516.8254],\n",
            "        [492.6984, 408.8889, 530.7936, 446.9841],\n",
            "        [427.9365, 481.2699, 466.0317, 519.3651],\n",
            "        [582.8571, 577.7778, 620.9524, 615.8730]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[11.1264, -1.7539,  6.8468],\n",
            "        [11.1376, -1.8736,  6.8633],\n",
            "        [11.1446, -1.9277,  6.8682],\n",
            "        [11.1176, -1.8346,  6.8514],\n",
            "        [-1.8267, 11.1202, 10.2598]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 53.7952, 692.1312,  91.4578, 728.7409],\n",
            "        [ 50.8566, 690.4298,  89.9552, 728.2892],\n",
            "        [ 51.9968, 692.0252,  90.1152, 728.8401],\n",
            "        [ 53.3326, 690.5773,  91.6492, 728.9839],\n",
            "        [721.1760, 623.9935, 759.6747, 661.1894]], device='cuda:0')\n",
            "GT bboxes: tensor([[722.5397, 623.4921, 760.6349, 661.5873],\n",
            "        [ 52.0635, 690.7937,  90.1587, 728.8889],\n",
            "        [218.4127, 429.2064, 256.5079, 467.3016]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 84\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_91_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9cc40>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[ 97.7778, 553.6508, 135.8730, 591.7460],\n",
            "                        [ 48.2540, 158.7302,  86.3492, 196.8254]], device='cuda:0')\n",
            "            labels: tensor([0, 3], device='cuda:0')\n",
            "        ) at 0x7f3761b9e6e0>\n",
            ") at 0x7f3761b9edd0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 26\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_42_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9ee60>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[698.4127, 560.0000, 736.5079, 598.0953],\n",
            "                        [111.7460, 558.7302, 149.8412, 596.8254],\n",
            "                        [449.5238, 171.4286, 487.6190, 209.5238]], device='cuda:0')\n",
            "            labels: tensor([0, 3, 4], device='cuda:0')\n",
            "        ) at 0x7f3761b9c6d0>\n",
            ") at 0x7f3761b9f1c0>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.3828, -1.8428],\n",
            "        [-1.4794,  7.0358],\n",
            "        [ 7.3753, -1.7938],\n",
            "        [-1.5953,  7.0381],\n",
            "        [-1.3670,  7.0717]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 47.7553, 159.2261,  87.2539, 197.8330],\n",
            "        [101.4733, 553.4493, 141.1009, 590.7444],\n",
            "        [ 47.8590, 159.7353,  87.1702, 198.4235],\n",
            "        [100.3404, 553.1196, 140.0328, 591.2719],\n",
            "        [101.9681, 552.1638, 141.7872, 590.7114]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 97.7778, 553.6508, 135.8730, 591.7460],\n",
            "        [ 48.2540, 158.7302,  86.3492, 196.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1340, -1.7211, 11.0350],\n",
            "        [13.4762,  6.6326,  5.9419],\n",
            "        [-1.4848,  8.7939,  9.5711],\n",
            "        [ 9.1315, -1.7333, 11.0353],\n",
            "        [13.4834,  6.6243,  5.9495]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[110.4833, 559.5309, 148.2695, 595.3779],\n",
            "        [139.5776, 198.4582, 177.9977, 235.8310],\n",
            "        [699.1138, 562.1381, 737.5223, 604.5478],\n",
            "        [110.4965, 559.5020, 148.1194, 595.6694],\n",
            "        [139.3064, 198.3820, 177.1736, 235.8323]], device='cuda:0')\n",
            "GT bboxes: tensor([[698.4127, 560.0000, 736.5079, 598.0953],\n",
            "        [111.7460, 558.7302, 149.8412, 596.8254],\n",
            "        [449.5238, 171.4286, 487.6190, 209.5238]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.3816, -1.8471],\n",
            "        [-1.4971,  7.0472],\n",
            "        [ 7.3784, -1.8240],\n",
            "        [-1.5967,  7.0489],\n",
            "        [-1.4021,  7.0640]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 47.7908, 158.9781,  87.4131, 198.0822],\n",
            "        [101.3243, 553.4675, 141.3249, 591.1553],\n",
            "        [ 47.8342, 159.1541,  87.3689, 198.3969],\n",
            "        [100.4002, 553.4033, 140.3645, 591.4150],\n",
            "        [101.8605, 552.6083, 141.8112, 590.9938]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 97.7778, 553.6508, 135.8730, 591.7460],\n",
            "        [ 48.2540, 158.7302,  86.3492, 196.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1342, -1.7348, 11.0358],\n",
            "        [13.4727,  6.6205,  5.9355],\n",
            "        [-1.4874,  8.7814,  9.5539],\n",
            "        [ 9.1358, -1.7395, 11.0345],\n",
            "        [13.4780,  6.6190,  5.9399]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[110.7589, 559.5972, 147.9599, 595.7064],\n",
            "        [139.6764, 198.7569, 177.9536, 235.9493],\n",
            "        [698.8993, 562.0342, 737.5712, 604.7699],\n",
            "        [110.7486, 559.4467, 147.8606, 595.7315],\n",
            "        [139.6846, 198.7121, 177.3389, 235.7397]], device='cuda:0')\n",
            "GT bboxes: tensor([[698.4127, 560.0000, 736.5079, 598.0953],\n",
            "        [111.7460, 558.7302, 149.8412, 596.8254],\n",
            "        [449.5238, 171.4286, 487.6190, 209.5238]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.3827, -1.8534],\n",
            "        [-1.5190,  7.0469],\n",
            "        [ 7.3800, -1.8370],\n",
            "        [-1.6105,  7.0282],\n",
            "        [-1.4381,  7.0458]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 47.8614, 159.0452,  87.3753, 197.9581],\n",
            "        [101.0947, 553.4333, 141.4085, 591.4723],\n",
            "        [ 47.9121, 159.1362,  87.3709, 198.2144],\n",
            "        [100.2086, 553.4394, 140.5296, 591.6105],\n",
            "        [101.4809, 552.7983, 142.0672, 591.3946]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 97.7778, 553.6508, 135.8730, 591.7460],\n",
            "        [ 48.2540, 158.7302,  86.3492, 196.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1353, -1.7334, 11.0296],\n",
            "        [13.4753,  6.6233,  5.9315],\n",
            "        [-1.4846,  8.8057,  9.5783],\n",
            "        [ 9.1370, -1.7304, 11.0275],\n",
            "        [13.4806,  6.6212,  5.9362]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.0329, 559.6570, 147.6217, 595.6931],\n",
            "        [139.7928, 198.4664, 178.0363, 235.9476],\n",
            "        [698.9747, 562.1198, 737.5560, 604.6698],\n",
            "        [110.9951, 559.5669, 147.5684, 595.6080],\n",
            "        [139.7444, 198.4974, 177.4536, 235.7148]], device='cuda:0')\n",
            "GT bboxes: tensor([[698.4127, 560.0000, 736.5079, 598.0953],\n",
            "        [111.7460, 558.7302, 149.8412, 596.8254],\n",
            "        [449.5238, 171.4286, 487.6190, 209.5238]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.3841, -1.8917],\n",
            "        [-1.5101,  7.0498],\n",
            "        [ 7.3817, -1.8760],\n",
            "        [-1.5981,  7.0438],\n",
            "        [-1.4494,  7.0634]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 48.0923, 159.0255,  87.2576, 197.8083],\n",
            "        [101.1337, 553.4146, 141.3579, 591.3190],\n",
            "        [ 48.1252, 159.0752,  87.2804, 198.0284],\n",
            "        [100.3058, 553.4916, 140.5744, 591.4576],\n",
            "        [101.4334, 553.0237, 141.9809, 591.2906]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 97.7778, 553.6508, 135.8730, 591.7460],\n",
            "        [ 48.2540, 158.7302,  86.3492, 196.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1357, -1.7333, 11.0235],\n",
            "        [13.4761,  6.6221,  5.9266],\n",
            "        [-1.4833,  8.8235,  9.6016],\n",
            "        [ 9.1379, -1.7280, 11.0222],\n",
            "        [13.4813,  6.6197,  5.9311]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.1069, 559.7156, 147.6533, 595.5655],\n",
            "        [139.9684, 198.5041, 177.9358, 235.7123],\n",
            "        [699.1940, 562.3371, 737.4016, 604.3199],\n",
            "        [111.0702, 559.6282, 147.6004, 595.4582],\n",
            "        [139.8850, 198.5714, 177.3868, 235.4580]], device='cuda:0')\n",
            "GT bboxes: tensor([[698.4127, 560.0000, 736.5079, 598.0953],\n",
            "        [111.7460, 558.7302, 149.8412, 596.8254],\n",
            "        [449.5238, 171.4286, 487.6190, 209.5238]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.3844, -1.8840],\n",
            "        [-1.5060,  7.0600],\n",
            "        [ 7.3818, -1.8702],\n",
            "        [-1.5940,  7.0556],\n",
            "        [-1.4543,  7.0725]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 48.0247, 159.1202,  87.3556, 197.6579],\n",
            "        [101.1216, 553.3870, 141.3734, 591.2680],\n",
            "        [ 48.0961, 159.1771,  87.3483, 197.8994],\n",
            "        [100.3515, 553.5170, 140.5816, 591.4131],\n",
            "        [101.4334, 553.0980, 141.9133, 591.2717]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 97.7778, 553.6508, 135.8730, 591.7460],\n",
            "        [ 48.2540, 158.7302,  86.3492, 196.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1355, -1.7284, 11.0245],\n",
            "        [13.4775,  6.6279,  5.9328],\n",
            "        [-1.4898,  8.8184,  9.5945],\n",
            "        [ 9.1375, -1.7245, 11.0231],\n",
            "        [13.4819,  6.6266,  5.9373]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.1810, 559.8064, 147.6408, 595.5226],\n",
            "        [139.9580, 198.6065, 177.8769, 235.5934],\n",
            "        [699.1896, 562.4227, 737.2660, 604.2018],\n",
            "        [111.1065, 559.7108, 147.6113, 595.4410],\n",
            "        [139.9428, 198.7113, 177.3705, 235.3383]], device='cuda:0')\n",
            "GT bboxes: tensor([[698.4127, 560.0000, 736.5079, 598.0953],\n",
            "        [111.7460, 558.7302, 149.8412, 596.8254],\n",
            "        [449.5238, 171.4286, 487.6190, 209.5238]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.3816, -1.8901],\n",
            "        [-1.5042,  7.0340],\n",
            "        [ 7.3789, -1.8777],\n",
            "        [-1.5968,  7.0282],\n",
            "        [-1.4537,  7.0459]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 48.0886, 159.0800,  87.2832, 197.6120],\n",
            "        [101.1916, 553.3845, 141.3779, 591.2309],\n",
            "        [ 48.1798, 159.1487,  87.2754, 197.8489],\n",
            "        [100.3526, 553.5154, 140.5452, 591.3585],\n",
            "        [101.4902, 553.1119, 141.9296, 591.2366]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 97.7778, 553.6508, 135.8730, 591.7460],\n",
            "        [ 48.2540, 158.7302,  86.3492, 196.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1334, -1.7183, 11.0339],\n",
            "        [13.4699,  6.6333,  5.9371],\n",
            "        [-1.4905,  8.8162,  9.5964],\n",
            "        [ 9.1355, -1.7136, 11.0330],\n",
            "        [13.4749,  6.6314,  5.9418]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.1756, 559.8107, 147.6473, 595.5099],\n",
            "        [140.0336, 198.6384, 177.9107, 235.6111],\n",
            "        [699.2273, 562.4766, 737.2882, 604.1926],\n",
            "        [111.1235, 559.7169, 147.5959, 595.4232],\n",
            "        [139.9685, 198.7430, 177.3682, 235.3299]], device='cuda:0')\n",
            "GT bboxes: tensor([[698.4127, 560.0000, 736.5079, 598.0953],\n",
            "        [111.7460, 558.7302, 149.8412, 596.8254],\n",
            "        [449.5238, 171.4286, 487.6190, 209.5238]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.3805, -1.8321],\n",
            "        [-1.4704,  7.0701],\n",
            "        [ 7.3677, -1.7369],\n",
            "        [-1.6295,  7.0512],\n",
            "        [-1.3624,  7.0734]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 48.0337, 159.9141,  86.6675, 198.2015],\n",
            "        [102.0136, 553.7720, 140.8675, 590.8260],\n",
            "        [ 48.0905, 160.8639,  86.6694, 199.1302],\n",
            "        [100.1511, 553.0468, 139.4258, 592.2682],\n",
            "        [102.2924, 551.6237, 141.8589, 591.5058]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 97.7778, 553.6508, 135.8730, 591.7460],\n",
            "        [ 48.2540, 158.7302,  86.3492, 196.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1191, -1.7617, 11.0368],\n",
            "        [13.4716,  6.6176,  5.9533],\n",
            "        [-1.5692,  8.8114,  9.5967],\n",
            "        [ 9.1215, -1.7667, 11.0386],\n",
            "        [13.4841,  6.6084,  5.9570]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[110.4849, 559.9353, 148.6511, 596.0947],\n",
            "        [139.1060, 198.8195, 177.7593, 236.5509],\n",
            "        [698.5347, 561.7439, 737.5680, 603.7272],\n",
            "        [110.2764, 559.6862, 148.3228, 596.4224],\n",
            "        [138.8427, 198.6713, 176.7948, 236.2517]], device='cuda:0')\n",
            "GT bboxes: tensor([[698.4127, 560.0000, 736.5079, 598.0953],\n",
            "        [111.7460, 558.7302, 149.8412, 596.8254],\n",
            "        [449.5238, 171.4286, 487.6190, 209.5238]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 77\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_90_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9fd60>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[173.9683, 165.0794, 212.0635, 203.1746],\n",
            "                        [488.8889, 741.5873, 526.9841, 779.6826]], device='cuda:0')\n",
            "            labels: tensor([3, 4], device='cuda:0')\n",
            "        ) at 0x7f3761b9c520>\n",
            ") at 0x7f3761b9cd60>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 51\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_51_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9d300>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[331.4286,   3.8095, 369.5238,  41.9048]], device='cuda:0')\n",
            "            labels: tensor([5], device='cuda:0')\n",
            "        ) at 0x7f3761b9ed40>\n",
            ") at 0x7f3761b9cd30>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[12.4907,  5.9505],\n",
            "        [ 8.5477, 12.0215],\n",
            "        [-1.7508, 13.1272],\n",
            "        [ 8.5359, 12.0114],\n",
            "        [12.5228,  5.9839]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.8527, 554.2212, 700.2676, 591.7787],\n",
            "        [712.0878, 160.5141, 751.8000, 198.5608],\n",
            "        [172.2452, 166.1063, 210.7276, 202.7211],\n",
            "        [712.0586, 161.0947, 751.3284, 198.9544],\n",
            "        [661.1292, 553.8698, 700.4252, 592.0155]], device='cuda:0')\n",
            "GT bboxes: tensor([[173.9683, 165.0794, 212.0635, 203.1746],\n",
            "        [488.8889, 741.5873, 526.9841, 779.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7333],\n",
            "        [ 4.6955],\n",
            "        [ 8.7589],\n",
            "        [-1.8774],\n",
            "        [ 8.7320]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 42.4065, 260.5011,  82.0725, 296.7390],\n",
            "        [127.0900,  41.9203, 166.7798,  79.5474],\n",
            "        [ 41.3699, 260.9176,  80.2885, 297.4524],\n",
            "        [332.3156,   4.1718, 370.2685,  42.2367],\n",
            "        [ 42.9788, 260.6944,  82.4263, 297.1608]], device='cuda:0')\n",
            "GT bboxes: tensor([[331.4286,   3.8095, 369.5238,  41.9048]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[12.4852,  5.9278],\n",
            "        [ 8.5345, 12.0094],\n",
            "        [-1.7628, 13.1179],\n",
            "        [ 8.5295, 12.0044],\n",
            "        [12.5057,  5.9559]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.5462, 554.2275, 700.2931, 592.3359],\n",
            "        [711.6830, 160.4375, 751.9327, 198.6827],\n",
            "        [172.1648, 165.9743, 210.5598, 202.8589],\n",
            "        [711.6666, 160.6564, 751.4764, 198.7936],\n",
            "        [660.6415, 554.0778, 700.5909, 592.2487]], device='cuda:0')\n",
            "GT bboxes: tensor([[173.9683, 165.0794, 212.0635, 203.1746],\n",
            "        [488.8889, 741.5873, 526.9841, 779.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7407],\n",
            "        [ 4.6989],\n",
            "        [ 8.7612],\n",
            "        [-1.8749],\n",
            "        [ 8.7362]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 42.7959, 260.6113,  81.8550, 297.3564],\n",
            "        [126.9614,  41.9774, 166.5763,  79.5517],\n",
            "        [ 41.6208, 260.8775,  80.5577, 297.8540],\n",
            "        [332.3098,   4.4538, 369.9451,  42.2105],\n",
            "        [ 43.5392, 260.5955,  82.0544, 297.5827]], device='cuda:0')\n",
            "GT bboxes: tensor([[331.4286,   3.8095, 369.5238,  41.9048]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[12.5145,  5.9677],\n",
            "        [ 8.5370, 12.0110],\n",
            "        [-1.7455, 13.1210],\n",
            "        [ 8.5307, 12.0049],\n",
            "        [12.5289,  5.9840]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.6742, 554.2363, 700.1913, 592.3574],\n",
            "        [711.8939, 160.5301, 751.7053, 198.5171],\n",
            "        [172.2668, 166.1343, 210.4389, 202.7844],\n",
            "        [711.7731, 160.7973, 751.2418, 198.6057],\n",
            "        [660.6052, 554.1639, 700.5161, 592.2344]], device='cuda:0')\n",
            "GT bboxes: tensor([[173.9683, 165.0794, 212.0635, 203.1746],\n",
            "        [488.8889, 741.5873, 526.9841, 779.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7410],\n",
            "        [ 4.7032],\n",
            "        [ 8.7604],\n",
            "        [-1.8829],\n",
            "        [ 8.7378]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 42.7672, 260.4895,  81.8987, 297.5750],\n",
            "        [127.1897,  42.3463, 166.2059,  79.1291],\n",
            "        [ 41.5767, 260.9086,  80.7330, 297.8320],\n",
            "        [332.3086,   4.4734, 369.8024,  42.1966],\n",
            "        [ 43.1865, 260.4660,  82.3357, 297.9706]], device='cuda:0')\n",
            "GT bboxes: tensor([[331.4286,   3.8095, 369.5238,  41.9048]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[12.5177,  5.9675],\n",
            "        [ 8.5294, 12.0023],\n",
            "        [-1.7582, 13.1125],\n",
            "        [ 8.5238, 11.9967],\n",
            "        [12.5216,  5.9744]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.6932, 554.4268, 700.2089, 592.2339],\n",
            "        [711.9756, 160.5074, 751.7287, 198.3373],\n",
            "        [172.4729, 166.0361, 210.3979, 202.5986],\n",
            "        [711.8834, 160.7629, 751.2145, 198.3985],\n",
            "        [660.6714, 554.3048, 700.3907, 592.1298]], device='cuda:0')\n",
            "GT bboxes: tensor([[173.9683, 165.0794, 212.0635, 203.1746],\n",
            "        [488.8889, 741.5873, 526.9841, 779.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7424],\n",
            "        [ 4.7029],\n",
            "        [ 8.7611],\n",
            "        [-1.8735],\n",
            "        [ 8.7402]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 42.8856, 260.7045,  81.6726, 297.4043],\n",
            "        [127.3390,  42.4448, 166.1736,  78.9786],\n",
            "        [ 41.7443, 261.1555,  80.5634, 297.6337],\n",
            "        [332.4737,   4.4999, 369.7817,  42.1799],\n",
            "        [ 43.1594, 260.7030,  82.0717, 297.7746]], device='cuda:0')\n",
            "GT bboxes: tensor([[331.4286,   3.8095, 369.5238,  41.9048]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[12.5450,  5.9920],\n",
            "        [ 8.5322, 12.0056],\n",
            "        [-1.7535, 13.1142],\n",
            "        [ 8.5268, 12.0004],\n",
            "        [12.5442,  5.9938]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.7192, 554.5136, 700.1299, 592.1935],\n",
            "        [711.9085, 160.5989, 751.9162, 198.2405],\n",
            "        [172.5095, 166.0677, 210.4259, 202.5195],\n",
            "        [711.8485, 160.8727, 751.4916, 198.3188],\n",
            "        [660.6395, 554.3500, 700.3611, 592.1144]], device='cuda:0')\n",
            "GT bboxes: tensor([[173.9683, 165.0794, 212.0635, 203.1746],\n",
            "        [488.8889, 741.5873, 526.9841, 779.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7420],\n",
            "        [ 4.7023],\n",
            "        [ 8.7599],\n",
            "        [-1.8680],\n",
            "        [ 8.7398]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 42.8703, 260.7653,  81.6472, 297.3520],\n",
            "        [127.2780,  42.4882, 166.2809,  78.9389],\n",
            "        [ 41.8105, 261.2574,  80.5970, 297.5392],\n",
            "        [332.3896,   4.5275, 369.9863,  42.1567],\n",
            "        [ 43.1200, 260.8040,  82.0452, 297.6717]], device='cuda:0')\n",
            "GT bboxes: tensor([[331.4286,   3.8095, 369.5238,  41.9048]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[12.5157,  5.9653],\n",
            "        [ 8.5417, 12.0146],\n",
            "        [-1.7456, 13.1233],\n",
            "        [ 8.5360, 12.0091],\n",
            "        [12.5134,  5.9662]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.7689, 554.5288, 700.1436, 592.1597],\n",
            "        [711.9786, 160.5256, 751.8117, 198.2322],\n",
            "        [172.5283, 166.0312, 210.4096, 202.4945],\n",
            "        [711.8834, 160.7962, 751.3726, 198.3016],\n",
            "        [660.6940, 554.3568, 700.3530, 592.0789]], device='cuda:0')\n",
            "GT bboxes: tensor([[173.9683, 165.0794, 212.0635, 203.1746],\n",
            "        [488.8889, 741.5873, 526.9841, 779.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7408],\n",
            "        [ 4.7023],\n",
            "        [ 8.7585],\n",
            "        [-1.8690],\n",
            "        [ 8.7384]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 42.8897, 260.7824,  81.6429, 297.3747],\n",
            "        [127.3214,  42.4894, 166.1885,  78.9049],\n",
            "        [ 41.8148, 261.2736,  80.5649, 297.5177],\n",
            "        [332.3865,   4.5570, 370.0017,  42.1333],\n",
            "        [ 43.1384, 260.8270,  82.0300, 297.6649]], device='cuda:0')\n",
            "GT bboxes: tensor([[331.4286,   3.8095, 369.5238,  41.9048]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[12.5595,  5.9991],\n",
            "        [ 8.5412, 12.0150],\n",
            "        [-1.7694, 13.1156],\n",
            "        [ 8.5171, 11.9946],\n",
            "        [12.5802,  6.0256]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[661.2183, 554.6744, 700.1190, 592.5467],\n",
            "        [712.2291, 160.6924, 751.3311, 198.9284],\n",
            "        [172.5133, 166.6415, 210.8604, 203.1595],\n",
            "        [711.9847, 161.6327, 750.6345, 199.6624],\n",
            "        [661.3181, 553.4984, 700.4872, 593.4145]], device='cuda:0')\n",
            "GT bboxes: tensor([[173.9683, 165.0794, 212.0635, 203.1746],\n",
            "        [488.8889, 741.5873, 526.9841, 779.6826]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.7233],\n",
            "        [ 4.7052],\n",
            "        [ 8.7696],\n",
            "        [-1.8476],\n",
            "        [ 8.7275]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 44.2853, 260.0882,  82.5743, 297.5453],\n",
            "        [127.3319,  41.9564, 166.3645,  80.4655],\n",
            "        [ 41.4391, 260.9947,  79.9387, 298.5558],\n",
            "        [332.7258,   4.1766, 370.5263,  41.7840],\n",
            "        [ 44.2703, 260.6864,  83.0538, 298.1704]], device='cuda:0')\n",
            "GT bboxes: tensor([[331.4286,   3.8095, 369.5238,  41.9048]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 93\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_82_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9e6e0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[59.6825, 26.6667, 97.7778, 64.7619]], device='cuda:0')\n",
            "            labels: tensor([2], device='cuda:0')\n",
            "        ) at 0x7f3761b9c5e0>\n",
            ") at 0x7f3761b9e9e0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 89\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_96_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9d330>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[496.5079, 526.9841, 534.6031, 565.0794]], device='cuda:0')\n",
            "            labels: tensor([5], device='cuda:0')\n",
            "        ) at 0x7f3761b9faf0>\n",
            ") at 0x7f3761b9d7b0>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.8592],\n",
            "        [ 7.8666],\n",
            "        [12.7400],\n",
            "        [12.7467],\n",
            "        [12.7453]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[464.0026, 101.1608, 502.4458, 139.3504],\n",
            "        [464.0157, 101.6737, 502.8155, 139.4338],\n",
            "        [660.3730, 287.2248, 699.3070, 326.5200],\n",
            "        [661.3213, 287.2087, 699.6406, 326.3780],\n",
            "        [661.3361, 287.1783, 699.7979, 326.0634]], device='cuda:0')\n",
            "GT bboxes: tensor([[59.6825, 26.6667, 97.7778, 64.7619]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.8755],\n",
            "        [ 9.8613],\n",
            "        [ 4.9013],\n",
            "        [ 4.8976],\n",
            "        [-1.9030]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[201.3230, 189.1615, 239.3638, 225.8037],\n",
            "        [202.8170, 189.1562, 240.3653, 225.5934],\n",
            "        [381.2535, 393.3337, 418.6201, 430.5125],\n",
            "        [381.0706, 393.2036, 419.1325, 430.5533],\n",
            "        [496.0114, 526.1124, 534.8878, 564.8970]], device='cuda:0')\n",
            "GT bboxes: tensor([[496.5079, 526.9841, 534.6031, 565.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.8548],\n",
            "        [ 7.8648],\n",
            "        [12.7332],\n",
            "        [12.7397],\n",
            "        [12.7401]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[464.0465, 101.3590, 502.4622, 139.4426],\n",
            "        [464.3264, 101.9972, 502.5378, 139.4762],\n",
            "        [660.3906, 287.0920, 699.5480, 326.6697],\n",
            "        [661.1301, 287.1378, 699.7567, 326.5938],\n",
            "        [661.1374, 287.1642, 699.8655, 326.4378]], device='cuda:0')\n",
            "GT bboxes: tensor([[59.6825, 26.6667, 97.7778, 64.7619]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.8758],\n",
            "        [ 9.8660],\n",
            "        [ 4.9004],\n",
            "        [ 4.8991],\n",
            "        [-1.8982]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[201.5361, 188.7153, 239.4290, 225.9052],\n",
            "        [202.6736, 188.6184, 240.1306, 225.7664],\n",
            "        [381.0745, 393.4417, 418.5216, 430.9882],\n",
            "        [380.9521, 393.2379, 418.8075, 431.0038],\n",
            "        [496.0184, 526.2369, 535.1500, 565.1589]], device='cuda:0')\n",
            "GT bboxes: tensor([[496.5079, 526.9841, 534.6031, 565.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.8590],\n",
            "        [ 7.8683],\n",
            "        [12.7354],\n",
            "        [12.7419],\n",
            "        [12.7418]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[464.4314, 101.4974, 502.3223, 139.3525],\n",
            "        [464.7549, 101.9067, 502.4024, 139.4120],\n",
            "        [660.7673, 287.3713, 699.1472, 326.5781],\n",
            "        [661.2972, 287.4273, 699.5229, 326.6079],\n",
            "        [661.3141, 287.4170, 699.5790, 326.5105]], device='cuda:0')\n",
            "GT bboxes: tensor([[59.6825, 26.6667, 97.7778, 64.7619]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.8774],\n",
            "        [ 9.8693],\n",
            "        [ 4.9069],\n",
            "        [ 4.9053],\n",
            "        [-1.9150]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[201.6601, 188.6613, 239.2991, 225.7056],\n",
            "        [202.5395, 188.6488, 239.8803, 225.5802],\n",
            "        [381.3141, 393.4269, 418.2581, 430.3922],\n",
            "        [381.0539, 393.2768, 418.5432, 430.4988],\n",
            "        [496.1957, 526.2151, 534.9655, 565.2053]], device='cuda:0')\n",
            "GT bboxes: tensor([[496.5079, 526.9841, 534.6031, 565.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.8590],\n",
            "        [ 7.8646],\n",
            "        [12.7264],\n",
            "        [12.7336],\n",
            "        [12.7339]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[464.5363, 101.6129, 502.3363, 139.3033],\n",
            "        [464.8488, 101.9550, 502.4261, 139.2948],\n",
            "        [660.8178, 287.4554, 699.1850, 326.3230],\n",
            "        [661.4225, 287.4964, 699.5078, 326.3586],\n",
            "        [661.4387, 287.4568, 699.5610, 326.2897]], device='cuda:0')\n",
            "GT bboxes: tensor([[59.6825, 26.6667, 97.7778, 64.7619]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.8791],\n",
            "        [ 9.8715],\n",
            "        [ 4.9075],\n",
            "        [ 4.9061],\n",
            "        [-1.9196]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[201.7619, 188.5203, 239.3180, 225.4751],\n",
            "        [202.5806, 188.4931, 239.8322, 225.4139],\n",
            "        [381.2388, 393.3934, 418.4157, 430.2138],\n",
            "        [381.0342, 393.2859, 418.6376, 430.3123],\n",
            "        [496.2592, 526.2265, 534.9502, 565.2116]], device='cuda:0')\n",
            "GT bboxes: tensor([[496.5079, 526.9841, 534.6031, 565.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.8618],\n",
            "        [ 7.8685],\n",
            "        [12.7269],\n",
            "        [12.7330],\n",
            "        [12.7332]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[464.6695, 101.7057, 502.2833, 139.2487],\n",
            "        [465.0329, 102.0505, 502.3292, 139.2164],\n",
            "        [660.8260, 287.4810, 699.3383, 326.2503],\n",
            "        [661.3943, 287.5252, 699.5852, 326.2611],\n",
            "        [661.4490, 287.4873, 699.5974, 326.1918]], device='cuda:0')\n",
            "GT bboxes: tensor([[59.6825, 26.6667, 97.7778, 64.7619]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.8784],\n",
            "        [ 9.8725],\n",
            "        [ 4.9069],\n",
            "        [ 4.9060],\n",
            "        [-1.9208]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[201.7013, 188.5972, 239.4603, 225.4227],\n",
            "        [202.4636, 188.6217, 239.7971, 225.2957],\n",
            "        [381.2993, 393.2854, 418.3863, 430.2784],\n",
            "        [381.1755, 393.2637, 418.5563, 430.2982],\n",
            "        [496.2707, 526.2415, 535.0291, 565.1553]], device='cuda:0')\n",
            "GT bboxes: tensor([[496.5079, 526.9841, 534.6031, 565.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.8690],\n",
            "        [ 7.8753],\n",
            "        [12.7364],\n",
            "        [12.7421],\n",
            "        [12.7420]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[464.6895, 101.7350, 502.2696, 139.2455],\n",
            "        [465.0549, 102.0790, 502.3124, 139.2053],\n",
            "        [660.9478, 287.4842, 699.2369, 326.2842],\n",
            "        [661.4705, 287.5223, 699.5067, 326.3113],\n",
            "        [661.4958, 287.4825, 699.5497, 326.2536]], device='cuda:0')\n",
            "GT bboxes: tensor([[59.6825, 26.6667, 97.7778, 64.7619]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.8786],\n",
            "        [ 9.8723],\n",
            "        [ 4.9048],\n",
            "        [ 4.9033],\n",
            "        [-1.9302]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[201.7855, 188.5150, 239.3694, 225.3906],\n",
            "        [202.5307, 188.5548, 239.7455, 225.2728],\n",
            "        [381.3101, 393.3410, 418.3656, 430.2258],\n",
            "        [381.1698, 393.3060, 418.5719, 430.2747],\n",
            "        [496.3098, 526.2857, 534.9945, 565.1572]], device='cuda:0')\n",
            "GT bboxes: tensor([[496.5079, 526.9841, 534.6031, 565.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 7.8438],\n",
            "        [ 7.8672],\n",
            "        [12.7410],\n",
            "        [12.7500],\n",
            "        [12.7510]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[463.8759, 100.1277, 502.3804, 139.2247],\n",
            "        [463.9183, 101.9346, 502.9103, 139.4790],\n",
            "        [660.0883, 287.6092, 699.0390, 327.2918],\n",
            "        [661.4952, 287.6500, 699.8093, 327.0117],\n",
            "        [661.4841, 287.7053, 699.9774, 326.3388]], device='cuda:0')\n",
            "GT bboxes: tensor([[59.6825, 26.6667, 97.7778, 64.7619]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.8678],\n",
            "        [ 9.8469],\n",
            "        [ 4.8913],\n",
            "        [ 4.8873],\n",
            "        [-1.9393]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[201.0935, 189.7615, 239.1878, 226.7813],\n",
            "        [203.2717, 189.9134, 240.8852, 226.1665],\n",
            "        [381.6650, 394.0389, 418.5810, 431.1651],\n",
            "        [381.3998, 393.7547, 419.3649, 431.0079],\n",
            "        [496.0181, 526.8599, 534.1699, 565.2001]], device='cuda:0')\n",
            "GT bboxes: tensor([[496.5079, 526.9841, 534.6031, 565.0794]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 49\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_57_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9c520>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[590.4762, 444.4445, 628.5714, 482.5397]], device='cuda:0')\n",
            "            labels: tensor([4], device='cuda:0')\n",
            "        ) at 0x7f3761b9c670>\n",
            ") at 0x7f3761b9caf0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 100\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_106_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9d9c0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[ 53.3333, 546.0317,  91.4286, 584.1270],\n",
            "                        [ 82.5397, 563.8096, 120.6349, 601.9048],\n",
            "                        [429.2064, 615.8730, 467.3016, 653.9683],\n",
            "                        [509.2064, 152.3810, 547.3016, 190.4762],\n",
            "                        [234.9206, 582.8572, 273.0159, 620.9524]], device='cuda:0')\n",
            "            labels: tensor([1, 2, 3, 3, 5], device='cuda:0')\n",
            "        ) at 0x7f3761b9dd50>\n",
            ") at 0x7f3761b9f460>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8836],\n",
            "        [-1.8937],\n",
            "        [-1.8662],\n",
            "        [ 6.4232],\n",
            "        [-1.8786]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[590.4745, 445.9738, 628.0451, 481.9100],\n",
            "        [591.1682, 445.5442, 628.7457, 482.0254],\n",
            "        [591.0651, 445.8090, 628.9894, 481.9598],\n",
            "        [312.6207, 351.1172, 351.3875, 390.0839],\n",
            "        [590.5981, 446.1731, 628.0200, 482.2301]], device='cuda:0')\n",
            "GT bboxes: tensor([[590.4762, 444.4445, 628.5714, 482.5397]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 3.1660,  2.2452,  5.5058, 12.1076,  2.5147],\n",
            "        [ 4.3351,  3.5762,  4.3624, 10.6799, -1.6887],\n",
            "        [ 3.1967,  2.2860,  5.4798, 12.0996,  2.5113],\n",
            "        [ 3.1873,  2.2740,  5.4937, 12.0933,  2.4984],\n",
            "        [ 3.1778,  2.2616,  5.5024, 12.1144,  2.5272]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[139.8106, 597.2612, 178.5424, 634.6191],\n",
            "        [236.3194, 583.4510, 275.5292, 622.3265],\n",
            "        [141.0514, 597.9838, 179.6299, 635.0580],\n",
            "        [141.3811, 597.1407, 179.2536, 634.6982],\n",
            "        [140.0516, 597.6915, 178.4151, 634.9389]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 53.3333, 546.0317,  91.4286, 584.1270],\n",
            "        [ 82.5397, 563.8096, 120.6349, 601.9048],\n",
            "        [429.2064, 615.8730, 467.3016, 653.9683],\n",
            "        [509.2064, 152.3810, 547.3016, 190.4762],\n",
            "        [234.9206, 582.8572, 273.0159, 620.9524]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9164],\n",
            "        [-1.9201],\n",
            "        [-1.8972],\n",
            "        [ 6.4273],\n",
            "        [-1.9102]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[590.2754, 445.6216, 628.3498, 482.2550],\n",
            "        [590.9759, 445.3021, 628.7548, 482.2614],\n",
            "        [590.8895, 445.4919, 628.9775, 482.2173],\n",
            "        [312.7582, 351.2469, 351.5941, 390.2958],\n",
            "        [590.6127, 445.7513, 628.2651, 482.3857]], device='cuda:0')\n",
            "GT bboxes: tensor([[590.4762, 444.4445, 628.5714, 482.5397]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 3.1649,  2.2445,  5.4951, 12.1047,  2.5137],\n",
            "        [ 4.3559,  3.5961,  4.3787, 10.6989, -1.6692],\n",
            "        [ 3.1888,  2.2758,  5.4789, 12.0976,  2.5106],\n",
            "        [ 3.1829,  2.2681,  5.4915, 12.0941,  2.5019],\n",
            "        [ 3.1773,  2.2605,  5.4983, 12.1098,  2.5205]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[139.8746, 596.9521, 178.8610, 635.3090],\n",
            "        [236.2491, 583.4607, 275.8430, 622.3883],\n",
            "        [140.9084, 597.5576, 179.5689, 635.3526],\n",
            "        [141.1927, 596.9392, 179.2177, 635.0370],\n",
            "        [140.2380, 597.3033, 178.7043, 635.2139]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 53.3333, 546.0317,  91.4286, 584.1270],\n",
            "        [ 82.5397, 563.8096, 120.6349, 601.9048],\n",
            "        [429.2064, 615.8730, 467.3016, 653.9683],\n",
            "        [509.2064, 152.3810, 547.3016, 190.4762],\n",
            "        [234.9206, 582.8572, 273.0159, 620.9524]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8980],\n",
            "        [-1.8916],\n",
            "        [-1.8899],\n",
            "        [ 6.4300],\n",
            "        [-1.8836]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[590.7347, 445.5496, 628.1192, 482.2105],\n",
            "        [591.4081, 445.3013, 628.4560, 482.1629],\n",
            "        [591.2642, 445.4437, 628.7155, 482.1708],\n",
            "        [312.9580, 351.2672, 351.4713, 390.2283],\n",
            "        [591.0062, 445.5605, 628.0479, 482.2965]], device='cuda:0')\n",
            "GT bboxes: tensor([[590.4762, 444.4445, 628.5714, 482.5397]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 3.1727,  2.2534,  5.5023, 12.1084,  2.5166],\n",
            "        [ 4.3501,  3.5913,  4.3723, 10.6933, -1.6676],\n",
            "        [ 3.1925,  2.2796,  5.4890, 12.1008,  2.5137],\n",
            "        [ 3.1877,  2.2732,  5.4955, 12.0977,  2.5076],\n",
            "        [ 3.1782,  2.2606,  5.5000, 12.1093,  2.5210]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[140.0928, 597.1869, 178.6891, 634.9633],\n",
            "        [236.2969, 583.3642, 275.7988, 622.5267],\n",
            "        [141.1234, 597.5893, 179.1982, 635.0218],\n",
            "        [141.2307, 597.2408, 179.0429, 634.7925],\n",
            "        [140.2870, 597.3967, 178.6522, 635.0155]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 53.3333, 546.0317,  91.4286, 584.1270],\n",
            "        [ 82.5397, 563.8096, 120.6349, 601.9048],\n",
            "        [429.2064, 615.8730, 467.3016, 653.9683],\n",
            "        [509.2064, 152.3810, 547.3016, 190.4762],\n",
            "        [234.9206, 582.8572, 273.0159, 620.9524]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8949],\n",
            "        [-1.8945],\n",
            "        [-1.8796],\n",
            "        [ 6.4264],\n",
            "        [-1.8888]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[590.7686, 445.5641, 628.1796, 482.1455],\n",
            "        [591.2750, 445.2926, 628.6812, 482.0628],\n",
            "        [591.2100, 445.4510, 628.8631, 482.0893],\n",
            "        [313.1424, 351.2621, 351.3840, 390.2278],\n",
            "        [590.9108, 445.5660, 628.2350, 482.1244]], device='cuda:0')\n",
            "GT bboxes: tensor([[590.4762, 444.4445, 628.5714, 482.5397]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 3.1736,  2.2551,  5.5020, 12.1080,  2.5171],\n",
            "        [ 4.3711,  3.6115,  4.3914, 10.7103, -1.6640],\n",
            "        [ 3.1906,  2.2777,  5.4909, 12.1012,  2.5119],\n",
            "        [ 3.1874,  2.2728,  5.4966, 12.0987,  2.5068],\n",
            "        [ 3.1802,  2.2634,  5.5015, 12.1096,  2.5218]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[140.1857, 597.1981, 178.6670, 634.9691],\n",
            "        [236.4835, 583.3168, 275.7435, 622.4890],\n",
            "        [141.0355, 597.5234, 179.2155, 634.9739],\n",
            "        [141.1487, 597.2374, 179.0808, 634.7673],\n",
            "        [140.3926, 597.4484, 178.5997, 634.9282]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 53.3333, 546.0317,  91.4286, 584.1270],\n",
            "        [ 82.5397, 563.8096, 120.6349, 601.9048],\n",
            "        [429.2064, 615.8730, 467.3016, 653.9683],\n",
            "        [509.2064, 152.3810, 547.3016, 190.4762],\n",
            "        [234.9206, 582.8572, 273.0159, 620.9524]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8843],\n",
            "        [-1.8933],\n",
            "        [-1.8803],\n",
            "        [ 6.4204],\n",
            "        [-1.8856]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[590.8959, 445.5499, 628.1080, 482.0558],\n",
            "        [591.3541, 445.2701, 628.6574, 481.9863],\n",
            "        [591.3039, 445.4293, 628.7860, 482.0109],\n",
            "        [313.2549, 351.2800, 351.3678, 390.1855],\n",
            "        [590.9911, 445.5208, 628.2128, 482.0347]], device='cuda:0')\n",
            "GT bboxes: tensor([[590.4762, 444.4445, 628.5714, 482.5397]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 3.1734,  2.2550,  5.5001, 12.1063,  2.5176],\n",
            "        [ 4.3580,  3.5974,  4.3777, 10.6966, -1.6619],\n",
            "        [ 3.1859,  2.2714,  5.4892, 12.0999,  2.5110],\n",
            "        [ 3.1857,  2.2710,  5.4966, 12.0987,  2.5094],\n",
            "        [ 3.1803,  2.2640,  5.5002, 12.1081,  2.5228]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[140.2813, 597.1906, 178.6310, 635.0159],\n",
            "        [236.4537, 583.3334, 275.8705, 622.4415],\n",
            "        [140.9223, 597.3636, 179.1919, 635.1208],\n",
            "        [141.1501, 597.2309, 178.9260, 634.8076],\n",
            "        [140.5246, 597.4432, 178.5233, 634.9625]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 53.3333, 546.0317,  91.4286, 584.1270],\n",
            "        [ 82.5397, 563.8096, 120.6349, 601.9048],\n",
            "        [429.2064, 615.8730, 467.3016, 653.9683],\n",
            "        [509.2064, 152.3810, 547.3016, 190.4762],\n",
            "        [234.9206, 582.8572, 273.0159, 620.9524]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8736],\n",
            "        [-1.8815],\n",
            "        [-1.8663],\n",
            "        [ 6.4352],\n",
            "        [-1.8736]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[590.8945, 445.5774, 628.1135, 482.0221],\n",
            "        [591.3666, 445.3038, 628.6386, 481.9512],\n",
            "        [591.3029, 445.4626, 628.8323, 481.9810],\n",
            "        [313.2978, 351.3077, 351.3277, 390.2177],\n",
            "        [591.0017, 445.5505, 628.2064, 482.0042]], device='cuda:0')\n",
            "GT bboxes: tensor([[590.4762, 444.4445, 628.5714, 482.5397]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 3.1837,  2.2659,  5.5097, 12.1166,  2.5162],\n",
            "        [ 4.3734,  3.6117,  4.3913, 10.7106, -1.6615],\n",
            "        [ 3.1982,  2.2849,  5.5001, 12.1104,  2.5102],\n",
            "        [ 3.1963,  2.2824,  5.5058, 12.1083,  2.5081],\n",
            "        [ 3.1898,  2.2741,  5.5088, 12.1175,  2.5216]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[140.2641, 597.2504, 178.6515, 634.9967],\n",
            "        [236.4785, 583.3835, 275.8514, 622.4296],\n",
            "        [140.9868, 597.4957, 179.1859, 634.9935],\n",
            "        [141.1920, 597.2930, 178.9357, 634.7834],\n",
            "        [140.5091, 597.5090, 178.5421, 634.9474]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 53.3333, 546.0317,  91.4286, 584.1270],\n",
            "        [ 82.5397, 563.8096, 120.6349, 601.9048],\n",
            "        [429.2064, 615.8730, 467.3016, 653.9683],\n",
            "        [509.2064, 152.3810, 547.3016, 190.4762],\n",
            "        [234.9206, 582.8572, 273.0159, 620.9524]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7936],\n",
            "        [-1.9069],\n",
            "        [-1.8622],\n",
            "        [ 6.4454],\n",
            "        [-1.7947]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[589.9274, 446.2058, 627.6514, 483.4469],\n",
            "        [591.1557, 445.5331, 628.7304, 482.7702],\n",
            "        [591.0560, 446.1117, 629.0859, 482.7041],\n",
            "        [312.3667, 351.9987, 350.5948, 390.6865],\n",
            "        [590.2312, 446.6372, 627.7382, 483.3743]], device='cuda:0')\n",
            "GT bboxes: tensor([[590.4762, 444.4445, 628.5714, 482.5397]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 5\n",
            "Cost matrix shape: torch.Size([900, 5])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 3.1606,  2.2393,  5.5126, 12.1129,  2.5205],\n",
            "        [ 4.3686,  3.6113,  4.3888, 10.7017, -1.6565],\n",
            "        [ 3.2145,  2.3082,  5.4743, 12.1077,  2.5178],\n",
            "        [ 3.1866,  2.2746,  5.4870, 12.0882,  2.4968],\n",
            "        [ 3.1870,  2.2725,  5.5053, 12.1288,  2.5440]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[139.5984, 597.1208, 178.1650, 634.6979],\n",
            "        [237.0096, 583.9310, 275.3806, 621.8244],\n",
            "        [141.2929, 598.3795, 179.9938, 635.5008],\n",
            "        [141.7159, 596.9653, 179.3709, 634.9780],\n",
            "        [139.7652, 598.1489, 178.1885, 635.2464]], device='cuda:0')\n",
            "GT bboxes: tensor([[ 53.3333, 546.0317,  91.4286, 584.1270],\n",
            "        [ 82.5397, 563.8096, 120.6349, 601.9048],\n",
            "        [429.2064, 615.8730, 467.3016, 653.9683],\n",
            "        [509.2064, 152.3810, 547.3016, 190.4762],\n",
            "        [234.9206, 582.8572, 273.0159, 620.9524]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 86\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_92_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9c5e0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[689.5238, 214.6032, 727.6190, 252.6984],\n",
            "                        [100.3174, 397.4603, 138.4127, 435.5556],\n",
            "                        [111.7460, 138.4127, 149.8412, 176.5079]], device='cuda:0')\n",
            "            labels: tensor([1, 2, 3], device='cuda:0')\n",
            "        ) at 0x7f3761b9c9d0>\n",
            ") at 0x7f3761b9d300>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 38\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_44_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9dc60>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[689.5238,  95.2381, 727.6190, 133.3333]], device='cuda:0')\n",
            "            labels: tensor([3], device='cuda:0')\n",
            "        ) at 0x7f3761b9da20>\n",
            ") at 0x7f3761b9e3b0>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 1.9627, 12.6006,  9.6246],\n",
            "        [ 1.9405, 12.5910,  9.6260],\n",
            "        [ 2.0039, 12.6183,  9.6291],\n",
            "        [11.6554, -1.4611,  5.0616],\n",
            "        [ 9.7447, 12.1120, 15.2231]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[712.8740, 158.8482, 752.3419, 198.3270],\n",
            "        [712.6351, 159.0083, 751.8835, 198.9593],\n",
            "        [714.0262, 158.4134, 753.0792, 197.7480],\n",
            "        [ 96.9245, 400.2447, 136.1167, 437.7757],\n",
            "        [566.4744, 729.9475, 628.9959, 781.6567]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238, 214.6032, 727.6190, 252.6984],\n",
            "        [100.3174, 397.4603, 138.4127, 435.5556],\n",
            "        [111.7460, 138.4127, 149.8412, 176.5079]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9062],\n",
            "        [-1.8630],\n",
            "        [-1.7471],\n",
            "        [-1.7498],\n",
            "        [-1.8527]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[689.7801,  94.8030, 728.4820, 133.5856],\n",
            "        [689.7036,  94.6168, 728.3712, 134.3772],\n",
            "        [691.3242,  94.7682, 729.4445, 133.9857],\n",
            "        [691.4772,  94.7888, 729.5101, 132.9487],\n",
            "        [689.8576,  93.9762, 728.6212, 133.1374]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238,  95.2381, 727.6190, 133.3333]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 1.9500, 12.5922,  9.6167],\n",
            "        [ 1.9358, 12.5870,  9.6151],\n",
            "        [ 1.9872, 12.6102,  9.6226],\n",
            "        [11.6544, -1.4516,  5.0586],\n",
            "        [ 9.7667, 12.1291, 15.2410]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[712.6315, 158.7821, 752.3448, 198.4354],\n",
            "        [712.3916, 158.7200, 751.9007, 198.7542],\n",
            "        [713.6614, 158.2659, 753.0541, 198.0390],\n",
            "        [ 97.0355, 400.3343, 136.2371, 438.1988],\n",
            "        [565.4871, 730.0811, 629.6113, 781.8211]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238, 214.6032, 727.6190, 252.6984],\n",
            "        [100.3174, 397.4603, 138.4127, 435.5556],\n",
            "        [111.7460, 138.4127, 149.8412, 176.5079]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9217],\n",
            "        [-1.8832],\n",
            "        [-1.7916],\n",
            "        [-1.7918],\n",
            "        [-1.8814]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[689.8283,  94.9929, 728.4420, 133.6092],\n",
            "        [689.7446,  94.7311, 728.4103, 134.1430],\n",
            "        [691.0800,  94.8759, 729.2259, 133.7870],\n",
            "        [691.2962,  94.8793, 729.2277, 133.1107],\n",
            "        [689.9158,  94.3372, 728.5945, 133.2870]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238,  95.2381, 727.6190, 133.3333]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 1.9529, 12.5921,  9.6175],\n",
            "        [ 1.9389, 12.5857,  9.6140],\n",
            "        [ 1.9791, 12.6056,  9.6218],\n",
            "        [11.6619, -1.4390,  5.0618],\n",
            "        [ 9.7474, 12.1071, 15.2191]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[712.8234, 158.9154, 752.1093, 198.3246],\n",
            "        [712.5825, 158.8979, 751.5977, 198.5319],\n",
            "        [713.5386, 158.4413, 752.7297, 198.1255],\n",
            "        [ 96.8685, 400.1243, 136.5584, 438.7644],\n",
            "        [565.1753, 729.8091, 629.5474, 782.6317]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238, 214.6032, 727.6190, 252.6984],\n",
            "        [100.3174, 397.4603, 138.4127, 435.5556],\n",
            "        [111.7460, 138.4127, 149.8412, 176.5079]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9382],\n",
            "        [-1.9229],\n",
            "        [-1.8206],\n",
            "        [-1.8157],\n",
            "        [-1.9011]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[690.1880,  95.1817, 728.1016, 133.4813],\n",
            "        [690.0876,  95.0992, 728.0765, 133.8098],\n",
            "        [691.1840,  95.0843, 728.9687, 133.6223],\n",
            "        [691.3965,  95.1191, 728.8695, 133.0689],\n",
            "        [690.2067,  94.7218, 728.2444, 133.1625]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238,  95.2381, 727.6190, 133.3333]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 1.9522, 12.5874,  9.6101],\n",
            "        [ 1.9394, 12.5813,  9.6076],\n",
            "        [ 1.9770, 12.6004,  9.6148],\n",
            "        [11.6532, -1.4493,  5.0558],\n",
            "        [ 9.7619, 12.1221, 15.2343]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[712.9160, 158.8881, 752.1174, 198.1297],\n",
            "        [712.6867, 158.9554, 751.6003, 198.2947],\n",
            "        [713.5869, 158.4440, 752.7555, 197.9671],\n",
            "        [ 96.8854, 400.2638, 136.5501, 438.5588],\n",
            "        [565.3416, 729.8913, 629.4522, 782.2838]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238, 214.6032, 727.6190, 252.6984],\n",
            "        [100.3174, 397.4603, 138.4127, 435.5556],\n",
            "        [111.7460, 138.4127, 149.8412, 176.5079]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9476],\n",
            "        [-1.9463],\n",
            "        [-1.8494],\n",
            "        [-1.8183],\n",
            "        [-1.8999]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[690.2749,  95.2287, 728.1099, 133.2307],\n",
            "        [690.1697,  95.1619, 728.0910, 133.5197],\n",
            "        [691.2142,  95.1495, 728.9303, 133.3323],\n",
            "        [691.3859,  95.1579, 728.8561, 132.8909],\n",
            "        [690.3293,  94.8433, 728.2034, 132.9571]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238,  95.2381, 727.6190, 133.3333]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 1.9543, 12.5868,  9.6089],\n",
            "        [ 1.9435, 12.5813,  9.6074],\n",
            "        [ 1.9787, 12.5993,  9.6132],\n",
            "        [11.6577, -1.4484,  5.0588],\n",
            "        [ 9.7452, 12.1058, 15.2168]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[712.8626, 159.0233, 752.2695, 197.9514],\n",
            "        [712.6880, 159.1493, 751.8325, 198.0938],\n",
            "        [713.5369, 158.6108, 752.8249, 197.7607],\n",
            "        [ 96.9254, 400.1093, 136.4006, 438.5256],\n",
            "        [565.1606, 729.9395, 629.7523, 782.2445]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238, 214.6032, 727.6190, 252.6984],\n",
            "        [100.3174, 397.4603, 138.4127, 435.5556],\n",
            "        [111.7460, 138.4127, 149.8412, 176.5079]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9315],\n",
            "        [-1.9522],\n",
            "        [-1.8465],\n",
            "        [-1.8186],\n",
            "        [-1.8961]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[690.3304,  95.2999, 728.1179, 133.0932],\n",
            "        [690.2361,  95.2499, 728.1044, 133.3732],\n",
            "        [691.2326,  95.2112, 728.8619, 133.1885],\n",
            "        [691.3939,  95.1996, 728.7884, 132.7993],\n",
            "        [690.4268,  94.9319, 728.1635, 132.8696]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238,  95.2381, 727.6190, 133.3333]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 1.9605, 12.5920,  9.6129],\n",
            "        [ 1.9491, 12.5861,  9.6108],\n",
            "        [ 1.9856, 12.6044,  9.6176],\n",
            "        [11.6644, -1.4406,  5.0649],\n",
            "        [ 9.7604, 12.1209, 15.2330]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[712.9166, 158.9701, 752.1781, 197.9012],\n",
            "        [712.7195, 159.0982, 751.7052, 198.0267],\n",
            "        [713.6409, 158.5948, 752.7346, 197.7059],\n",
            "        [ 96.9716, 400.1594, 136.4074, 438.5495],\n",
            "        [565.1625, 729.9487, 629.7563, 782.2494]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238, 214.6032, 727.6190, 252.6984],\n",
            "        [100.3174, 397.4603, 138.4127, 435.5556],\n",
            "        [111.7460, 138.4127, 149.8412, 176.5079]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9302],\n",
            "        [-1.9457],\n",
            "        [-1.8370],\n",
            "        [-1.8097],\n",
            "        [-1.8897]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[690.3630,  95.2494, 728.0627, 133.1108],\n",
            "        [690.2668,  95.2066, 728.0507, 133.3777],\n",
            "        [691.2649,  95.1746, 728.8535, 133.1930],\n",
            "        [691.4216,  95.1444, 728.7764, 132.8179],\n",
            "        [690.4357,  94.8803, 728.1374, 132.8918]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238,  95.2381, 727.6190, 133.3333]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 1.9497, 12.5922,  9.6266],\n",
            "        [ 1.9111, 12.5724,  9.6279],\n",
            "        [ 2.0270, 12.6261,  9.6348],\n",
            "        [11.6703, -1.3731,  5.0735],\n",
            "        [ 9.7595, 12.1171, 15.2279]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[712.9027, 159.1892, 751.9258, 198.6796],\n",
            "        [712.3678, 159.9179, 751.0353, 199.4573],\n",
            "        [714.7879, 158.5380, 753.3553, 197.3911],\n",
            "        [ 97.0813, 400.8013, 136.0441, 439.1742],\n",
            "        [568.2766, 730.5175, 626.7559, 780.5540]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238, 214.6032, 727.6190, 252.6984],\n",
            "        [100.3174, 397.4603, 138.4127, 435.5556],\n",
            "        [111.7460, 138.4127, 149.8412, 176.5079]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9055],\n",
            "        [-1.8474],\n",
            "        [-1.6475],\n",
            "        [-1.6755],\n",
            "        [-1.8111]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[689.4263,  94.6641, 728.2739, 133.8755],\n",
            "        [689.3582,  94.7970, 728.1779, 135.1752],\n",
            "        [691.9495,  94.9729, 730.3554, 134.6658],\n",
            "        [692.2476,  95.1079, 730.4803, 132.9240],\n",
            "        [689.6269,  92.9991, 728.5928, 132.7561]], device='cuda:0')\n",
            "GT bboxes: tensor([[689.5238,  95.2381, 727.6190, 133.3333]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 113\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_100_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9c670>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[111.7460, 552.3810, 149.8413, 590.4762],\n",
            "                        [278.0952, 236.1905, 316.1905, 274.2857],\n",
            "                        [234.9206, 402.5397, 273.0159, 440.6349],\n",
            "                        [157.4603, 459.6826, 195.5556, 497.7778]], device='cuda:0')\n",
            "            labels: tensor([0, 1, 3, 4], device='cuda:0')\n",
            "        ) at 0x7f3761b9ec80>\n",
            ") at 0x7f3761b9fa60>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 91\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_83_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761b9c160>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[712.3810, 132.0635, 750.4762, 170.1587],\n",
            "                        [660.3174, 286.9841, 698.4127, 325.0794]], device='cuda:0')\n",
            "            labels: tensor([3, 3], device='cuda:0')\n",
            "        ) at 0x7f3761b9fb50>\n",
            ") at 0x7f3761b9d2d0>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8121,  7.5328,  4.7686,  2.7529],\n",
            "        [ 3.7310,  5.3950,  3.3546,  3.7552],\n",
            "        [ 3.7423,  5.3945,  3.3731,  3.7705],\n",
            "        [-1.7507,  7.5513,  4.7948,  2.7714],\n",
            "        [-1.6604,  7.5702,  4.8187,  2.7873]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.9298, 550.7671, 150.9378, 589.9057],\n",
            "        [264.8920, 526.7673, 303.5396, 565.3806],\n",
            "        [265.4622, 526.9876, 303.8629, 565.2951],\n",
            "        [111.3555, 549.5066, 150.4230, 589.6442],\n",
            "        [113.6090, 551.1441, 152.2872, 589.6409]], device='cuda:0')\n",
            "GT bboxes: tensor([[111.7460, 552.3810, 149.8413, 590.4762],\n",
            "        [278.0952, 236.1905, 316.1905, 274.2857],\n",
            "        [234.9206, 402.5397, 273.0159, 440.6349],\n",
            "        [157.4603, 459.6826, 195.5556, 497.7778]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.2453, -1.8848],\n",
            "        [ 4.2323, -1.8311],\n",
            "        [ 5.1901,  6.6573],\n",
            "        [ 4.2315, -1.8050],\n",
            "        [ 5.1769,  6.6466]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.2728, 286.8435, 698.9426, 326.5224],\n",
            "        [661.0797, 286.6632, 699.4231, 326.1063],\n",
            "        [464.2384, 100.8828, 502.6449, 138.3789],\n",
            "        [661.1906, 286.4644, 699.2796, 326.4500],\n",
            "        [464.3497, 101.7659, 502.9387, 138.7265]], device='cuda:0')\n",
            "GT bboxes: tensor([[712.3810, 132.0635, 750.4762, 170.1587],\n",
            "        [660.3174, 286.9841, 698.4127, 325.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8393,  7.5398,  4.7677,  2.7428],\n",
            "        [ 3.7422,  5.4065,  3.3710,  3.7704],\n",
            "        [ 3.7483,  5.4098,  3.3825,  3.7806],\n",
            "        [-1.7786,  7.5486,  4.7869,  2.7570],\n",
            "        [-1.7359,  7.5513,  4.7902,  2.7602]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.7179, 550.6591, 150.8923, 590.3203],\n",
            "        [265.0028, 526.7459, 303.6393, 565.6022],\n",
            "        [265.3254, 526.8052, 303.7079, 565.4423],\n",
            "        [111.3023, 549.8062, 150.5711, 590.1132],\n",
            "        [113.0210, 550.9559, 151.3443, 589.8278]], device='cuda:0')\n",
            "GT bboxes: tensor([[111.7460, 552.3810, 149.8413, 590.4762],\n",
            "        [278.0952, 236.1905, 316.1905, 274.2857],\n",
            "        [234.9206, 402.5397, 273.0159, 440.6349],\n",
            "        [157.4603, 459.6826, 195.5556, 497.7778]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.2372, -1.8881],\n",
            "        [ 4.2269, -1.8215],\n",
            "        [ 5.1804,  6.6476],\n",
            "        [ 4.2274, -1.8138],\n",
            "        [ 5.1707,  6.6399]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.3667, 286.8122, 698.9889, 326.5010],\n",
            "        [661.0281, 286.6301, 699.4329, 326.4197],\n",
            "        [464.2747, 101.1564, 502.5109, 138.4185],\n",
            "        [661.0732, 286.5182, 699.3055, 326.5346],\n",
            "        [464.4752, 101.9558, 502.6655, 138.7717]], device='cuda:0')\n",
            "GT bboxes: tensor([[712.3810, 132.0635, 750.4762, 170.1587],\n",
            "        [660.3174, 286.9841, 698.4127, 325.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8381,  7.5346,  4.7772,  2.7570],\n",
            "        [ 3.7422,  5.3989,  3.3649,  3.7652],\n",
            "        [ 3.7476,  5.3977,  3.3723,  3.7713],\n",
            "        [-1.7807,  7.5319,  4.7772,  2.7554],\n",
            "        [-1.7688,  7.5265,  4.7717,  2.7495]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.5839, 550.6982, 150.9433, 590.4548],\n",
            "        [265.1524, 526.6130, 303.5197, 565.6820],\n",
            "        [265.4238, 526.7064, 303.6617, 565.5580],\n",
            "        [111.0988, 550.0897, 150.8631, 590.3756],\n",
            "        [112.7114, 551.0231, 151.4005, 590.1313]], device='cuda:0')\n",
            "GT bboxes: tensor([[111.7460, 552.3810, 149.8413, 590.4762],\n",
            "        [278.0952, 236.1905, 316.1905, 274.2857],\n",
            "        [234.9206, 402.5397, 273.0159, 440.6349],\n",
            "        [157.4603, 459.6826, 195.5556, 497.7778]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.2414, -1.8998],\n",
            "        [ 4.2327, -1.8485],\n",
            "        [ 5.1774,  6.6441],\n",
            "        [ 4.2330, -1.8477],\n",
            "        [ 5.1715,  6.6394]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.7349, 287.0173, 698.6215, 326.4087],\n",
            "        [661.2277, 286.8980, 699.0362, 326.3695],\n",
            "        [464.5872, 101.3587, 502.4345, 138.3918],\n",
            "        [661.2333, 286.8781, 698.9882, 326.4096],\n",
            "        [464.8677, 101.9342, 502.5843, 138.6221]], device='cuda:0')\n",
            "GT bboxes: tensor([[712.3810, 132.0635, 750.4762, 170.1587],\n",
            "        [660.3174, 286.9841, 698.4127, 325.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8411,  7.5396,  4.7957,  2.7747],\n",
            "        [ 3.7448,  5.3923,  3.3609,  3.7615],\n",
            "        [ 3.7492,  5.3900,  3.3661,  3.7654],\n",
            "        [-1.7912,  7.5507,  4.8073,  2.7853],\n",
            "        [-1.7746,  7.5365,  4.7919,  2.7709]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.7355, 550.7966, 150.8449, 590.1796],\n",
            "        [265.2446, 526.5419, 303.5234, 565.6453],\n",
            "        [265.5087, 526.6006, 303.6326, 565.5551],\n",
            "        [111.2288, 550.3447, 150.8293, 590.1671],\n",
            "        [112.6321, 551.1124, 151.2483, 589.9304]], device='cuda:0')\n",
            "GT bboxes: tensor([[111.7460, 552.3810, 149.8413, 590.4762],\n",
            "        [278.0952, 236.1905, 316.1905, 274.2857],\n",
            "        [234.9206, 402.5397, 273.0159, 440.6349],\n",
            "        [157.4603, 459.6826, 195.5556, 497.7778]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.2307, -1.9209],\n",
            "        [ 4.2225, -1.8672],\n",
            "        [ 5.1748,  6.6416],\n",
            "        [ 4.2238, -1.8659],\n",
            "        [ 5.1676,  6.6353]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.8245, 287.0244, 698.6094, 326.1064],\n",
            "        [661.3064, 286.9359, 699.0743, 326.1018],\n",
            "        [464.6257, 101.4229, 502.5146, 138.3639],\n",
            "        [661.3553, 286.9326, 698.9691, 326.1743],\n",
            "        [464.9560, 101.9243, 502.6122, 138.5695]], device='cuda:0')\n",
            "GT bboxes: tensor([[712.3810, 132.0635, 750.4762, 170.1587],\n",
            "        [660.3174, 286.9841, 698.4127, 325.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8377,  7.5645,  4.8103,  2.7840],\n",
            "        [ 3.7474,  5.3835,  3.3527,  3.7524],\n",
            "        [ 3.7525,  5.3811,  3.3597,  3.7578],\n",
            "        [-1.7978,  7.5695,  4.8167,  2.7888],\n",
            "        [-1.7806,  7.5626,  4.8089,  2.7825]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.7241, 550.7721, 150.7569, 590.0728],\n",
            "        [265.2375, 526.5508, 303.6526, 565.5566],\n",
            "        [265.5527, 526.6236, 303.8002, 565.4638],\n",
            "        [111.3110, 550.4090, 150.7710, 590.1038],\n",
            "        [112.5218, 551.0760, 151.0924, 589.8179]], device='cuda:0')\n",
            "GT bboxes: tensor([[111.7460, 552.3810, 149.8413, 590.4762],\n",
            "        [278.0952, 236.1905, 316.1905, 274.2857],\n",
            "        [234.9206, 402.5397, 273.0159, 440.6349],\n",
            "        [157.4603, 459.6826, 195.5556, 497.7778]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.2301, -1.9121],\n",
            "        [ 4.2229, -1.8689],\n",
            "        [ 5.1754,  6.6421],\n",
            "        [ 4.2247, -1.8671],\n",
            "        [ 5.1685,  6.6358]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.8587, 287.0432, 698.7700, 326.0212],\n",
            "        [661.3047, 286.9402, 699.1257, 325.9999],\n",
            "        [464.7314, 101.4962, 502.4863, 138.3351],\n",
            "        [661.3795, 286.9439, 698.9994, 326.0774],\n",
            "        [465.1086, 101.9753, 502.5365, 138.5443]], device='cuda:0')\n",
            "GT bboxes: tensor([[712.3810, 132.0635, 750.4762, 170.1587],\n",
            "        [660.3174, 286.9841, 698.4127, 325.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8344,  7.5508,  4.7933,  2.7669],\n",
            "        [ 3.7354,  5.4015,  3.3700,  3.7695],\n",
            "        [ 3.7409,  5.3984,  3.3769,  3.7748],\n",
            "        [-1.7998,  7.5550,  4.7990,  2.7714],\n",
            "        [-1.7835,  7.5489,  4.7923,  2.7663]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[111.7350, 550.7382, 150.8006, 589.9953],\n",
            "        [265.2672, 526.6002, 303.6014, 565.5505],\n",
            "        [265.5956, 526.6733, 303.7612, 565.4581],\n",
            "        [111.3124, 550.4194, 150.7994, 590.0750],\n",
            "        [112.4825, 551.0776, 151.0815, 589.7403]], device='cuda:0')\n",
            "GT bboxes: tensor([[111.7460, 552.3810, 149.8413, 590.4762],\n",
            "        [278.0952, 236.1905, 316.1905, 274.2857],\n",
            "        [234.9206, 402.5397, 273.0159, 440.6349],\n",
            "        [157.4603, 459.6826, 195.5556, 497.7778]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.2379, -1.9031],\n",
            "        [ 4.2304, -1.8601],\n",
            "        [ 5.1832,  6.6498],\n",
            "        [ 4.2317, -1.8581],\n",
            "        [ 5.1767,  6.6438]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[660.9764, 287.0386, 698.6595, 326.0479],\n",
            "        [661.3772, 286.9394, 699.0516, 326.0323],\n",
            "        [464.7410, 101.5278, 502.4831, 138.3089],\n",
            "        [661.4320, 286.9394, 698.9398, 326.1224],\n",
            "        [465.1309, 101.9985, 502.5213, 138.5171]], device='cuda:0')\n",
            "GT bboxes: tensor([[712.3810, 132.0635, 750.4762, 170.1587],\n",
            "        [660.3174, 286.9841, 698.4127, 325.0794]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8184,  7.5721,  4.8251,  2.7941],\n",
            "        [ 3.7176,  5.4263,  3.3733,  3.7748],\n",
            "        [ 3.7367,  5.4228,  3.4102,  3.8054],\n",
            "        [-1.6740,  7.5873,  4.8412,  2.8057],\n",
            "        [-1.6466,  7.5779,  4.8282,  2.7899]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[112.0649, 550.4618, 151.0017, 590.4848],\n",
            "        [264.7156, 527.7210, 302.8743, 565.6994],\n",
            "        [265.8886, 527.9060, 303.7085, 565.4647],\n",
            "        [111.0541, 548.1553, 150.2009, 589.4763],\n",
            "        [114.2589, 551.4341, 152.7756, 590.2138]], device='cuda:0')\n",
            "GT bboxes: tensor([[111.7460, 552.3810, 149.8413, 590.4762],\n",
            "        [278.0952, 236.1905, 316.1905, 274.2857],\n",
            "        [234.9206, 402.5397, 273.0159, 440.6349],\n",
            "        [157.4603, 459.6826, 195.5556, 497.7778]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.2568, -1.8283],\n",
            "        [ 4.2352, -1.7837],\n",
            "        [ 5.1953,  6.6604],\n",
            "        [ 4.2329, -1.7894],\n",
            "        [ 5.1700,  6.6412]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[659.9425, 287.5173, 698.6830, 327.1458],\n",
            "        [661.2954, 287.4483, 699.7230, 326.3578],\n",
            "        [464.1561, 100.2119, 502.3913, 138.0527],\n",
            "        [661.2841, 287.0887, 699.4299, 327.0079],\n",
            "        [464.2307, 101.9324, 503.0084, 139.0937]], device='cuda:0')\n",
            "GT bboxes: tensor([[712.3810, 132.0635, 750.4762, 170.1587],\n",
            "        [660.3174, 286.9841, 698.4127, 325.0794]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 54\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_63_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f37cc219de0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[463.4921, 558.7302, 501.5873, 596.8254]], device='cuda:0')\n",
            "            labels: tensor([4], device='cuda:0')\n",
            "        ) at 0x7f37cc21a680>\n",
            ") at 0x7f37cc2199f0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 40\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_25_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3763d47040>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[618.4127, 203.1746, 656.5079, 241.2699],\n",
            "                        [624.7619, 241.2699, 662.8571, 279.3651],\n",
            "                        [673.0159,  64.7619, 711.1111, 102.8571]], device='cuda:0')\n",
            "            labels: tensor([0, 0, 3], device='cuda:0')\n",
            "        ) at 0x7f3763d47880>\n",
            ") at 0x7f37cc219510>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[4.2917],\n",
            "        [4.2930],\n",
            "        [4.2757],\n",
            "        [4.2771],\n",
            "        [4.2989]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[574.0960, 463.3643, 611.2281, 497.0706],\n",
            "        [574.2391, 462.9854, 611.1036, 497.4286],\n",
            "        [573.3422, 463.6028, 610.3631, 497.8330],\n",
            "        [573.3505, 463.6218, 610.7308, 497.8672],\n",
            "        [574.0516, 462.8258, 611.0743, 497.0023]], device='cuda:0')\n",
            "GT bboxes: tensor([[463.4921, 558.7302, 501.5873, 596.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8701,  0.8699,  3.6512],\n",
            "        [ 0.9253, -1.7918,  4.1175],\n",
            "        [ 4.0881,  4.5252, -1.7720],\n",
            "        [ 0.3372, -0.1311,  3.7663],\n",
            "        [ 0.8012, -1.8518,  4.0601]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[618.6086, 203.7470, 656.5412, 239.7328],\n",
            "        [624.6830, 244.1048, 663.3796, 279.1137],\n",
            "        [673.6727,  64.1169, 711.8296, 100.7769],\n",
            "        [629.9595, 224.3655, 668.0050, 260.2880],\n",
            "        [624.5276, 239.7765, 663.6648, 279.5573]], device='cuda:0')\n",
            "GT bboxes: tensor([[618.4127, 203.1746, 656.5079, 241.2699],\n",
            "        [624.7619, 241.2699, 662.8571, 279.3651],\n",
            "        [673.0159,  64.7619, 711.1111, 102.8571]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[4.2886],\n",
            "        [4.2923],\n",
            "        [4.2828],\n",
            "        [4.2858],\n",
            "        [4.3022]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[573.8713, 463.0839, 611.0808, 497.4472],\n",
            "        [574.0254, 462.8298, 611.0108, 497.5342],\n",
            "        [573.4512, 463.2211, 610.5639, 497.6790],\n",
            "        [573.4673, 463.1605, 610.8063, 497.6573],\n",
            "        [574.1397, 462.6052, 611.0107, 497.1942]], device='cuda:0')\n",
            "GT bboxes: tensor([[463.4921, 558.7302, 501.5873, 596.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8380,  0.8818,  3.7088],\n",
            "        [ 0.9013, -1.8218,  4.1687],\n",
            "        [ 4.0889,  4.5260, -1.7827],\n",
            "        [ 0.3587, -0.1050,  3.8310],\n",
            "        [ 0.8288, -1.8192,  4.1510]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[618.6202, 203.8922, 656.3387, 239.4597],\n",
            "        [624.5679, 243.3508, 663.1883, 279.9514],\n",
            "        [673.8295,  64.0088, 711.7147, 100.9277],\n",
            "        [630.4893, 224.8171, 667.9229, 259.7754],\n",
            "        [624.3712, 240.3417, 664.1761, 280.0704]], device='cuda:0')\n",
            "GT bboxes: tensor([[618.4127, 203.1746, 656.5079, 241.2699],\n",
            "        [624.7619, 241.2699, 662.8571, 279.3651],\n",
            "        [673.0159,  64.7619, 711.1111, 102.8571]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[4.2948],\n",
            "        [4.2952],\n",
            "        [4.2884],\n",
            "        [4.2869],\n",
            "        [4.2972]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[574.0743, 462.9813, 610.6118, 496.9724],\n",
            "        [574.2432, 462.8253, 610.5198, 497.0692],\n",
            "        [573.8262, 463.0752, 610.3218, 497.1577],\n",
            "        [573.7368, 462.9611, 610.6453, 497.3261],\n",
            "        [574.1614, 462.5721, 610.7896, 497.0357]], device='cuda:0')\n",
            "GT bboxes: tensor([[463.4921, 558.7302, 501.5873, 596.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8595,  0.8808,  3.6863],\n",
            "        [ 0.8801, -1.8612,  4.1514],\n",
            "        [ 4.0922,  4.5291, -1.7783],\n",
            "        [ 0.3652, -0.1200,  3.7721],\n",
            "        [ 0.8198, -1.7333,  4.1182]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[618.6660, 203.5674, 656.2454, 239.6604],\n",
            "        [624.5795, 242.6583, 663.0598, 280.0908],\n",
            "        [674.1141,  64.0621, 711.5353, 100.8859],\n",
            "        [630.3647, 224.7697, 668.1063, 260.2396],\n",
            "        [623.6904, 240.1964, 664.8088, 280.2928]], device='cuda:0')\n",
            "GT bboxes: tensor([[618.4127, 203.1746, 656.5079, 241.2699],\n",
            "        [624.7619, 241.2699, 662.8571, 279.3651],\n",
            "        [673.0159,  64.7619, 711.1111, 102.8571]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[4.2975],\n",
            "        [4.2972],\n",
            "        [4.2920],\n",
            "        [4.2926],\n",
            "        [4.3011]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[574.0726, 462.7629, 610.6777, 497.0018],\n",
            "        [574.1401, 462.7033, 610.6554, 497.0599],\n",
            "        [573.8704, 462.9488, 610.3726, 497.1450],\n",
            "        [573.8611, 462.8300, 610.6156, 497.3507],\n",
            "        [574.1702, 462.5009, 610.7948, 497.0731]], device='cuda:0')\n",
            "GT bboxes: tensor([[463.4921, 558.7302, 501.5873, 596.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8356,  0.8860,  3.6862],\n",
            "        [ 0.8782, -1.8970,  4.1445],\n",
            "        [ 4.0949,  4.5316, -1.7794],\n",
            "        [ 0.3703, -0.1140,  3.7944],\n",
            "        [ 0.7992, -1.7539,  4.1656]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[618.8069, 203.5806, 656.1721, 239.4976],\n",
            "        [624.7151, 242.5925, 662.9554, 279.7418],\n",
            "        [674.3170,  64.1618, 711.4523, 100.8218],\n",
            "        [630.5646, 224.8204, 667.9776, 260.1660],\n",
            "        [623.8831, 239.6665, 664.6025, 279.7791]], device='cuda:0')\n",
            "GT bboxes: tensor([[618.4127, 203.1746, 656.5079, 241.2699],\n",
            "        [624.7619, 241.2699, 662.8571, 279.3651],\n",
            "        [673.0159,  64.7619, 711.1111, 102.8571]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[4.2937],\n",
            "        [4.2939],\n",
            "        [4.2888],\n",
            "        [4.2901],\n",
            "        [4.2995]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[574.1453, 462.8471, 610.6679, 496.9851],\n",
            "        [574.2459, 462.8002, 610.6100, 497.0281],\n",
            "        [573.9932, 463.0688, 610.3105, 497.0995],\n",
            "        [573.9945, 462.9395, 610.5438, 497.3181],\n",
            "        [574.3115, 462.5681, 610.7268, 497.0649]], device='cuda:0')\n",
            "GT bboxes: tensor([[463.4921, 558.7302, 501.5873, 596.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8144,  0.8909,  3.6847],\n",
            "        [ 0.8844, -1.8983,  4.1434],\n",
            "        [ 4.0960,  4.5326, -1.7819],\n",
            "        [ 0.3760, -0.1134,  3.7867],\n",
            "        [ 0.8052, -1.7620,  4.1144]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[618.8933, 203.6304, 656.1239, 239.3223],\n",
            "        [624.7667, 242.7765, 662.9283, 279.5783],\n",
            "        [674.4344,  64.3341, 711.3785, 100.7804],\n",
            "        [630.6075, 224.8965, 667.9683, 260.1863],\n",
            "        [623.9807, 239.7113, 664.6061, 279.7144]], device='cuda:0')\n",
            "GT bboxes: tensor([[618.4127, 203.1746, 656.5079, 241.2699],\n",
            "        [624.7619, 241.2699, 662.8571, 279.3651],\n",
            "        [673.0159,  64.7619, 711.1111, 102.8571]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[4.3004],\n",
            "        [4.3006],\n",
            "        [4.2950],\n",
            "        [4.2959],\n",
            "        [4.3050]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[574.1588, 462.9135, 610.6567, 496.9655],\n",
            "        [574.2637, 462.8578, 610.5961, 497.0192],\n",
            "        [573.9972, 463.1166, 610.3121, 497.0990],\n",
            "        [573.9986, 462.9877, 610.5452, 497.3174],\n",
            "        [574.2985, 462.6146, 610.7454, 497.0628]], device='cuda:0')\n",
            "GT bboxes: tensor([[463.4921, 558.7302, 501.5873, 596.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8167,  0.8859,  3.6655],\n",
            "        [ 0.8842, -1.8955,  4.1212],\n",
            "        [ 4.0931,  4.5297, -1.7752],\n",
            "        [ 0.3746, -0.1159,  3.7668],\n",
            "        [ 0.7972, -1.7556,  4.0949]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[618.9084, 203.6635, 656.1353, 239.3337],\n",
            "        [624.8141, 242.8283, 662.9390, 279.5728],\n",
            "        [674.4663,  64.2898, 711.3476, 100.8148],\n",
            "        [630.6304, 224.9350, 667.9673, 260.1706],\n",
            "        [623.9765, 239.5602, 664.6142, 279.7467]], device='cuda:0')\n",
            "GT bboxes: tensor([[618.4127, 203.1746, 656.5079, 241.2699],\n",
            "        [624.7619, 241.2699, 662.8571, 279.3651],\n",
            "        [673.0159,  64.7619, 711.1111, 102.8571]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[4.2936],\n",
            "        [4.2869],\n",
            "        [4.2510],\n",
            "        [4.2610],\n",
            "        [4.2925]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[573.9977, 463.5369, 611.6700, 497.7020],\n",
            "        [574.3083, 462.8008, 611.4520, 498.3520],\n",
            "        [572.7567, 464.1604, 610.2128, 498.8002],\n",
            "        [572.7223, 464.1926, 610.7509, 498.9355],\n",
            "        [573.9008, 462.7446, 611.2424, 497.5858]], device='cuda:0')\n",
            "GT bboxes: tensor([[463.4921, 558.7302, 501.5873, 596.8254]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9211,  0.8528,  3.7381],\n",
            "        [ 0.9247, -1.7839,  4.2012],\n",
            "        [ 4.0882,  4.5253, -1.7597],\n",
            "        [ 0.3755, -0.1197,  3.8366],\n",
            "        [ 0.7120, -1.6914,  4.1207]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[618.3348, 203.8071, 656.5067, 240.4792],\n",
            "        [624.7292, 244.0597, 663.1677, 280.1157],\n",
            "        [673.4940,  63.9077, 711.9559, 100.6418],\n",
            "        [630.2966, 225.1862, 668.1996, 260.0275],\n",
            "        [624.5526, 237.0099, 663.4018, 280.3990]], device='cuda:0')\n",
            "GT bboxes: tensor([[618.4127, 203.1746, 656.5079, 241.2699],\n",
            "        [624.7619, 241.2699, 662.8571, 279.3651],\n",
            "        [673.0159,  64.7619, 711.1111, 102.8571]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 99\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_86_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f37cc2196c0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[641.2698, 707.3016, 679.3651, 745.3969],\n",
            "                        [248.8889, 681.9048, 286.9841, 720.0000]], device='cuda:0')\n",
            "            labels: tensor([4, 5], device='cuda:0')\n",
            "        ) at 0x7f37cc219cc0>\n",
            ") at 0x7f37cc21a2c0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 41\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_33_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3763d47e80>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[445.7143, 214.6032, 483.8095, 252.6984]], device='cuda:0')\n",
            "            labels: tensor([0], device='cuda:0')\n",
            "        ) at 0x7f3763d47550>\n",
            ") at 0x7f37cc2199f0>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8973,  6.9939],\n",
            "        [-1.8079,  7.0152],\n",
            "        [-1.8705,  6.9986],\n",
            "        [-1.7119,  7.0015],\n",
            "        [ 4.8791,  6.5221]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[641.5007, 707.2650, 679.1765, 743.7408],\n",
            "        [642.4720, 707.6582, 680.3033, 744.2423],\n",
            "        [641.4572, 707.6868, 679.1410, 743.7313],\n",
            "        [642.7278, 706.2360, 680.4995, 743.6287],\n",
            "        [505.0814, 565.4249, 543.5084, 603.3206]], device='cuda:0')\n",
            "GT bboxes: tensor([[641.2698, 707.3016, 679.3651, 745.3969],\n",
            "        [248.8889, 681.9048, 286.9841, 720.0000]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9050],\n",
            "        [-1.9148],\n",
            "        [-1.9097],\n",
            "        [-1.9039],\n",
            "        [-1.8629]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[446.1277, 214.9859, 484.1198, 253.3461],\n",
            "        [446.3385, 214.6012, 484.1390, 253.3340],\n",
            "        [445.2748, 214.5625, 483.3967, 253.5030],\n",
            "        [446.6006, 214.6823, 483.3585, 253.0819],\n",
            "        [445.0697, 214.1264, 483.1786, 253.5093]], device='cuda:0')\n",
            "GT bboxes: tensor([[445.7143, 214.6032, 483.8095, 252.6984]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9405,  6.9986],\n",
            "        [-1.8757,  7.0141],\n",
            "        [-1.8987,  7.0029],\n",
            "        [-1.8269,  7.0071],\n",
            "        [ 4.8463,  6.5220]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[641.4465, 707.1902, 679.1290, 744.2726],\n",
            "        [642.3104, 707.5116, 679.9141, 744.5209],\n",
            "        [641.5914, 707.6248, 679.0663, 744.1636],\n",
            "        [642.4216, 706.7201, 680.0151, 744.3079],\n",
            "        [505.0984, 565.6844, 543.5443, 603.7254]], device='cuda:0')\n",
            "GT bboxes: tensor([[641.2698, 707.3016, 679.3651, 745.3969],\n",
            "        [248.8889, 681.9048, 286.9841, 720.0000]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8762],\n",
            "        [-1.8879],\n",
            "        [-1.8992],\n",
            "        [-1.8541],\n",
            "        [-1.9148]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[446.3022, 215.2213, 483.9516, 253.6043],\n",
            "        [446.4764, 214.9628, 483.8864, 253.5355],\n",
            "        [445.8626, 214.9651, 483.4461, 253.6587],\n",
            "        [446.7399, 215.0306, 483.3318, 253.3763],\n",
            "        [445.7053, 214.4867, 483.2582, 253.5678]], device='cuda:0')\n",
            "GT bboxes: tensor([[445.7143, 214.6032, 483.8095, 252.6984]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8483,  7.0000],\n",
            "        [-1.8175,  7.0121],\n",
            "        [-1.8042,  7.0036],\n",
            "        [-1.8683,  7.0073],\n",
            "        [ 4.8750,  6.5239]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[641.6827, 707.5286, 678.6289, 743.9134],\n",
            "        [642.3468, 707.9365, 679.0386, 744.0400],\n",
            "        [641.8078, 707.9428, 678.5270, 743.7933],\n",
            "        [642.2835, 707.2424, 679.4792, 744.0780],\n",
            "        [505.4162, 566.0213, 543.5133, 603.8784]], device='cuda:0')\n",
            "GT bboxes: tensor([[641.2698, 707.3016, 679.3651, 745.3969],\n",
            "        [248.8889, 681.9048, 286.9841, 720.0000]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8736],\n",
            "        [-1.8788],\n",
            "        [-1.9019],\n",
            "        [-1.8676],\n",
            "        [-1.9172]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[446.4072, 215.2279, 483.9696, 253.4960],\n",
            "        [446.4933, 215.1129, 483.9735, 253.4216],\n",
            "        [445.8210, 215.1309, 483.5236, 253.5499],\n",
            "        [446.6543, 215.1862, 483.5962, 253.3284],\n",
            "        [445.6475, 214.7315, 483.3188, 253.5159]], device='cuda:0')\n",
            "GT bboxes: tensor([[445.7143, 214.6032, 483.8095, 252.6984]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8386,  7.0012],\n",
            "        [-1.8281,  7.0121],\n",
            "        [-1.8038,  7.0049],\n",
            "        [-1.8742,  7.0080],\n",
            "        [ 4.8768,  6.5266]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[641.7767, 707.5520, 678.5623, 743.8848],\n",
            "        [642.2941, 707.8958, 679.0537, 744.0582],\n",
            "        [641.9020, 707.9202, 678.5109, 743.8135],\n",
            "        [642.1792, 707.4376, 679.3255, 744.0408],\n",
            "        [505.7027, 566.0835, 543.4547, 603.6757]], device='cuda:0')\n",
            "GT bboxes: tensor([[641.2698, 707.3016, 679.3651, 745.3969],\n",
            "        [248.8889, 681.9048, 286.9841, 720.0000]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8775],\n",
            "        [-1.8817],\n",
            "        [-1.8884],\n",
            "        [-1.8667],\n",
            "        [-1.9117]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[446.7232, 215.2437, 483.7994, 253.2287],\n",
            "        [446.7516, 215.1674, 483.8485, 253.1712],\n",
            "        [446.1234, 215.1691, 483.3617, 253.2764],\n",
            "        [446.8061, 215.2221, 483.5681, 253.1174],\n",
            "        [445.8873, 214.8423, 483.2167, 253.2803]], device='cuda:0')\n",
            "GT bboxes: tensor([[445.7143, 214.6032, 483.8095, 252.6984]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8350,  7.0009],\n",
            "        [-1.8317,  7.0102],\n",
            "        [-1.8021,  7.0046],\n",
            "        [-1.8648,  7.0067],\n",
            "        [ 4.8899,  6.5263]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[641.8006, 707.5844, 678.5424, 743.8518],\n",
            "        [642.1763, 707.9059, 678.9913, 744.0391],\n",
            "        [641.9251, 707.9393, 678.4948, 743.7985],\n",
            "        [642.1325, 707.4863, 679.1978, 744.0123],\n",
            "        [505.7380, 566.0898, 543.3943, 603.5862]], device='cuda:0')\n",
            "GT bboxes: tensor([[641.2698, 707.3016, 679.3651, 745.3969],\n",
            "        [248.8889, 681.9048, 286.9841, 720.0000]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8798],\n",
            "        [-1.8833],\n",
            "        [-1.8965],\n",
            "        [-1.8701],\n",
            "        [-1.9105]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[446.7090, 215.2626, 483.8932, 253.0981],\n",
            "        [446.7948, 215.1861, 483.8975, 253.0218],\n",
            "        [446.2182, 215.1844, 483.4788, 253.1312],\n",
            "        [446.8519, 215.2672, 483.6111, 253.0041],\n",
            "        [446.0882, 214.9303, 483.3745, 253.1693]], device='cuda:0')\n",
            "GT bboxes: tensor([[445.7143, 214.6032, 483.8095, 252.6984]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8218,  6.9991],\n",
            "        [-1.8161,  7.0085],\n",
            "        [-1.7890,  7.0029],\n",
            "        [-1.8519,  7.0048],\n",
            "        [ 4.8663,  6.5204]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[641.8239, 707.6501, 678.5654, 743.8011],\n",
            "        [642.2014, 707.9722, 678.9781, 743.9893],\n",
            "        [641.9450, 708.0098, 678.5181, 743.7495],\n",
            "        [642.1292, 707.5606, 679.1928, 743.9520],\n",
            "        [505.7324, 566.0781, 543.4052, 603.5609]], device='cuda:0')\n",
            "GT bboxes: tensor([[641.2698, 707.3016, 679.3651, 745.3969],\n",
            "        [248.8889, 681.9048, 286.9841, 720.0000]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8810],\n",
            "        [-1.8844],\n",
            "        [-1.8964],\n",
            "        [-1.8716],\n",
            "        [-1.9126]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[446.7263, 215.2702, 483.8799, 253.1470],\n",
            "        [446.8208, 215.1919, 483.8755, 253.0732],\n",
            "        [446.1732, 215.1882, 483.4028, 253.1803],\n",
            "        [446.8637, 215.2723, 483.6056, 253.0379],\n",
            "        [446.0496, 214.9135, 483.3189, 253.2141]], device='cuda:0')\n",
            "GT bboxes: tensor([[445.7143, 214.6032, 483.8095, 252.6984]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8711,  6.9860],\n",
            "        [-1.8312,  7.0222],\n",
            "        [-1.9092,  6.9950],\n",
            "        [-1.6446,  6.9978],\n",
            "        [ 4.9091,  6.5117]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[640.9254, 706.4603, 679.3452, 744.0424],\n",
            "        [642.6296, 707.3093, 680.8713, 745.0439],\n",
            "        [640.8152, 707.4588, 679.3174, 744.2074],\n",
            "        [642.9253, 705.3355, 680.9116, 743.7341],\n",
            "        [504.5889, 565.9116, 543.2083, 603.9314]], device='cuda:0')\n",
            "GT bboxes: tensor([[641.2698, 707.3016, 679.3651, 745.3969],\n",
            "        [248.8889, 681.9048, 286.9841, 720.0000]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8697],\n",
            "        [-1.9056],\n",
            "        [-1.7820],\n",
            "        [-1.8558],\n",
            "        [-1.7232]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[445.8484, 215.4443, 484.2863, 253.6899],\n",
            "        [446.0070, 215.0322, 483.9745, 253.6129],\n",
            "        [444.1622, 214.9421, 482.8755, 253.9477],\n",
            "        [446.1107, 215.1351, 482.8065, 253.4056],\n",
            "        [443.8936, 213.7647, 482.4178, 253.8384]], device='cuda:0')\n",
            "GT bboxes: tensor([[445.7143, 214.6032, 483.8095, 252.6984]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 6\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_18_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3763d47880>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[219.6825,  10.1587, 257.7778,  48.2540],\n",
            "                        [123.1746,   2.5397, 161.2699,  40.6349]], device='cuda:0')\n",
            "            labels: tensor([1, 3], device='cuda:0')\n",
            "        ) at 0x7f3763d459c0>\n",
            ") at 0x7f375e4993c0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 35\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_41_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761d335e0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[683.1746, 345.3969, 721.2698, 383.4921],\n",
            "                        [675.5556, 332.6984, 713.6508, 370.7937]], device='cuda:0')\n",
            "            labels: tensor([0, 0], device='cuda:0')\n",
            "        ) at 0x7f3761d33ac0>\n",
            ") at 0x7f375e49a110>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1422, 10.4563],\n",
            "        [ 2.3356, -1.8312],\n",
            "        [ 2.3224, -1.7220],\n",
            "        [ 9.1317, 10.4460],\n",
            "        [ 2.2697, -1.6887]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[606.8555, 202.1953, 643.8096, 238.8458],\n",
            "        [123.4732,   1.3181, 162.4183,  41.1547],\n",
            "        [124.9707,   1.4080, 163.5095,  40.5638],\n",
            "        [605.7448, 202.9196, 642.5298, 238.8530],\n",
            "        [124.6840,   2.4015, 163.2242,  42.9423]], device='cuda:0')\n",
            "GT bboxes: tensor([[219.6825,  10.1587, 257.7778,  48.2540],\n",
            "        [123.1746,   2.5397, 161.2699,  40.6349]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-0.3011, -1.8424],\n",
            "        [-0.4212, -1.7877],\n",
            "        [ 5.2394,  4.9504],\n",
            "        [-1.7514, -0.1585],\n",
            "        [-0.2165, -1.8274]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[675.8121, 333.9939, 712.9447, 370.2206],\n",
            "        [677.5477, 333.8861, 714.0072, 371.0908],\n",
            "        [481.4958, 268.9957, 519.6624, 308.8808],\n",
            "        [684.3896, 347.4813, 722.3376, 383.6406],\n",
            "        [674.7298, 332.8814, 712.4123, 369.9024]], device='cuda:0')\n",
            "GT bboxes: tensor([[683.1746, 345.3969, 721.2698, 383.4921],\n",
            "        [675.5556, 332.6984, 713.6508, 370.7937]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1389, 10.4526],\n",
            "        [ 2.3275, -1.8392],\n",
            "        [ 2.3217, -1.7556],\n",
            "        [ 9.1311, 10.4447],\n",
            "        [ 2.2804, -1.7514]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[606.7412, 202.1543, 643.3909, 239.3779],\n",
            "        [123.8397,   1.6386, 162.3764,  41.0876],\n",
            "        [124.9278,   1.6605, 163.1896,  40.5268],\n",
            "        [605.9273, 202.6906, 642.2281, 239.2100],\n",
            "        [124.4162,   2.4703, 163.0141,  42.3381]], device='cuda:0')\n",
            "GT bboxes: tensor([[219.6825,  10.1587, 257.7778,  48.2540],\n",
            "        [123.1746,   2.5397, 161.2699,  40.6349]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-0.2473, -1.7784],\n",
            "        [-0.3231, -1.7603],\n",
            "        [ 5.2380,  4.9486],\n",
            "        [-1.8055, -0.1925],\n",
            "        [-0.1925, -1.7834]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[675.6826, 333.9543, 712.6434, 369.2216],\n",
            "        [676.9826, 334.0260, 713.2942, 369.6085],\n",
            "        [481.1247, 269.1654, 519.8628, 309.2591],\n",
            "        [684.0831, 347.0553, 721.9520, 383.7679],\n",
            "        [674.7228, 332.9879, 712.5304, 369.1244]], device='cuda:0')\n",
            "GT bboxes: tensor([[683.1746, 345.3969, 721.2698, 383.4921],\n",
            "        [675.5556, 332.6984, 713.6508, 370.7937]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1428, 10.4565],\n",
            "        [ 2.3374, -1.8771],\n",
            "        [ 2.3346, -1.7583],\n",
            "        [ 9.1345, 10.4481],\n",
            "        [ 2.3019, -1.8131]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[606.9243, 202.1576, 643.1625, 239.2408],\n",
            "        [123.9211,   1.9177, 162.1964,  40.5125],\n",
            "        [124.9617,   1.9384, 162.8204,  39.9966],\n",
            "        [606.3312, 202.5462, 642.1737, 239.1357],\n",
            "        [124.5035,   2.6069, 162.7420,  41.3385]], device='cuda:0')\n",
            "GT bboxes: tensor([[219.6825,  10.1587, 257.7778,  48.2540],\n",
            "        [123.1746,   2.5397, 161.2699,  40.6349]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-0.2539, -1.8042],\n",
            "        [-0.3166, -1.7777],\n",
            "        [ 5.2451,  4.9563],\n",
            "        [-1.8439, -0.2109],\n",
            "        [-0.1992, -1.7990]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[675.6058, 333.8602, 712.5914, 369.5703],\n",
            "        [676.6496, 334.0807, 713.0582, 369.8991],\n",
            "        [481.5248, 269.3844, 519.5563, 308.4763],\n",
            "        [684.1953, 346.7969, 721.6529, 383.4915],\n",
            "        [674.6182, 332.9050, 712.5289, 369.4289]], device='cuda:0')\n",
            "GT bboxes: tensor([[683.1746, 345.3969, 721.2698, 383.4921],\n",
            "        [675.5556, 332.6984, 713.6508, 370.7937]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1358, 10.4491],\n",
            "        [ 2.3292, -1.8842],\n",
            "        [ 2.3270, -1.7681],\n",
            "        [ 9.1257, 10.4388],\n",
            "        [ 2.2973, -1.8215]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[606.9276, 202.2779, 643.2398, 239.1446],\n",
            "        [124.0349,   2.2055, 162.2120,  40.3616],\n",
            "        [124.9903,   2.1999, 162.8379,  39.8394],\n",
            "        [606.4066, 202.5534, 642.1393, 239.0315],\n",
            "        [124.5697,   2.7686, 162.7074,  41.1226]], device='cuda:0')\n",
            "GT bboxes: tensor([[219.6825,  10.1587, 257.7778,  48.2540],\n",
            "        [123.1746,   2.5397, 161.2699,  40.6349]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-0.2517, -1.7868],\n",
            "        [-0.3061, -1.7619],\n",
            "        [ 5.2464,  4.9576],\n",
            "        [-1.8395, -0.2254],\n",
            "        [-0.1976, -1.7904]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[675.7769, 333.8456, 712.5084, 369.5292],\n",
            "        [676.6452, 334.0997, 713.0130, 369.7043],\n",
            "        [481.4485, 269.3767, 519.7192, 308.3059],\n",
            "        [684.3232, 346.4675, 721.6339, 383.1996],\n",
            "        [674.7849, 333.0103, 712.4185, 369.3564]], device='cuda:0')\n",
            "GT bboxes: tensor([[683.1746, 345.3969, 721.2698, 383.4921],\n",
            "        [675.5556, 332.6984, 713.6508, 370.7937]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1388, 10.4525],\n",
            "        [ 2.3300, -1.8774],\n",
            "        [ 2.3283, -1.7693],\n",
            "        [ 9.1305, 10.4442],\n",
            "        [ 2.2989, -1.8191]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[606.9694, 202.3715, 643.1964, 239.0686],\n",
            "        [124.1509,   2.2695, 162.2111,  40.3001],\n",
            "        [125.0106,   2.2474, 162.7945,  39.7963],\n",
            "        [606.5743, 202.6224, 642.0898, 238.9771],\n",
            "        [124.6355,   2.8252, 162.6886,  41.0489]], device='cuda:0')\n",
            "GT bboxes: tensor([[219.6825,  10.1587, 257.7778,  48.2540],\n",
            "        [123.1746,   2.5397, 161.2699,  40.6349]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-0.2497, -1.7867],\n",
            "        [-0.3032, -1.7550],\n",
            "        [ 5.2465,  4.9578],\n",
            "        [-1.8086, -0.2190],\n",
            "        [-0.1996, -1.7866]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[675.7417, 333.8569, 712.5971, 369.4351],\n",
            "        [676.6818, 334.0975, 713.0945, 369.5484],\n",
            "        [481.5720, 269.3895, 519.6678, 308.2967],\n",
            "        [684.4072, 346.6413, 721.6516, 382.9575],\n",
            "        [674.8021, 333.0958, 712.4665, 369.3257]], device='cuda:0')\n",
            "GT bboxes: tensor([[683.1746, 345.3969, 721.2698, 383.4921],\n",
            "        [675.5556, 332.6984, 713.6508, 370.7937]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1435, 10.4570],\n",
            "        [ 2.3334, -1.8777],\n",
            "        [ 2.3303, -1.7610],\n",
            "        [ 9.1353, 10.4487],\n",
            "        [ 2.3022, -1.8175]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[607.0053, 202.4082, 643.2161, 239.0762],\n",
            "        [124.1166,   2.2517, 162.1785,  40.3133],\n",
            "        [125.0500,   2.2450, 162.8426,  39.7926],\n",
            "        [606.6084, 202.6674, 642.0573, 238.9768],\n",
            "        [124.6301,   2.7862, 162.6943,  41.0559]], device='cuda:0')\n",
            "GT bboxes: tensor([[219.6825,  10.1587, 257.7778,  48.2540],\n",
            "        [123.1746,   2.5397, 161.2699,  40.6349]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-0.2577, -1.7956],\n",
            "        [-0.3109, -1.7604],\n",
            "        [ 5.2421,  4.9533],\n",
            "        [-1.8083, -0.2206],\n",
            "        [-0.2075, -1.7987]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[675.8147, 333.7897, 712.5211, 369.5976],\n",
            "        [676.7686, 334.0471, 713.0324, 369.6678],\n",
            "        [481.5489, 269.4467, 519.6954, 308.2636],\n",
            "        [684.4348, 346.6963, 721.6447, 382.9503],\n",
            "        [674.8303, 333.0697, 712.4155, 369.4615]], device='cuda:0')\n",
            "GT bboxes: tensor([[683.1746, 345.3969, 721.2698, 383.4921],\n",
            "        [675.5556, 332.6984, 713.6508, 370.7937]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.1446, 10.4590],\n",
            "        [ 2.3520, -1.8285],\n",
            "        [ 2.3302, -1.6376],\n",
            "        [ 9.1354, 10.4499],\n",
            "        [ 2.2239, -1.5796]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[606.3566, 201.8192, 644.5811, 240.0280],\n",
            "        [123.0031,   0.6785, 162.0381,  41.1152],\n",
            "        [125.2477,   0.9273, 163.9315,  40.0884],\n",
            "        [604.1939, 203.0206, 642.5297, 240.3512],\n",
            "        [124.6509,   3.2584, 163.3441,  44.5355]], device='cuda:0')\n",
            "GT bboxes: tensor([[219.6825,  10.1587, 257.7778,  48.2540],\n",
            "        [123.1746,   2.5397, 161.2699,  40.6349]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 2\n",
            "Cost matrix shape: torch.Size([900, 2])\n",
            "Sample of cost matrix:\n",
            " tensor([[-0.3468, -1.7779],\n",
            "        [-0.4862, -1.6700],\n",
            "        [ 5.2323,  4.9431],\n",
            "        [-1.6676, -0.1095],\n",
            "        [-0.2297, -1.8399]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[676.1478, 335.0544, 712.8519, 370.5056],\n",
            "        [678.3481, 335.0517, 714.2050, 371.1344],\n",
            "        [481.5726, 269.6606, 519.2568, 309.6552],\n",
            "        [684.8749, 347.9648, 722.8189, 383.7953],\n",
            "        [674.6287, 332.9206, 712.3654, 370.2520]], device='cuda:0')\n",
            "GT bboxes: tensor([[683.1746, 345.3969, 721.2698, 383.4921],\n",
            "        [675.5556, 332.6984, 713.6508, 370.7937]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 36\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_35_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3763d47e80>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[537.1429, 220.9524, 575.2381, 259.0476]], device='cuda:0')\n",
            "            labels: tensor([0], device='cuda:0')\n",
            "        ) at 0x7f3763d459c0>\n",
            ") at 0x7f3763d477c0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 72\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_72_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f37cc219ae0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[242.5397,  87.6190, 280.6349, 125.7143]], device='cuda:0')\n",
            "            labels: tensor([0], device='cuda:0')\n",
            "        ) at 0x7f37cc21a170>\n",
            ") at 0x7f3763d47880>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8117],\n",
            "        [10.8054],\n",
            "        [10.7740],\n",
            "        [10.7891],\n",
            "        [-1.6159]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[538.3549, 221.0238, 576.0613, 257.7618],\n",
            "        [ 32.7783,  15.8677,  72.5588,  54.1937],\n",
            "        [ 34.2597,  16.7432,  73.7701,  55.5724],\n",
            "        [ 33.0531,  16.4471,  72.5274,  55.7743],\n",
            "        [540.3038, 221.2821, 577.8046, 257.9642]], device='cuda:0')\n",
            "GT bboxes: tensor([[537.1429, 220.9524, 575.2381, 259.0476]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8314],\n",
            "        [-1.9407],\n",
            "        [-1.8031],\n",
            "        [-1.9439],\n",
            "        [-1.7820]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[241.5154,  88.7377, 279.7629, 125.7871],\n",
            "        [242.4697,  88.3826, 280.5397, 125.9317],\n",
            "        [241.6377,  88.8232, 279.3801, 125.4503],\n",
            "        [242.4940,  87.1807, 280.9763, 126.0135],\n",
            "        [241.0341,  87.5283, 278.7032, 125.1743]], device='cuda:0')\n",
            "GT bboxes: tensor([[242.5397,  87.6190, 280.6349, 125.7143]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8450],\n",
            "        [10.8021],\n",
            "        [10.7787],\n",
            "        [10.7926],\n",
            "        [-1.6816]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[538.3161, 220.9372, 575.9113, 258.1254],\n",
            "        [ 32.9024,  15.9323,  72.5384,  54.7535],\n",
            "        [ 34.1900,  16.4473,  73.5540,  55.6187],\n",
            "        [ 33.0416,  16.2924,  72.5560,  55.7003],\n",
            "        [539.8678, 221.2031, 577.1727, 258.1179]], device='cuda:0')\n",
            "GT bboxes: tensor([[537.1429, 220.9524, 575.2381, 259.0476]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8161],\n",
            "        [-1.8865],\n",
            "        [-1.7892],\n",
            "        [-1.9426],\n",
            "        [-1.7839]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[241.5922,  88.7657, 279.6383, 125.9660],\n",
            "        [242.3345,  88.6917, 280.0345, 125.8904],\n",
            "        [241.8629,  88.9471, 279.0788, 125.4823],\n",
            "        [242.4079,  87.9559, 280.4399, 126.1134],\n",
            "        [241.4890,  88.1783, 278.7697, 125.3036]], device='cuda:0')\n",
            "GT bboxes: tensor([[242.5397,  87.6190, 280.6349, 125.7143]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8405],\n",
            "        [10.8022],\n",
            "        [10.7810],\n",
            "        [10.7945],\n",
            "        [-1.7069]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[538.4549, 220.8934, 575.9124, 258.2399],\n",
            "        [ 33.0574,  16.1561,  72.3012,  54.5986],\n",
            "        [ 34.3098,  16.5927,  73.2455,  55.2818],\n",
            "        [ 33.1914,  16.4406,  72.3268,  55.3022],\n",
            "        [539.5681, 221.1398, 576.9396, 258.0316]], device='cuda:0')\n",
            "GT bboxes: tensor([[537.1429, 220.9524, 575.2381, 259.0476]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8199],\n",
            "        [-1.8729],\n",
            "        [-1.8093],\n",
            "        [-1.9147],\n",
            "        [-1.8045]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[241.5586,  88.6688, 279.7141, 126.0075],\n",
            "        [242.1679,  88.6883, 279.9477, 125.8549],\n",
            "        [241.9470,  88.8720, 279.2585, 125.5404],\n",
            "        [241.9216,  87.9037, 280.5208, 126.2485],\n",
            "        [241.2758,  88.0961, 279.0719, 125.4999]], device='cuda:0')\n",
            "GT bboxes: tensor([[242.5397,  87.6190, 280.6349, 125.7143]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7971],\n",
            "        [10.8024],\n",
            "        [10.7825],\n",
            "        [10.7954],\n",
            "        [-1.6858]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[539.2862, 221.0820, 575.5633, 258.0323],\n",
            "        [ 33.1671,  16.3741,  72.2823,  54.4146],\n",
            "        [ 34.2976,  16.7650,  73.2934,  55.0169],\n",
            "        [ 33.2875,  16.6443,  72.3038,  55.0653],\n",
            "        [540.1091, 221.1664, 576.3879, 257.6927]], device='cuda:0')\n",
            "GT bboxes: tensor([[537.1429, 220.9524, 575.2381, 259.0476]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8284],\n",
            "        [-1.8722],\n",
            "        [-1.8102],\n",
            "        [-1.9100],\n",
            "        [-1.8059]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[241.8315,  88.7070, 279.5779, 125.9387],\n",
            "        [242.3040,  88.7431, 279.7940, 125.7946],\n",
            "        [242.1119,  88.9292, 279.1964, 125.5093],\n",
            "        [242.0780,  88.0714, 280.2784, 126.0729],\n",
            "        [241.4257,  88.1422, 279.0024, 125.5002]], device='cuda:0')\n",
            "GT bboxes: tensor([[242.5397,  87.6190, 280.6349, 125.7143]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7665],\n",
            "        [10.8028],\n",
            "        [10.7846],\n",
            "        [10.7961],\n",
            "        [-1.6691]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[539.3575, 221.2905, 575.5989, 257.8191],\n",
            "        [ 33.1712,  16.4916,  72.3496,  54.3283],\n",
            "        [ 34.1731,  16.8646,  73.2799,  54.8896],\n",
            "        [ 33.2767,  16.7606,  72.3963,  54.9320],\n",
            "        [540.0461, 221.1884, 576.5389, 257.5201]], device='cuda:0')\n",
            "GT bboxes: tensor([[537.1429, 220.9524, 575.2381, 259.0476]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8300],\n",
            "        [-1.8627],\n",
            "        [-1.8085],\n",
            "        [-1.9027],\n",
            "        [-1.8073]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[241.9152,  88.7781, 279.5670, 125.8956],\n",
            "        [242.3057,  88.8317, 279.6712, 125.7433],\n",
            "        [242.2191,  88.9953, 279.1646, 125.4805],\n",
            "        [242.1041,  88.1784, 280.2050, 126.0390],\n",
            "        [241.4686,  88.1832, 279.0393, 125.4925]], device='cuda:0')\n",
            "GT bboxes: tensor([[242.5397,  87.6190, 280.6349, 125.7143]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7666],\n",
            "        [10.7995],\n",
            "        [10.7810],\n",
            "        [10.7928],\n",
            "        [-1.6793]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[539.3629, 221.3710, 575.6060, 257.8392],\n",
            "        [ 33.2505,  16.4564,  72.2573,  54.3473],\n",
            "        [ 34.2641,  16.8480,  73.2157,  54.9017],\n",
            "        [ 33.3417,  16.7460,  72.3155,  54.9433],\n",
            "        [540.0649, 221.1396, 576.5214, 257.5913]], device='cuda:0')\n",
            "GT bboxes: tensor([[537.1429, 220.9524, 575.2381, 259.0476]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8379],\n",
            "        [-1.8788],\n",
            "        [-1.8117],\n",
            "        [-1.9160],\n",
            "        [-1.8105]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[241.9213,  88.7743, 279.5665, 125.8539],\n",
            "        [242.4051,  88.8252, 279.7418, 125.7089],\n",
            "        [242.2377,  88.9860, 279.1511, 125.4377],\n",
            "        [242.1680,  88.1720, 280.2468, 125.9984],\n",
            "        [241.5032,  88.1782, 279.0071, 125.4552]], device='cuda:0')\n",
            "GT bboxes: tensor([[242.5397,  87.6190, 280.6349, 125.7143]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.8403],\n",
            "        [10.8222],\n",
            "        [10.7669],\n",
            "        [10.7897],\n",
            "        [-1.5738]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[537.8329, 222.0436, 575.7865, 258.4799],\n",
            "        [ 32.8115,  14.5344,  71.9570,  53.4575],\n",
            "        [ 34.8335,  16.7966,  73.9523,  56.0216],\n",
            "        [ 33.0884,  16.3996,  72.0268,  56.3583],\n",
            "        [540.4754, 221.8270, 578.6014, 258.5846]], device='cuda:0')\n",
            "GT bboxes: tensor([[537.1429, 220.9524, 575.2381, 259.0476]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.7739],\n",
            "        [-1.8593],\n",
            "        [-1.7570],\n",
            "        [-1.8317],\n",
            "        [-1.7194]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[241.0836,  89.0597, 279.9709, 126.3288],\n",
            "        [242.6311,  88.7282, 281.1167, 126.6315],\n",
            "        [241.2178,  89.4137, 279.3373, 125.7820],\n",
            "        [242.5816,  86.6803, 281.7228, 126.8210],\n",
            "        [240.5122,  87.3240, 278.3650, 125.1129]], device='cuda:0')\n",
            "GT bboxes: tensor([[242.5397,  87.6190, 280.6349, 125.7143]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 42\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_45_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3763d47670>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[446.9841, 241.2699, 485.0794, 279.3651]], device='cuda:0')\n",
            "            labels: tensor([1], device='cuda:0')\n",
            "        ) at 0x7f3763d47040>\n",
            ") at 0x7f37cc21a170>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 116\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_117_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f376400b8e0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[270.4762, 458.4127, 308.5714, 496.5080]], device='cuda:0')\n",
            "            labels: tensor([1], device='cuda:0')\n",
            "        ) at 0x7f376400b790>\n",
            ") at 0x7f375e49a0e0>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.4302],\n",
            "        [ 8.4280],\n",
            "        [ 8.4063],\n",
            "        [ 8.4507],\n",
            "        [-1.8896]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 71.7463,  95.2310, 110.5597, 132.6836],\n",
            "        [ 71.5536,  95.3486, 110.1583, 133.4333],\n",
            "        [ 73.1541,  95.7789, 111.2753, 133.5514],\n",
            "        [ 71.8571,  93.4208, 110.3265, 131.1979],\n",
            "        [446.4117, 240.1719, 485.1670, 278.9570]], device='cuda:0')\n",
            "GT bboxes: tensor([[446.9841, 241.2699, 485.0794, 279.3651]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[7.3091],\n",
            "        [6.1913],\n",
            "        [7.3055],\n",
            "        [6.1837],\n",
            "        [6.1996]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[701.7062, 472.5278, 736.9752, 510.1871],\n",
            "        [388.6322, 686.6587, 426.9889, 725.8902],\n",
            "        [702.1172, 471.8726, 738.2024, 509.4893],\n",
            "        [388.1985, 686.3742, 426.6237, 726.0388],\n",
            "        [388.6481, 687.3464, 427.0069, 726.6829]], device='cuda:0')\n",
            "GT bboxes: tensor([[270.4762, 458.4127, 308.5714, 496.5080]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.4201],\n",
            "        [ 8.4206],\n",
            "        [ 8.4047],\n",
            "        [ 8.4365],\n",
            "        [-1.8873]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 72.0678,  95.2362, 110.3571, 132.8377],\n",
            "        [ 71.8419,  95.2705, 110.0594, 133.2893],\n",
            "        [ 73.1333,  95.6246, 110.8747, 133.3920],\n",
            "        [ 72.1626,  94.0105, 110.0044, 131.9283],\n",
            "        [446.3693, 240.0586, 485.1899, 278.9885]], device='cuda:0')\n",
            "GT bboxes: tensor([[446.9841, 241.2699, 485.0794, 279.3651]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[7.2993],\n",
            "        [6.1880],\n",
            "        [7.2953],\n",
            "        [6.1829],\n",
            "        [6.1949]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[701.6483, 472.2640, 736.7936, 510.5168],\n",
            "        [388.8069, 686.5929, 426.9334, 726.1569],\n",
            "        [702.0734, 471.5524, 737.7151, 509.7560],\n",
            "        [388.4877, 686.3172, 426.6971, 726.1675],\n",
            "        [388.8792, 686.9319, 426.9373, 726.6279]], device='cuda:0')\n",
            "GT bboxes: tensor([[270.4762, 458.4127, 308.5714, 496.5080]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.4230],\n",
            "        [ 8.4227],\n",
            "        [ 8.4094],\n",
            "        [ 8.4384],\n",
            "        [-1.8880]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 72.3950,  95.6092, 110.0394, 132.4336],\n",
            "        [ 72.1449,  95.7416, 109.7529, 132.7965],\n",
            "        [ 73.3412,  96.0086, 110.4913, 132.9120],\n",
            "        [ 72.4299,  94.6401, 109.6980, 131.6444],\n",
            "        [446.4126, 239.9889, 485.3721, 279.0485]], device='cuda:0')\n",
            "GT bboxes: tensor([[446.9841, 241.2699, 485.0794, 279.3651]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[7.2949],\n",
            "        [6.1857],\n",
            "        [7.2931],\n",
            "        [6.1800],\n",
            "        [6.1903]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[701.9635, 472.0902, 736.5175, 510.3142],\n",
            "        [389.1083, 686.8956, 426.6871, 725.8806],\n",
            "        [702.3802, 471.5506, 737.2946, 509.8322],\n",
            "        [388.8395, 686.6710, 426.4792, 725.8546],\n",
            "        [389.0871, 687.2014, 426.7138, 726.3197]], device='cuda:0')\n",
            "GT bboxes: tensor([[270.4762, 458.4127, 308.5714, 496.5080]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.4182],\n",
            "        [ 8.4187],\n",
            "        [ 8.4078],\n",
            "        [ 8.4331],\n",
            "        [-1.8855]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 72.4960,  95.5957, 110.0162, 132.3110],\n",
            "        [ 72.2517,  95.7262, 109.7234, 132.5999],\n",
            "        [ 73.2803,  95.8754, 110.4217, 132.6260],\n",
            "        [ 72.4926,  94.6555, 109.6636, 131.6645],\n",
            "        [446.5132, 240.1399, 485.4333, 278.9083]], device='cuda:0')\n",
            "GT bboxes: tensor([[446.9841, 241.2699, 485.0794, 279.3651]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[7.2931],\n",
            "        [6.1863],\n",
            "        [7.2936],\n",
            "        [6.1811],\n",
            "        [6.1898]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[701.9313, 471.9294, 736.5502, 510.1149],\n",
            "        [389.1929, 686.8976, 426.7552, 725.7526],\n",
            "        [702.3842, 471.4875, 737.3718, 509.7540],\n",
            "        [388.8953, 686.7542, 426.5565, 725.6870],\n",
            "        [389.1808, 687.1099, 426.7764, 726.1179]], device='cuda:0')\n",
            "GT bboxes: tensor([[270.4762, 458.4127, 308.5714, 496.5080]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.4164],\n",
            "        [ 8.4166],\n",
            "        [ 8.4071],\n",
            "        [ 8.4295],\n",
            "        [-1.8795]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 72.4770,  95.6243, 110.0854, 132.2659],\n",
            "        [ 72.2681,  95.7673, 109.8234, 132.5554],\n",
            "        [ 73.2058,  95.9771, 110.4148, 132.5989],\n",
            "        [ 72.4852,  94.7898, 109.7967, 131.6794],\n",
            "        [446.4850, 240.2235, 485.4481, 278.8584]], device='cuda:0')\n",
            "GT bboxes: tensor([[446.9841, 241.2699, 485.0794, 279.3651]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[7.2909],\n",
            "        [6.1871],\n",
            "        [7.2909],\n",
            "        [6.1815],\n",
            "        [6.1912]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[702.0519, 472.1784, 736.4645, 509.9466],\n",
            "        [389.2693, 687.0275, 426.8003, 725.7238],\n",
            "        [702.5076, 471.7196, 737.2526, 509.5585],\n",
            "        [388.9539, 686.8508, 426.5845, 725.6876],\n",
            "        [389.2578, 687.2728, 426.8050, 726.0964]], device='cuda:0')\n",
            "GT bboxes: tensor([[270.4762, 458.4127, 308.5714, 496.5080]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.4226],\n",
            "        [ 8.4229],\n",
            "        [ 8.4130],\n",
            "        [ 8.4349],\n",
            "        [-1.8796]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 72.5520,  95.5784, 110.0025, 132.2604],\n",
            "        [ 72.3510,  95.7132, 109.7142, 132.5480],\n",
            "        [ 73.2799,  95.9187, 110.3622, 132.5926],\n",
            "        [ 72.5517,  94.7721, 109.6874, 131.7048],\n",
            "        [446.5433, 240.2545, 485.4931, 278.8813]], device='cuda:0')\n",
            "GT bboxes: tensor([[446.9841, 241.2699, 485.0794, 279.3651]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[7.2995],\n",
            "        [6.1935],\n",
            "        [7.2995],\n",
            "        [6.1879],\n",
            "        [6.1971]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[702.1037, 472.2284, 736.4189, 509.8365],\n",
            "        [389.3008, 687.0249, 426.7954, 725.6807],\n",
            "        [702.5641, 471.7685, 737.2104, 509.4559],\n",
            "        [388.9746, 686.8531, 426.5695, 725.6414],\n",
            "        [389.2780, 687.2523, 426.8069, 726.0483]], device='cuda:0')\n",
            "GT bboxes: tensor([[270.4762, 458.4127, 308.5714, 496.5080]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 8.4247],\n",
            "        [ 8.4187],\n",
            "        [ 8.3877],\n",
            "        [ 8.4550],\n",
            "        [-1.9268]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 71.9086,  95.3458, 110.5377, 133.0065],\n",
            "        [ 71.3594,  95.8527, 109.9908, 134.0884],\n",
            "        [ 73.7057,  96.4310, 111.8258, 134.4650],\n",
            "        [ 71.8000,  92.3487, 110.3304, 130.1226],\n",
            "        [446.4829, 240.6120, 485.0228, 279.6650]], device='cuda:0')\n",
            "GT bboxes: tensor([[446.9841, 241.2699, 485.0794, 279.3651]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[7.3089],\n",
            "        [6.1902],\n",
            "        [7.3054],\n",
            "        [6.1766],\n",
            "        [6.2039]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[701.0039, 473.3637, 736.4556, 510.7287],\n",
            "        [388.7150, 686.7899, 427.1300, 725.9590],\n",
            "        [702.0170, 472.3786, 738.5618, 509.2145],\n",
            "        [387.7584, 686.3325, 426.2216, 726.3290],\n",
            "        [388.6941, 687.7164, 427.1499, 727.2365]], device='cuda:0')\n",
            "GT bboxes: tensor([[270.4762, 458.4127, 308.5714, 496.5080]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 115\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_112_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3761d33430>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[737.7778, 516.8254, 775.8730, 554.9207],\n",
            "                        [614.6032, 723.8096, 652.6984, 761.9048],\n",
            "                        [604.4445, 622.2222, 642.5397, 660.3175]], device='cuda:0')\n",
            "            labels: tensor([0, 3, 3], device='cuda:0')\n",
            "        ) at 0x7f3761d32b30>\n",
            ") at 0x7f3763d459c0>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 82\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_87_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f376400b100>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[411.4286, 731.4286, 449.5238, 769.5239]], device='cuda:0')\n",
            "            labels: tensor([1], device='cuda:0')\n",
            "        ) at 0x7f376400a830>\n",
            ") at 0x7f3763d47670>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9185,  5.5581,  4.3272],\n",
            "        [-1.9182,  5.5791,  4.3471],\n",
            "        [-1.9031,  5.6106,  4.3791],\n",
            "        [ 8.0145,  4.3749,  4.8603],\n",
            "        [-1.7461,  5.5661,  4.3344]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[737.8265, 517.0881, 775.1004, 554.4867],\n",
            "        [737.6178, 516.3120, 775.2019, 555.1192],\n",
            "        [738.5484, 516.5814, 776.6029, 554.8416],\n",
            "        [425.5415, 692.9859, 464.2365, 730.2953],\n",
            "        [736.5884, 517.4448, 773.2375, 555.1124]], device='cuda:0')\n",
            "GT bboxes: tensor([[737.7778, 516.8254, 775.8730, 554.9207],\n",
            "        [614.6032, 723.8096, 652.6984, 761.9048],\n",
            "        [604.4445, 622.2222, 642.5397, 660.3175]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.8306],\n",
            "        [ 4.8226],\n",
            "        [ 4.8428],\n",
            "        [10.0349],\n",
            "        [10.0374]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[640.7145, 706.2516, 679.5324, 742.9896],\n",
            "        [640.7172, 707.3774, 679.2096, 743.0649],\n",
            "        [642.2390, 706.7120, 681.0314, 743.8179],\n",
            "        [652.9987, 325.1088, 689.9742, 363.6533],\n",
            "        [653.8000, 325.5966, 690.3415, 363.7563]], device='cuda:0')\n",
            "GT bboxes: tensor([[411.4286, 731.4286, 449.5238, 769.5239]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9189,  5.5461,  4.3144],\n",
            "        [-1.9154,  5.5657,  4.3335],\n",
            "        [-1.9905,  5.5810,  4.3493],\n",
            "        [ 8.0132,  4.3721,  4.8542],\n",
            "        [-1.8112,  5.5595,  4.3278]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[737.4144, 517.1132, 775.0775, 554.8723],\n",
            "        [737.3392, 516.6678, 775.1382, 555.1508],\n",
            "        [737.9979, 516.8232, 775.8801, 554.8967],\n",
            "        [425.7342, 692.6783, 464.2567, 730.4100],\n",
            "        [737.0081, 517.3856, 773.9731, 555.0660]], device='cuda:0')\n",
            "GT bboxes: tensor([[737.7778, 516.8254, 775.8730, 554.9207],\n",
            "        [614.6032, 723.8096, 652.6984, 761.9048],\n",
            "        [604.4445, 622.2222, 642.5397, 660.3175]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.8174],\n",
            "        [ 4.8198],\n",
            "        [ 4.8321],\n",
            "        [10.0262],\n",
            "        [10.0312]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[640.4059, 706.1331, 679.5408, 743.7826],\n",
            "        [640.6100, 706.9695, 679.1973, 743.6823],\n",
            "        [641.6458, 706.5366, 680.4444, 744.3022],\n",
            "        [653.1556, 325.2290, 689.8352, 363.9828],\n",
            "        [653.8447, 325.5045, 690.1093, 363.9081]], device='cuda:0')\n",
            "GT bboxes: tensor([[411.4286, 731.4286, 449.5238, 769.5239]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9001,  5.5659,  4.3340],\n",
            "        [-1.9081,  5.5642,  4.3319],\n",
            "        [-1.9482,  5.5671,  4.3347],\n",
            "        [ 8.0134,  4.3674,  4.8470],\n",
            "        [-1.8195,  5.5642,  4.3323]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[737.2429, 517.0229, 774.8494, 554.9817],\n",
            "        [737.1985, 516.7836, 775.0146, 555.1147],\n",
            "        [737.4510, 516.7461, 775.5543, 555.1686],\n",
            "        [425.8533, 692.6216, 464.0159, 730.3404],\n",
            "        [736.9774, 516.9977, 773.9211, 555.2374]], device='cuda:0')\n",
            "GT bboxes: tensor([[737.7778, 516.8254, 775.8730, 554.9207],\n",
            "        [614.6032, 723.8096, 652.6984, 761.9048],\n",
            "        [604.4445, 622.2222, 642.5397, 660.3175]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.8302],\n",
            "        [ 4.8319],\n",
            "        [ 4.8345],\n",
            "        [10.0245],\n",
            "        [10.0297]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[640.6807, 706.3293, 679.0926, 743.4882],\n",
            "        [641.0651, 707.1100, 678.6940, 743.3267],\n",
            "        [641.5942, 706.6190, 679.9471, 744.1584],\n",
            "        [653.4987, 325.5276, 689.5326, 363.5517],\n",
            "        [654.0391, 325.7065, 689.8606, 363.4944]], device='cuda:0')\n",
            "GT bboxes: tensor([[411.4286, 731.4286, 449.5238, 769.5239]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9108,  5.5695,  4.3379],\n",
            "        [-1.9255,  5.5724,  4.3405],\n",
            "        [-1.9584,  5.5813,  4.3491],\n",
            "        [ 8.0110,  4.3596,  4.8382],\n",
            "        [-1.8393,  5.5701,  4.3387]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[737.4102, 516.9933, 774.8436, 554.8746],\n",
            "        [737.4079, 516.8323, 774.9614, 554.9893],\n",
            "        [737.5684, 516.8163, 775.4728, 555.0928],\n",
            "        [425.9131, 692.6310, 464.2202, 730.2582],\n",
            "        [737.1924, 516.9568, 773.8723, 555.0669]], device='cuda:0')\n",
            "GT bboxes: tensor([[737.7778, 516.8254, 775.8730, 554.9207],\n",
            "        [614.6032, 723.8096, 652.6984, 761.9048],\n",
            "        [604.4445, 622.2222, 642.5397, 660.3175]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.8286],\n",
            "        [ 4.8284],\n",
            "        [ 4.8306],\n",
            "        [10.0216],\n",
            "        [10.0277]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[640.8455, 706.4604, 679.0096, 743.3627],\n",
            "        [641.1633, 707.1921, 678.6596, 743.2335],\n",
            "        [641.5524, 706.7973, 679.7735, 743.9446],\n",
            "        [653.5765, 325.6123, 689.5247, 363.2308],\n",
            "        [654.1636, 325.7282, 689.8381, 363.1651]], device='cuda:0')\n",
            "GT bboxes: tensor([[411.4286, 731.4286, 449.5238, 769.5239]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9000,  5.5871,  4.3557],\n",
            "        [-1.9197,  5.5884,  4.3569],\n",
            "        [-1.9503,  5.5951,  4.3632],\n",
            "        [ 8.0119,  4.3669,  4.8462],\n",
            "        [-1.8444,  5.5808,  4.3495]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[737.4670, 517.0343, 774.7397, 554.7839],\n",
            "        [737.4720, 516.8958, 774.8469, 554.8770],\n",
            "        [737.6059, 516.8959, 775.3102, 555.0359],\n",
            "        [425.9174, 692.6722, 464.2388, 730.2568],\n",
            "        [737.2126, 516.9825, 773.9061, 554.9945]], device='cuda:0')\n",
            "GT bboxes: tensor([[737.7778, 516.8254, 775.8730, 554.9207],\n",
            "        [614.6032, 723.8096, 652.6984, 761.9048],\n",
            "        [604.4445, 622.2222, 642.5397, 660.3175]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.8289],\n",
            "        [ 4.8279],\n",
            "        [ 4.8307],\n",
            "        [10.0218],\n",
            "        [10.0278]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[640.9199, 706.4738, 678.9913, 743.3251],\n",
            "        [641.2610, 707.2314, 678.6125, 743.1880],\n",
            "        [641.5569, 706.8353, 679.6379, 743.8933],\n",
            "        [653.6404, 325.6720, 689.5238, 363.1499],\n",
            "        [654.2090, 325.7905, 689.8380, 363.0468]], device='cuda:0')\n",
            "GT bboxes: tensor([[411.4286, 731.4286, 449.5238, 769.5239]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9009,  5.5673,  4.3360],\n",
            "        [-1.9188,  5.5685,  4.3370],\n",
            "        [-1.9537,  5.5732,  4.3413],\n",
            "        [ 8.0094,  4.3755,  4.8529],\n",
            "        [-1.8453,  5.5597,  4.3285]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[737.4916, 517.0977, 774.7350, 554.7630],\n",
            "        [737.4852, 516.9691, 774.8492, 554.8408],\n",
            "        [737.5888, 516.9609, 775.3375, 555.0046],\n",
            "        [426.0345, 692.6784, 464.1717, 730.1530],\n",
            "        [737.2526, 517.0314, 773.8477, 554.9871]], device='cuda:0')\n",
            "GT bboxes: tensor([[737.7778, 516.8254, 775.8730, 554.9207],\n",
            "        [614.6032, 723.8096, 652.6984, 761.9048],\n",
            "        [604.4445, 622.2222, 642.5397, 660.3175]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.8339],\n",
            "        [ 4.8324],\n",
            "        [ 4.8349],\n",
            "        [10.0311],\n",
            "        [10.0370]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[640.9210, 706.5274, 678.9931, 743.2919],\n",
            "        [641.2590, 707.3151, 678.6185, 743.1407],\n",
            "        [641.5766, 706.9059, 679.6462, 743.8571],\n",
            "        [653.6561, 325.6400, 689.4924, 363.1400],\n",
            "        [654.2360, 325.7562, 689.8127, 363.0482]], device='cuda:0')\n",
            "GT bboxes: tensor([[411.4286, 731.4286, 449.5238, 769.5239]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 3\n",
            "Cost matrix shape: torch.Size([900, 3])\n",
            "Sample of cost matrix:\n",
            " tensor([[-1.9158,  5.5969,  4.3649],\n",
            "        [-1.8868,  5.5994,  4.3659],\n",
            "        [-1.8281,  5.6268,  4.3943],\n",
            "        [ 8.0226,  4.3783,  4.8683],\n",
            "        [-1.4789,  5.5468,  4.3123]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[737.4709, 517.9578, 775.7456, 554.8947],\n",
            "        [737.1102, 516.5742, 775.4934, 555.7531],\n",
            "        [738.7175, 517.0409, 777.4659, 555.3776],\n",
            "        [425.1905, 692.9753, 463.5395, 730.6273],\n",
            "        [734.2417, 518.6775, 772.1999, 555.8811]], device='cuda:0')\n",
            "GT bboxes: tensor([[737.7778, 516.8254, 775.8730, 554.9207],\n",
            "        [614.6032, 723.8096, 652.6984, 761.9048],\n",
            "        [604.4445, 622.2222, 642.5397, 660.3175]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 4.8336],\n",
            "        [ 4.8126],\n",
            "        [ 4.8429],\n",
            "        [10.0214],\n",
            "        [10.0335]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[640.7328, 705.7307, 679.2855, 743.1904],\n",
            "        [640.4462, 707.6531, 678.9249, 743.5043],\n",
            "        [642.6160, 706.7186, 681.2955, 744.8093],\n",
            "        [652.2933, 325.2658, 690.0279, 364.4057],\n",
            "        [653.6041, 325.8600, 690.6301, 364.0597]], device='cuda:0')\n",
            "GT bboxes: tensor([[411.4286, 731.4286, 449.5238, 769.5239]], device='cuda:0')\n",
            "batch_data_samples:  [<DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 129\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_113_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f3763d47670>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[171.4286, 681.9048, 209.5238, 720.0000],\n",
            "                        [345.3969, 662.8572, 383.4921, 700.9524],\n",
            "                        [383.4921, 620.9524, 421.5873, 659.0477],\n",
            "                        [204.4445, 306.0318, 242.5397, 344.1270]], device='cuda:0')\n",
            "            labels: tensor([2, 3, 3, 3], device='cuda:0')\n",
            "        ) at 0x7f3763d47880>\n",
            ") at 0x7f3763d47d00>, <DetDataSample(\n",
            "\n",
            "    META INFORMATION\n",
            "    pad_shape: (800, 800)\n",
            "    img_id: 29\n",
            "    custom_entities: True\n",
            "    ori_shape: (630, 630)\n",
            "    scale_factor: (1.2698412698412698, 1.2698412698412698)\n",
            "    img_shape: (800, 800)\n",
            "    batch_input_shape: (800, 800)\n",
            "    text: ('ferritin_complex', 'beta_amylase', 'beta_galactosidase', 'cytosolic_ribosome', 'thyroglobulin', 'virus')\n",
            "    img_path: '/content/drive/MyDrive/10440_TS_99_9_17042/./10.012_39_slice.png'\n",
            "\n",
            "    DATA FIELDS\n",
            "    ignored_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
            "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
            "        ) at 0x7f376400b8e0>\n",
            "    gt_instances: <InstanceData(\n",
            "        \n",
            "            META INFORMATION\n",
            "        \n",
            "            DATA FIELDS\n",
            "            bboxes: tensor([[279.3651, 270.4762, 317.4603, 308.5714]], device='cuda:0')\n",
            "            labels: tensor([4], device='cuda:0')\n",
            "        ) at 0x7f37640083a0>\n",
            ") at 0x7f3763d47550>]\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[10.6593,  8.2357,  7.2053, 10.8357],\n",
            "        [10.6691,  8.2474,  7.2167, 10.8482],\n",
            "        [11.9563, 10.9784, 10.9491,  6.7670],\n",
            "        [10.6541,  8.2337,  7.2031, 10.8459],\n",
            "        [10.7117,  8.2888,  7.2579, 10.8888]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[ 7.3693e+02,  5.1711e+02,  7.7419e+02,  5.5437e+02],\n",
            "        [ 7.3665e+02,  5.1656e+02,  7.7398e+02,  5.5495e+02],\n",
            "        [ 2.8734e+02, -6.9935e-01,  3.2440e+02,  3.0294e+01],\n",
            "        [ 7.3557e+02,  5.1736e+02,  7.7226e+02,  5.5506e+02],\n",
            "        [ 7.3719e+02,  5.1660e+02,  7.7530e+02,  5.5484e+02]], device='cuda:0')\n",
            "GT bboxes: tensor([[171.4286, 681.9048, 209.5238, 720.0000],\n",
            "        [345.3969, 662.8572, 383.4921, 700.9524],\n",
            "        [383.4921, 620.9524, 421.5873, 659.0477],\n",
            "        [204.4445, 306.0318, 242.5397, 344.1270]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2629],\n",
            "        [ 9.2779],\n",
            "        [ 9.2654],\n",
            "        [10.7916],\n",
            "        [10.8364]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[690.8012,  95.6366, 728.0815, 132.2992],\n",
            "        [691.7916,  95.2118, 728.8709, 132.1727],\n",
            "        [690.7907,  94.8681, 727.5525, 132.1970],\n",
            "        [730.4734,  14.9737, 768.6548,  51.7558],\n",
            "        [733.0936,  14.3950, 770.6348,  49.6490]], device='cuda:0')\n",
            "GT bboxes: tensor([[279.3651, 270.4762, 317.4603, 308.5714]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[10.6465,  8.2186,  7.1879, 10.8249],\n",
            "        [10.6563,  8.2295,  7.1987, 10.8354],\n",
            "        [11.9502, 10.9707, 10.9414,  6.7606],\n",
            "        [10.6478,  8.2236,  7.1931, 10.8339],\n",
            "        [10.6747,  8.2507,  7.2199, 10.8535]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[7.3657e+02, 5.1717e+02, 7.7413e+02, 5.5478e+02],\n",
            "        [7.3640e+02, 5.1681e+02, 7.7392e+02, 5.5509e+02],\n",
            "        [2.8727e+02, 1.6381e-01, 3.2459e+02, 3.0999e+01],\n",
            "        [7.3590e+02, 5.1733e+02, 7.7274e+02, 5.5494e+02],\n",
            "        [7.3698e+02, 5.1685e+02, 7.7483e+02, 5.5482e+02]], device='cuda:0')\n",
            "GT bboxes: tensor([[171.4286, 681.9048, 209.5238, 720.0000],\n",
            "        [345.3969, 662.8572, 383.4921, 700.9524],\n",
            "        [383.4921, 620.9524, 421.5873, 659.0477],\n",
            "        [204.4445, 306.0318, 242.5397, 344.1270]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2602],\n",
            "        [ 9.2723],\n",
            "        [ 9.2640],\n",
            "        [10.7857],\n",
            "        [10.8282]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[690.9048,  95.6071, 727.8888, 132.2188],\n",
            "        [691.7238,  95.3189, 728.4011, 132.1273],\n",
            "        [690.8879,  94.9555, 727.4907, 132.1292],\n",
            "        [730.6070,  15.2295, 768.4859,  51.9988],\n",
            "        [732.9413,  14.6214, 770.1545,  49.9817]], device='cuda:0')\n",
            "GT bboxes: tensor([[279.3651, 270.4762, 317.4603, 308.5714]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[10.6675,  8.2427,  7.2121, 10.8486],\n",
            "        [10.6634,  8.2382,  7.2074, 10.8441],\n",
            "        [11.9470, 10.9710, 10.9415,  6.7581],\n",
            "        [10.6503,  8.2281,  7.1975, 10.8366],\n",
            "        [10.6696,  8.2464,  7.2154, 10.8513]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[7.3640e+02, 5.1699e+02, 7.7381e+02, 5.5492e+02],\n",
            "        [7.3628e+02, 5.1680e+02, 7.7378e+02, 5.5510e+02],\n",
            "        [2.8734e+02, 3.8209e-01, 3.2427e+02, 3.0607e+01],\n",
            "        [7.3589e+02, 5.1703e+02, 7.7274e+02, 5.5509e+02],\n",
            "        [7.3647e+02, 5.1670e+02, 7.7447e+02, 5.5511e+02]], device='cuda:0')\n",
            "GT bboxes: tensor([[171.4286, 681.9048, 209.5238, 720.0000],\n",
            "        [345.3969, 662.8572, 383.4921, 700.9524],\n",
            "        [383.4921, 620.9524, 421.5873, 659.0477],\n",
            "        [204.4445, 306.0318, 242.5397, 344.1270]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2563],\n",
            "        [ 9.2665],\n",
            "        [ 9.2567],\n",
            "        [10.7809],\n",
            "        [10.8208]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[691.2723,  95.6181, 727.5743, 132.1413],\n",
            "        [691.8743,  95.3884, 728.0803, 132.0633],\n",
            "        [691.1664,  95.1133, 727.2371, 132.0771],\n",
            "        [730.7740,  15.4262, 768.3225,  51.9778],\n",
            "        [732.6171,  14.8518, 769.9081,  50.2262]], device='cuda:0')\n",
            "GT bboxes: tensor([[279.3651, 270.4762, 317.4603, 308.5714]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[10.6608,  8.2318,  7.2012, 10.8354],\n",
            "        [10.6634,  8.2349,  7.2042, 10.8392],\n",
            "        [11.9464, 10.9709, 10.9414,  6.7575],\n",
            "        [10.6593,  8.2318,  7.2014, 10.8382],\n",
            "        [10.6730,  8.2447,  7.2139, 10.8487]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[7.3649e+02, 5.1694e+02, 7.7379e+02, 5.5480e+02],\n",
            "        [7.3644e+02, 5.1683e+02, 7.7372e+02, 5.5496e+02],\n",
            "        [2.8741e+02, 5.1276e-01, 3.2416e+02, 3.0760e+01],\n",
            "        [7.3614e+02, 5.1703e+02, 7.7269e+02, 5.5494e+02],\n",
            "        [7.3652e+02, 5.1672e+02, 7.7437e+02, 5.5502e+02]], device='cuda:0')\n",
            "GT bboxes: tensor([[171.4286, 681.9048, 209.5238, 720.0000],\n",
            "        [345.3969, 662.8572, 383.4921, 700.9524],\n",
            "        [383.4921, 620.9524, 421.5873, 659.0477],\n",
            "        [204.4445, 306.0318, 242.5397, 344.1270]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2556],\n",
            "        [ 9.2650],\n",
            "        [ 9.2558],\n",
            "        [10.7809],\n",
            "        [10.8179]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[691.4182,  95.7220, 727.5450, 132.0228],\n",
            "        [692.0148,  95.5273, 728.0311, 131.9525],\n",
            "        [691.3104,  95.3544, 727.1531, 131.9092],\n",
            "        [730.8612,  15.6540, 768.2998,  51.7933],\n",
            "        [732.6630,  14.9955, 769.8710,  50.3032]], device='cuda:0')\n",
            "GT bboxes: tensor([[279.3651, 270.4762, 317.4603, 308.5714]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[10.6737,  8.2426,  7.2121, 10.8449],\n",
            "        [10.6747,  8.2437,  7.2131, 10.8469],\n",
            "        [11.9450, 10.9710, 10.9416,  6.7559],\n",
            "        [10.6730,  8.2415,  7.2111, 10.8466],\n",
            "        [10.6843,  8.2533,  7.2225, 10.8568]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[7.3652e+02, 5.1695e+02, 7.7369e+02, 5.5470e+02],\n",
            "        [7.3647e+02, 5.1684e+02, 7.7362e+02, 5.5488e+02],\n",
            "        [2.8736e+02, 4.7846e-01, 3.2407e+02, 3.0793e+01],\n",
            "        [7.3621e+02, 5.1706e+02, 7.7268e+02, 5.5482e+02],\n",
            "        [7.3649e+02, 5.1676e+02, 7.7426e+02, 5.5495e+02]], device='cuda:0')\n",
            "GT bboxes: tensor([[171.4286, 681.9048, 209.5238, 720.0000],\n",
            "        [345.3969, 662.8572, 383.4921, 700.9524],\n",
            "        [383.4921, 620.9524, 421.5873, 659.0477],\n",
            "        [204.4445, 306.0318, 242.5397, 344.1270]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2544],\n",
            "        [ 9.2629],\n",
            "        [ 9.2544],\n",
            "        [10.7784],\n",
            "        [10.8147]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[691.6130,  95.8225, 727.3920, 131.9624],\n",
            "        [692.2295,  95.6449, 727.7960, 131.9095],\n",
            "        [691.4514,  95.4772, 727.1117, 131.8270],\n",
            "        [731.0110,  15.7073, 768.2384,  51.7481],\n",
            "        [732.9382,  15.0833, 769.4486,  50.3242]], device='cuda:0')\n",
            "GT bboxes: tensor([[279.3651, 270.4762, 317.4603, 308.5714]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[10.6660,  8.2309,  7.2004, 10.8338],\n",
            "        [10.6672,  8.2320,  7.2014, 10.8358],\n",
            "        [11.9478, 10.9733, 10.9438,  6.7589],\n",
            "        [10.6676,  8.2312,  7.2009, 10.8367],\n",
            "        [10.6756,  8.2402,  7.2094, 10.8442]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[7.3655e+02, 5.1700e+02, 7.7369e+02, 5.5470e+02],\n",
            "        [7.3650e+02, 5.1689e+02, 7.7361e+02, 5.5487e+02],\n",
            "        [2.8740e+02, 5.1620e-01, 3.2408e+02, 3.0741e+01],\n",
            "        [7.3624e+02, 5.1713e+02, 7.7262e+02, 5.5479e+02],\n",
            "        [7.3652e+02, 5.1681e+02, 7.7427e+02, 5.5494e+02]], device='cuda:0')\n",
            "GT bboxes: tensor([[171.4286, 681.9048, 209.5238, 720.0000],\n",
            "        [345.3969, 662.8572, 383.4921, 700.9524],\n",
            "        [383.4921, 620.9524, 421.5873, 659.0477],\n",
            "        [204.4445, 306.0318, 242.5397, 344.1270]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2555],\n",
            "        [ 9.2640],\n",
            "        [ 9.2552],\n",
            "        [10.7794],\n",
            "        [10.8165]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[691.6057,  95.8047, 727.4045, 131.9967],\n",
            "        [692.2292,  95.6464, 727.8252, 131.9388],\n",
            "        [691.4927,  95.4766, 727.0564, 131.8618],\n",
            "        [731.0291,  15.6906, 768.1941,  51.7776],\n",
            "        [732.9354,  15.1066, 769.5048,  50.3466]], device='cuda:0')\n",
            "GT bboxes: tensor([[279.3651, 270.4762, 317.4603, 308.5714]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 4\n",
            "Cost matrix shape: torch.Size([900, 4])\n",
            "Sample of cost matrix:\n",
            " tensor([[10.7012,  8.2669,  7.2358, 10.8867],\n",
            "        [10.6935,  8.2599,  7.2285, 10.8767],\n",
            "        [11.9618, 10.9912, 10.9630,  6.7673],\n",
            "        [10.6535,  8.2194,  7.1878, 10.8604],\n",
            "        [10.7123,  8.2808,  7.2494, 10.8980]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[736.6002, 517.7972, 775.0992, 555.1948],\n",
            "        [735.9954, 516.7879, 774.3679, 555.9216],\n",
            "        [286.3045,  -4.1044, 324.7192,  31.3098],\n",
            "        [733.3151, 518.4434, 771.5361, 556.1769],\n",
            "        [737.0500, 517.0263, 776.0870, 555.7183]], device='cuda:0')\n",
            "GT bboxes: tensor([[171.4286, 681.9048, 209.5238, 720.0000],\n",
            "        [345.3969, 662.8572, 383.4921, 700.9524],\n",
            "        [383.4921, 620.9524, 421.5873, 659.0477],\n",
            "        [204.4445, 306.0318, 242.5397, 344.1270]], device='cuda:0')\n",
            "Number of predictions: 900\n",
            "Number of ground truths: 1\n",
            "Cost matrix shape: torch.Size([900, 1])\n",
            "Sample of cost matrix:\n",
            " tensor([[ 9.2616],\n",
            "        [ 9.2821],\n",
            "        [ 9.2553],\n",
            "        [10.7991],\n",
            "        [10.8566]])\n",
            "Contains NaN: tensor(False)\n",
            "Contains inf: tensor(False)\n",
            "Pred bboxes: tensor([[690.1373,  95.3313, 728.4185, 132.3720],\n",
            "        [691.8177,  95.2932, 729.8673, 132.1375],\n",
            "        [690.0441,  94.4699, 727.5335, 132.0214],\n",
            "        [730.1821,  13.9316, 768.7532,  51.7701],\n",
            "        [733.3502,  13.4865, 771.7748,  49.0517]], device='cuda:0')\n",
            "GT bboxes: tensor([[279.3651, 270.4762, 317.4603, 308.5714]], device='cuda:0')\n",
            "12/13 18:46:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: finetune_config_20241213_180906\n",
            "12/13 18:46:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][39/39]  lr: 1.0000e-06  eta: 0:40:45  time: 1.7439  data_time: 0.0191  memory: 11898  grad_norm: 228.6251  loss: 21.8242  loss_cls: 2.8164  loss_bbox: 0.0193  loss_iou: 0.1474  d0.loss_cls: 2.6262  d0.loss_bbox: 0.0190  d0.loss_iou: 0.1428  d1.loss_cls: 2.7113  d1.loss_bbox: 0.0197  d1.loss_iou: 0.1441  d2.loss_cls: 2.7937  d2.loss_bbox: 0.0188  d2.loss_iou: 0.1415  d3.loss_cls: 2.7901  d3.loss_bbox: 0.0189  d3.loss_iou: 0.1448  d4.loss_cls: 2.7959  d4.loss_bbox: 0.0193  d4.loss_iou: 0.1474  enc_loss_cls: 2.3899  enc_loss_bbox: 0.0185  enc_loss_iou: 0.1462  dn_loss_cls: 0.0256  dn_loss_bbox: 0.0242  dn_loss_iou: 0.2062  d0.dn_loss_cls: 0.1338  d0.dn_loss_bbox: 0.0328  d0.dn_loss_iou: 0.2597  d1.dn_loss_cls: 0.0432  d1.dn_loss_bbox: 0.0267  d1.dn_loss_iou: 0.2201  d2.dn_loss_cls: 0.0327  d2.dn_loss_bbox: 0.0253  d2.dn_loss_iou: 0.2119  d3.dn_loss_cls: 0.0253  d3.dn_loss_bbox: 0.0243  d3.dn_loss_iou: 0.2066  d4.dn_loss_cls: 0.0246  d4.dn_loss_bbox: 0.0242  d4.dn_loss_iou: 0.2060\n",
            "12/13 18:46:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
            "/usr/local/lib/python3.10/dist-packages/mmcv/cnn/bricks/transformer.py:524: UserWarning: position encoding of key ismissing in MultiheadAttention.\n",
            "  warnings.warn(f'position encoding of key is'\n",
            "12/13 18:48:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\n",
            "12/13 18:48:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.003 0.003 0.003 0.003 -1.000 -1.000\n",
            "12/13 18:48:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][37/37]    coco/bbox_mAP: 0.0030  coco/bbox_mAP_50: 0.0030  coco/bbox_mAP_75: 0.0030  coco/bbox_mAP_s: 0.0030  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: -1.0000  data_time: 0.0063  time: 0.3279\n"
          ]
        }
      ],
      "source": [
        "\n",
        "! python /content/drive/MyDrive/mmdetection/tools/train.py /content/drive/MyDrive/finetune_config.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmyQp3P68dI1",
        "outputId": "b6fe0e18-225e-434b-821a-272191e2e5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-Cs2cDAtTky",
        "outputId": "ce3fece0-fae4-456f-9b04-fc53c4e1a73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_base_ = [\n",
            "    '../_base_/datasets/coco_detection.py',\n",
            "    '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'\n",
            "]\n",
            "\n",
            "lang_model_name = 'bert-base-uncased'\n",
            "\n",
            "model = dict(\n",
            "    type='GroundingDINO',\n",
            "    num_queries=900,\n",
            "    with_box_refine=True,\n",
            "    as_two_stage=True,\n",
            "    data_preprocessor=dict(\n",
            "        type='DetDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        bgr_to_rgb=True,\n",
            "        pad_mask=False,\n",
            "    ),\n",
            "    language_model=dict(\n",
            "        type='BertModel',\n",
            "        name=lang_model_name,\n",
            "        pad_to_max=False,\n",
            "        use_sub_sentence_represent=True,\n",
            "        special_tokens_list=['[CLS]', '[SEP]', '.', '?'],\n",
            "        add_pooling_layer=True,\n",
            "    ),\n",
            "    backbone=dict(\n",
            "        type='SwinTransformer',\n",
            "        embed_dims=96,\n",
            "        depths=[2, 2, 6, 2],\n",
            "        num_heads=[3, 6, 12, 24],\n",
            "        window_size=7,\n",
            "        mlp_ratio=4,\n",
            "        qkv_bias=True,\n",
            "        qk_scale=None,\n",
            "        drop_rate=0.,\n",
            "        attn_drop_rate=0.,\n",
            "        drop_path_rate=0.2,\n",
            "        patch_norm=True,\n",
            "        out_indices=(1, 2, 3),\n",
            "        with_cp=False,\n",
            "        convert_weights=False),\n",
            "    neck=dict(\n",
            "        type='ChannelMapper',\n",
            "        in_channels=[192, 384, 768],\n",
            "        kernel_size=1,\n",
            "        out_channels=256,\n",
            "        act_cfg=None,\n",
            "        bias=True,\n",
            "        norm_cfg=dict(type='GN', num_groups=32),\n",
            "        num_outs=4),\n",
            "    encoder=dict(\n",
            "        num_layers=6,\n",
            "        # visual layer config\n",
            "        layer_cfg=dict(\n",
            "            self_attn_cfg=dict(embed_dims=256, num_levels=4, dropout=0.0),\n",
            "            ffn_cfg=dict(\n",
            "                embed_dims=256, feedforward_channels=2048, ffn_drop=0.0)),\n",
            "        # text layer config\n",
            "        text_layer_cfg=dict(\n",
            "            self_attn_cfg=dict(num_heads=4, embed_dims=256, dropout=0.0),\n",
            "            ffn_cfg=dict(\n",
            "                embed_dims=256, feedforward_channels=1024, ffn_drop=0.0)),\n",
            "        # fusion layer config\n",
            "        fusion_layer_cfg=dict(\n",
            "            v_dim=256,\n",
            "            l_dim=256,\n",
            "            embed_dim=1024,\n",
            "            num_heads=4,\n",
            "            init_values=1e-4),\n",
            "    ),\n",
            "    decoder=dict(\n",
            "        num_layers=6,\n",
            "        return_intermediate=True,\n",
            "        layer_cfg=dict(\n",
            "            # query self attention layer\n",
            "            self_attn_cfg=dict(embed_dims=256, num_heads=8, dropout=0.0),\n",
            "            # cross attention layer query to text\n",
            "            cross_attn_text_cfg=dict(embed_dims=256, num_heads=8, dropout=0.0),\n",
            "            # cross attention layer query to image\n",
            "            cross_attn_cfg=dict(embed_dims=256, num_heads=8, dropout=0.0),\n",
            "            ffn_cfg=dict(\n",
            "                embed_dims=256, feedforward_channels=2048, ffn_drop=0.0)),\n",
            "        post_norm_cfg=None),\n",
            "    positional_encoding=dict(\n",
            "        num_feats=128, normalize=True, offset=0.0, temperature=20),\n",
            "    bbox_head=dict(\n",
            "        type='GroundingDINOHead',\n",
            "        num_classes=80,\n",
            "        sync_cls_avg_factor=True,\n",
            "        contrastive_cfg=dict(max_text_len=256),\n",
            "        loss_cls=dict(\n",
            "            type='FocalLoss',\n",
            "            use_sigmoid=True,\n",
            "            gamma=2.0,\n",
            "            alpha=0.25,\n",
            "            loss_weight=1.0),  # 2.0 in DeformDETR\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=5.0)),\n",
            "    dn_cfg=dict(  # TODO: Move to model.train_cfg ?\n",
            "        label_noise_scale=0.5,\n",
            "        box_noise_scale=1.0,  # 0.4 for DN-DETR\n",
            "        group_cfg=dict(dynamic=True, num_groups=None,\n",
            "                       num_dn_queries=100)),  # TODO: half num_dn_queries\n",
            "    # training and testing settings\n",
            "    train_cfg=None,\n",
            "    test_cfg=dict(max_per_img=300))\n",
            "\n",
            "test_pipeline = [\n",
            "    dict(\n",
            "        type='LoadImageFromFile', backend_args=None,\n",
            "        imdecode_backend='pillow'),\n",
            "    dict(\n",
            "        type='FixScaleResize',\n",
            "        scale=(800, 1333),\n",
            "        keep_ratio=True,\n",
            "        backend='pillow'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor', 'text', 'custom_entities',\n",
            "                   'tokens_positive'))\n",
            "]\n",
            "\n",
            "val_dataloader = dict(\n",
            "    dataset=dict(pipeline=test_pipeline, return_classes=True))\n",
            "test_dataloader = val_dataloader\n"
          ]
        }
      ],
      "source": [
        "! cat mmdetection/configs/grounding_dino/grounding_dino_swin-t_pretrain_obj365_goldg_cap4m.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqRrJXRHF4EM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0002d229d22f4562951c1332ab9aea32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "058373ce91c9405492df3e7381d9e750": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "070f2d176e404d0fba57ca0c00cff31b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c9a5518c2894dbcad7d9a0ca7b6b466": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de1b0cffcb014954895bd097930f2012",
              "IPY_MODEL_c9e2d5c317ae4af79ee167b789087f8d",
              "IPY_MODEL_f6e1e14592de4309a26a1603f445f78a"
            ],
            "layout": "IPY_MODEL_795ff19d7cda498d9f3648077776d762"
          }
        },
        "0d76974e9d304a29be21ffa5ad25cd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10b528bd4b0f4d8a86e57f9caa9acdb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "114d5244775645b488c536af762ea71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17fb60778927455bb0c0e222b5479554": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d8c1ec8fca42fbb72d6c292a37a5d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7171ac41d14fa4a07d3524f5c08501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5cc0e51d3ef417b844d85558cce6267",
            "placeholder": "​",
            "style": "IPY_MODEL_e7384a69f73b4e68a1955f83fcb81873",
            "value": "model.safetensors: 100%"
          }
        },
        "30505c7b565445cc9f70a961da2e2e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3223638c2d2a4a77baf8dfcc6e8fb944",
            "placeholder": "​",
            "style": "IPY_MODEL_114d5244775645b488c536af762ea71d",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.70kB/s]"
          }
        },
        "3223638c2d2a4a77baf8dfcc6e8fb944": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ba22c0d97f42ac83da374d98eaa519": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b69f457d324012a112737bfed4ebf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e3207c1d9514299b56c8ffd0afe3691": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3f171b8646e4e969a6055c05a3b6370",
              "IPY_MODEL_78c5532280bf42f6b6da9c202a41d496",
              "IPY_MODEL_30505c7b565445cc9f70a961da2e2e69"
            ],
            "layout": "IPY_MODEL_070f2d176e404d0fba57ca0c00cff31b"
          }
        },
        "564fd734b1ba44adb381cf286baeb993": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce8427ef2354ab7a494870d4ff8a601",
            "placeholder": "​",
            "style": "IPY_MODEL_f753631e9e0f4771a77e9005f8304b1e",
            "value": " 440M/440M [00:01&lt;00:00, 241MB/s]"
          }
        },
        "5b4278cf6ccb40c89005c2f2c84ff5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b08d1e009384d77873c447e6184f7de",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_782bbd88682b40348759f06969b3a5ea",
            "value": 231508
          }
        },
        "5cd90df8b53749ecbfcd33e9956ea5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64a2ac7439164acd8c68bae0664e989c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e7171ac41d14fa4a07d3524f5c08501",
              "IPY_MODEL_ab30b91b7552489996e323be81d40ebf",
              "IPY_MODEL_564fd734b1ba44adb381cf286baeb993"
            ],
            "layout": "IPY_MODEL_10b528bd4b0f4d8a86e57f9caa9acdb1"
          }
        },
        "668d751e06d542a8b9fc4d4f3bf17fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3f4094fc2d94cd18a912f75393008a7",
              "IPY_MODEL_5b4278cf6ccb40c89005c2f2c84ff5a3",
              "IPY_MODEL_d3d8508668d6471592667a8b19227eec"
            ],
            "layout": "IPY_MODEL_854ae1afb85b4255b57927e3aa0afaa8"
          }
        },
        "6b08d1e009384d77873c447e6184f7de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b0a36e17c64e49a9c0f96a94f3747e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73292c29eea747b6b87cc202bf63cf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b09f7109168f4294a80aefaa5c49432b",
            "placeholder": "​",
            "style": "IPY_MODEL_058373ce91c9405492df3e7381d9e750",
            "value": "config.json: 100%"
          }
        },
        "782bbd88682b40348759f06969b3a5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78c5532280bf42f6b6da9c202a41d496": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fb60778927455bb0c0e222b5479554",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9df1bc8c8d194cefbbac40371393faf6",
            "value": 48
          }
        },
        "795ff19d7cda498d9f3648077776d762": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad47d08b4bf49aa811e36aa6d18d327": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848029d5ac424538ae9efbcde8c042ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "854ae1afb85b4255b57927e3aa0afaa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899879659aca4677bbc85ce6dd3d3026": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad47d08b4bf49aa811e36aa6d18d327",
            "placeholder": "​",
            "style": "IPY_MODEL_848029d5ac424538ae9efbcde8c042ea",
            "value": " 570/570 [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "9b625fbfedec40ff8f1722c6d106d212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df1bc8c8d194cefbbac40371393faf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a14a10039fb5407fb72b70ba4525cfd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3f4094fc2d94cd18a912f75393008a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45643cd6c2148a98a2e560704ebc4f3",
            "placeholder": "​",
            "style": "IPY_MODEL_0002d229d22f4562951c1332ab9aea32",
            "value": "vocab.txt: 100%"
          }
        },
        "a5cc0e51d3ef417b844d85558cce6267": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a787c1fc926b45a286b2f64bdf8e4506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9876268ab49422dbb5560df47e8c646": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aabcf19f14f547bf9dc90c21f0228266": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab30b91b7552489996e323be81d40ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b625fbfedec40ff8f1722c6d106d212",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cd90df8b53749ecbfcd33e9956ea5d0",
            "value": 440449768
          }
        },
        "b09f7109168f4294a80aefaa5c49432b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b45643cd6c2148a98a2e560704ebc4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8834a66e1c4f60b48fdde46e6bba46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb77c13076141e180baae89b36f91d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73292c29eea747b6b87cc202bf63cf39",
              "IPY_MODEL_d324155e057c45a085dcd5aa411a40df",
              "IPY_MODEL_899879659aca4677bbc85ce6dd3d3026"
            ],
            "layout": "IPY_MODEL_c5823cedb1f74011b70fee06c37d084a"
          }
        },
        "c5823cedb1f74011b70fee06c37d084a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67ee0314410458984acb5ccae11fbc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9e2d5c317ae4af79ee167b789087f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c67ee0314410458984acb5ccae11fbc8",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d76974e9d304a29be21ffa5ad25cd14",
            "value": 466062
          }
        },
        "cce8427ef2354ab7a494870d4ff8a601": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d324155e057c45a085dcd5aa411a40df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ba22c0d97f42ac83da374d98eaa519",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aabcf19f14f547bf9dc90c21f0228266",
            "value": 570
          }
        },
        "d3d8508668d6471592667a8b19227eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d8c1ec8fca42fbb72d6c292a37a5d0",
            "placeholder": "​",
            "style": "IPY_MODEL_42b69f457d324012a112737bfed4ebf0",
            "value": " 232k/232k [00:00&lt;00:00, 7.90MB/s]"
          }
        },
        "d948c3b3b3f04929a11aa9e925f85bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de1b0cffcb014954895bd097930f2012": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71b0a36e17c64e49a9c0f96a94f3747e",
            "placeholder": "​",
            "style": "IPY_MODEL_a14a10039fb5407fb72b70ba4525cfd5",
            "value": "tokenizer.json: 100%"
          }
        },
        "e7384a69f73b4e68a1955f83fcb81873": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3f171b8646e4e969a6055c05a3b6370": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc8834a66e1c4f60b48fdde46e6bba46",
            "placeholder": "​",
            "style": "IPY_MODEL_d948c3b3b3f04929a11aa9e925f85bf7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f6e1e14592de4309a26a1603f445f78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9876268ab49422dbb5560df47e8c646",
            "placeholder": "​",
            "style": "IPY_MODEL_a787c1fc926b45a286b2f64bdf8e4506",
            "value": " 466k/466k [00:00&lt;00:00, 19.3MB/s]"
          }
        },
        "f753631e9e0f4771a77e9005f8304b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
